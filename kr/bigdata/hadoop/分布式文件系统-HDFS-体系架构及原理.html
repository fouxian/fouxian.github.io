<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>分布式文件系统 HDFS 体系架构及原理 | Keep Running</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.png">
    <script charset="utf-8" async="async" src="/js/jquery.min.js"></script>
    <script charset="utf-8" async="async" src="/js/global.js"></script>
    <script charset="utf-8" async="async" src="/js/fingerprint2.min.js"></script>
    <meta name="description" content="">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <meta name="apple-mobile-web-app-capable" content="yes">
    
    <link rel="preload" href="/assets/css/0.styles.42b858ce.css" as="style"><link rel="preload" href="/assets/js/app.cfd60917.js" as="script"><link rel="preload" href="/assets/js/4.8234885e.js" as="script"><link rel="preload" href="/assets/js/3.1429892b.js" as="script"><link rel="preload" href="/assets/js/22.80eaa289.js" as="script"><link rel="prefetch" href="/assets/js/10.0f0de338.js"><link rel="prefetch" href="/assets/js/11.0c47d372.js"><link rel="prefetch" href="/assets/js/12.b45ce082.js"><link rel="prefetch" href="/assets/js/13.f2032214.js"><link rel="prefetch" href="/assets/js/14.0a8927b2.js"><link rel="prefetch" href="/assets/js/15.9ab1d206.js"><link rel="prefetch" href="/assets/js/16.f03f2e40.js"><link rel="prefetch" href="/assets/js/17.c6bbe2be.js"><link rel="prefetch" href="/assets/js/18.e08bb862.js"><link rel="prefetch" href="/assets/js/19.c00af7cb.js"><link rel="prefetch" href="/assets/js/20.35396483.js"><link rel="prefetch" href="/assets/js/21.fe05d239.js"><link rel="prefetch" href="/assets/js/23.bce5e854.js"><link rel="prefetch" href="/assets/js/24.fa104861.js"><link rel="prefetch" href="/assets/js/25.2c725be9.js"><link rel="prefetch" href="/assets/js/26.fc7addb7.js"><link rel="prefetch" href="/assets/js/27.fc831a66.js"><link rel="prefetch" href="/assets/js/28.3784f580.js"><link rel="prefetch" href="/assets/js/29.7e78aa5c.js"><link rel="prefetch" href="/assets/js/30.b074fddd.js"><link rel="prefetch" href="/assets/js/31.059ebf27.js"><link rel="prefetch" href="/assets/js/32.12570018.js"><link rel="prefetch" href="/assets/js/33.d0dc971f.js"><link rel="prefetch" href="/assets/js/34.c9b46696.js"><link rel="prefetch" href="/assets/js/35.77a81c6a.js"><link rel="prefetch" href="/assets/js/36.6048e328.js"><link rel="prefetch" href="/assets/js/37.b9f285de.js"><link rel="prefetch" href="/assets/js/38.ac5a2abf.js"><link rel="prefetch" href="/assets/js/39.97ca52cb.js"><link rel="prefetch" href="/assets/js/40.1689d33f.js"><link rel="prefetch" href="/assets/js/41.4d2d8182.js"><link rel="prefetch" href="/assets/js/42.8647a8ff.js"><link rel="prefetch" href="/assets/js/43.f867a280.js"><link rel="prefetch" href="/assets/js/44.a51272ee.js"><link rel="prefetch" href="/assets/js/45.c31e6474.js"><link rel="prefetch" href="/assets/js/46.fe85ae54.js"><link rel="prefetch" href="/assets/js/47.dc8a97d4.js"><link rel="prefetch" href="/assets/js/48.c97f7726.js"><link rel="prefetch" href="/assets/js/49.ac219d14.js"><link rel="prefetch" href="/assets/js/5.963fada3.js"><link rel="prefetch" href="/assets/js/50.926ecfa5.js"><link rel="prefetch" href="/assets/js/51.e776b5b1.js"><link rel="prefetch" href="/assets/js/52.4938314c.js"><link rel="prefetch" href="/assets/js/53.6b4d7266.js"><link rel="prefetch" href="/assets/js/54.bfaf622b.js"><link rel="prefetch" href="/assets/js/55.c6d160b9.js"><link rel="prefetch" href="/assets/js/56.31f6843c.js"><link rel="prefetch" href="/assets/js/57.55cbf7b8.js"><link rel="prefetch" href="/assets/js/58.8174871d.js"><link rel="prefetch" href="/assets/js/59.3eee2bde.js"><link rel="prefetch" href="/assets/js/6.b2e36a75.js"><link rel="prefetch" href="/assets/js/60.233a32ed.js"><link rel="prefetch" href="/assets/js/61.defb83ac.js"><link rel="prefetch" href="/assets/js/62.442070cd.js"><link rel="prefetch" href="/assets/js/63.cc121456.js"><link rel="prefetch" href="/assets/js/64.c8f83f5d.js"><link rel="prefetch" href="/assets/js/65.b9bc8c1c.js"><link rel="prefetch" href="/assets/js/7.fb6689bf.js"><link rel="prefetch" href="/assets/js/8.e390cc6b.js"><link rel="prefetch" href="/assets/js/9.c03c9dfe.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.db8a86c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.42b858ce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Keep Running</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="sidebar-link">Hadoop概述及分布式集群容器化部署</a></li><li><a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="active sidebar-link">分布式文件系统 HDFS 体系架构及原理</a></li><li><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html" class="sidebar-link">分布式并行计算 MapReduce 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html" class="sidebar-link">集群资源管理与调度平台 YARN 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/MapReduce-实例-WordCount.html" class="sidebar-link">MapReduce 经典案例：WordCount</a></li><li><a href="/kr/bigdata/hadoop/HDFS-3-X-纠删码.html" class="sidebar-link">HDFS 3.X 纠删码</a></li><li><a href="/kr/bigdata/hadoop/大数据生态圈与离线实时数据平台实践.html" class="sidebar-link">大数据生态圈与离线实时数据平台实践</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hive/分布式数据仓库-Hive.html" class="sidebar-link">分布式数据仓库 Hive</a></li><li><a href="/kr/bigdata/hive/Hive-SQL.html" class="sidebar-link">Hive SQL 执行计划|数据倾斜|性能优化</a></li><li><a href="/kr/bigdata/hive/HiveSQL-编译过程.html" class="sidebar-link">Hive 工作原理：Hive SQL 编译过程</a></li><li><a href="/kr/bigdata/hive/Hive-function.html" class="sidebar-link">Hive Function</a></li><li><a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="sidebar-link">Hive SQL Examples</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="sidebar-link">Spark 概述与集群部署模式</a></li><li><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html" class="sidebar-link">Spark RDD 弹性分布式数据集</a></li><li><a href="/kr/bigdata/spark/Spark-运行架构.html" class="sidebar-link">Spark 运行架构及作业提交流程</a></li><li><a href="/kr/bigdata/spark/Spark-Streaming.html" class="sidebar-link">Spark Streaming</a></li><li><a href="/kr/bigdata/spark/Spark-sql.html" class="sidebar-link">Spark SQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Other</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/Canal-MySQL-binlog-增量订阅与消费组件.html" class="sidebar-link">Canal：MySQL Binlog 增量订阅与消费组件</a></li><li><a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="sidebar-link">Sqoop 数据迁移工具</a></li><li><a href="/kr/bigdata/Flume-基本架构及应用场景.html" class="sidebar-link">Flume 基本架构及应用场景</a></li><li><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html" class="sidebar-link">Azkaban 编译镜像及基本使用</a></li><li><a href="/kr/bigdata/Maxwell.html" class="sidebar-link">Maxwell</a></li><li><a href="/kr/bigdata/Elaticsearch.html" class="sidebar-link">Elaticsearch</a></li><li><a href="/kr/bigdata/大数据可视化交互平台-Hue.html" class="sidebar-link">大数据可视化交互平台 Hue</a></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-default-content content__default"><h1 id="分布式文件系统-hdfs-体系架构及原理"><a href="#分布式文件系统-hdfs-体系架构及原理" class="header-anchor">#</a> 分布式文件系统 HDFS 体系架构及原理</h1> <blockquote><p>分布式文件系统 HDFS 是基于流式数据模式访问和处理超大文件的海量数据存储解决方案，具备在通用硬件集群中进行分布式文件存储的能力，具有高容错、高可靠性、高可扩展性、高吞吐量等特征。</p></blockquote> <p>Hadoop Distributed File System，HDFS：Hadoop 分布式文件系统；
Hadoop 中有一个综合性的文件系统抽象，它提供了文件系统实现的各类接口，而 HDFS 只是这个抽象文件系统的一种具体实现。</p> <p>特点：处理超大文件、运行于廉价的商用机器集群上、高容错性、高可靠性、流式数据访问</p> <p>局限：不适合低延迟数据访问、无法高效存储大量小文件、不支持多用户写入和随机文件修改
（在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作。目前HDFS还不支持多个用户对同一文件的写操作，也不支持在文件任意位置进行修改）</p> <h2 id="hdfs-主从体系架构"><a href="#hdfs-主从体系架构" class="header-anchor">#</a> HDFS 主从体系架构</h2> <p><img src="/images/kr/bigdata/hadoop/HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg" alt="">
分布式文件系统 HDFS 采用 Master-Slave 主从架构模式（一主多从）：</p> <ul><li>NameNode：负责文件系统命名空间、文件目录信息、文件数据块信息(元数据)的管理，主要功能是对内存及 IO 进行集中管理，负责接受用户操作请求</li> <li>SecondaryNameNode：辅助监控 HDFS 状态，辅助 NameNode 管理元数据信息，定期保存 HDFS 元数据快照，用以备份和恢复数据，但不支持热备</li> <li>DataNode：负责文件数据块（多副本机制）的存储管理，定期向 Namenode 发送文件数据块信息</li></ul> <h2 id="namenode"><a href="#namenode" class="header-anchor">#</a> NameNode</h2> <p>NameNode 中元数据信息存储（启动时加载到内存），主要存储文件：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@xzx-hadoop namenode<span class="token punctuation">]</span><span class="token comment"># tree -C</span>
<span class="token builtin class-name">.</span>   <span class="token comment"># NameNode 中文件路径由 hdfs-default.xml 中 dfs.namenode.name.dir 配置</span>
<span class="token operator">|</span>-- current
<span class="token operator">|</span>   <span class="token operator">|</span>-- VERSION     <span class="token comment"># 记录集群信息，HDFS 格式化后集群信息发生变化，故 HDFS 只格式化一次</span>
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000001-0000000000000000002   <span class="token comment"># edits：事务日志文件，记录对文件的操作</span>
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000003-0000000000000000003
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000004-0000000000000000004
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000005-0000000000000000006
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000007-0000000000000000008
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000009-0000000000000000010
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000011-0000000000000000012
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000013-0000000000000000014
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000015-0000000000000000016
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_0000000000000000017-0000000000000000018
<span class="token operator">|</span>   <span class="token operator">|</span>-- edits_inprogress_0000000000000000019
<span class="token operator">|</span>   <span class="token operator">|</span>-- fsimage_0000000000000000016         <span class="token comment"># fsimage：filesystem image，文件系统(元数据)镜像，存储某时刻 NameNode 内存中元数据信息(快照操作)</span>
<span class="token operator">|</span>   <span class="token operator">|</span>-- fsimage_0000000000000000016.md5     <span class="token comment"># 通过 md5 加密 fsimage，通过 md5 值判断 fsimage 是否完整</span>
<span class="token operator">|</span>   <span class="token operator">|</span>-- fsimage_0000000000000000018
<span class="token operator">|</span>   <span class="token operator">|</span>-- fsimage_0000000000000000018.md5
<span class="token operator">|</span>   <span class="token variable"><span class="token variable">`</span>-- seen_txid   <span class="token comment"># HDFS 格式化后为 0，记录 edits 文件尾数</span>
<span class="token variable">`</span></span>-- in_use.lock     <span class="token comment"># 用于控制 NameNode 启动的一把锁，存在则已启动，不可重启，不存在则已停止</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><ul><li>FsImage：元数据镜像文件，持久化元数据信息（快照），包含整个命名空间的信息及文件数据块的映射信息等</li> <li>EditLog：事务日志文件，记录每一个对文件系统元数据的改变</li></ul> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># -i：输入，-o：输出</span>
<span class="token comment"># 查看 fsimage 文件</span>
<span class="token punctuation">[</span>root@xzx-hadoop namenode<span class="token punctuation">]</span><span class="token comment"># hdfs oiv -p XML -i current/fsimage_0000000000000000016 -o fsimage16.xml</span>
<span class="token comment"># 查看 edits 文件</span>
<span class="token punctuation">[</span>root@xzx-hadoop namenode<span class="token punctuation">]</span><span class="token comment"># hdfs oev -i current/edits_0000000000000000009-0000000000000000010 -o edits.xml</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><blockquote><p>hdfs-default.xml：位于 $HADOOP_HOME\share\hadoop\hdfs\hadoop-hdfs-xxx.jar，配置 HDFS 所有默认参数，hdfs-site.xml 属于该文件一个扩展，可覆盖默认参数</p></blockquote> <p>NameNode 元数据信息维护了两个关系映射：</p> <ul><li>File 与 Block List 的映射关系</li> <li>DataNode 与 Block 的映射关系</li></ul> <blockquote><p>NameNode 启动时会将文件元数据信息加载至内存中，每个文件元数据信息占用固定的 150 字节空间。HDFS 不适合存储小文件，因为 NameNode 的内存占满后，DataNode 存储了大量小文件，但文件总体大小很小，失去 HDFS 的价值。</p></blockquote> <p>首次启动 NameNode：</p> <ol><li>格式化文件系统，生成 FsImage 元数据镜像文件；</li> <li>启动 NameNode：读取 FsImage 文件并加载进内存；等待 DataNade 注册并发送块状态报告（block report）</li> <li>启动 DataNode：向 NameNode 注册并发送块状态报告；检查 FsImage 中记录的块数量和块状态报告中的块的总数是否相同</li></ol> <p>第二次启动 NameNode：读取 Fsimage/Editlog 文件并合并成新的 FsImage 文件；创建新的 EditLog 文件，内容开始为空；启动 DataNode</p> <h2 id="secondarynamenode"><a href="#secondarynamenode" class="header-anchor">#</a> SecondaryNameNode</h2> <p>SecondaryNamenode：完成 NameNode CheckPoint（检查点）工作，减少 Editlog 文件大小，缩短 NameNode 重启时间。</p> <p>NameNode CheckPoint：只有当 NameNode 启动时，才会从磁盘中读取 FsImage/EditLog，将 EditLog 中的所有事务应用合并到 FsImage（得到最新的文件系统镜像快照），然后将新的 FsImage 刷新到本地磁盘中，再删除旧的 EditLog 并创建新的 EditLog。
<img src="/images/kr/bigdata/hadoop/SecondaryNamenode-CheckPoint.jpg" alt=""></p> <p>日志与镜像的定期合并步骤：</p> <ul><li>SecondaryNameNode 请求 NameNode 执行检查点，此时 NameNode 产生 edits.new</li> <li>SecondaryNameNode 通过 HTTP GET 获取 NameNode 的 FsImage/Editlog</li> <li>SecondaryNameNode 开始合并 FsImage/Editlog，产生新的 fsimage.ckpt 文件</li> <li>SecondaryNameNode 通过 HTTP POST 发送 fsimage.ckpt 至 NameNode</li> <li>NameNode 将 fsimage.ckpt/edits.new 分别重命名为 fsimage/edits，然后刷新 FsImage 到磁盘</li></ul> <blockquote><p>在 NameNode 的 HA 架构中没有 SecondaryNameNode 进程，检查点工作会由 StandbyNameNode 负责实现，故 Hadoop 集群中，SecondaryNameNode 进程并不是必须的</p></blockquote> <blockquote><p>NameNode 中元数据丢失，可从 SecondaryNameNode 恢复一部分，但不能恢复全部，因 NameNode 正在写的 EditLog 日志还没有拷贝到 SecondaryNameNode。</p> <p>SecondaryNameNode 不能恢复 NameNode 的全部元数据，那如何保证 NameNode 元数据存储安全？：NameNode HA 高可用</p></blockquote> <h2 id="datanode"><a href="#datanode" class="header-anchor">#</a> DataNode</h2> <p>DataNode 文件存储服务：</p> <ul><li>Block：数据读写基本单元，按照固定大小、顺序进行文件分块，默认 Block 大小为 128 M</li> <li>DataNode 中文件路径由 hdfs-default.xml 中 dfs.datanode.data.dir 配置</li> <li>HDFS 中，若一个文件小于一个数据块大小，那么并不会占用整个数据块的存储空间</li> <li>数据块存在多副本机制，保证数据安全，由 dfs.replication 配置，默认 3 个副本</li> <li>数据完整性：读取块时，计算数据块校验和，若与块创建时校验和不一样，则该块已损坏，这时应该读取块副本</li></ul> <p>NameNode 周期性从 DataNode 接收心跳信号和块状态报告：</p> <ul><li>心跳信号：意味着该 Datanode 节点工作正常</li> <li>块状态报告：包含了该 Datanode 节点信息及其上所有数据块的列表等信息</li></ul> <blockquote><p>块状态报告：集群启动时，DataNode 会扫描该节点上所有 Block 信息，再将节点及其上的 Block 信息发送至 NameNode，这个过程在集群启动时进行动态加载，故集群数据越多，启动越慢。</p></blockquote> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># DataNode 的目录结构是初始阶段自动创建，查看版本号</span>
<span class="token punctuation">[</span>root@dmcdw-1 current<span class="token punctuation">]</span><span class="token comment"># cat /usr/local/data/hadoop/datanode/current/VERSION</span>
<span class="token comment">#Fri Oct 08 11:02:02 CST 2021</span>
<span class="token assign-left variable">storageID</span><span class="token operator">=</span>DS-d81c0a18-2a58-41a1-9f67-997b4346d0c7		<span class="token comment"># 存储ID</span>
<span class="token assign-left variable">clusterID</span><span class="token operator">=</span>CID-9eff8e06-885a-47b5-955e-7afc04474768		<span class="token comment"># 集群ID，全局唯一</span>
<span class="token assign-left variable">cTime</span><span class="token operator">=</span><span class="token number">0</span>	<span class="token comment"># DataNode 存储系统创建时间，是在文件系统升级之后，该值会更新到新的时间戳</span>
<span class="token assign-left variable">datanodeUuid</span><span class="token operator">=</span>d83dfcb7-c1aa-4aeb-a88b-9cb008d2af85		<span class="token comment"># DataNode 的唯一识别码</span>
<span class="token assign-left variable">storageType</span><span class="token operator">=</span>DATA_NODE <span class="token comment"># 存储类型</span>
<span class="token assign-left variable">layoutVersion</span><span class="token operator">=</span>-57 <span class="token comment"># 负整数，通常只有 HDFS 增加新特性时才会更新这个值</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="hdfs-high-available-ha-高可用"><a href="#hdfs-high-available-ha-高可用" class="header-anchor">#</a> HDFS High Available（HA） 高可用</h2> <p>NameNode 单点故障：NameNode 负责接收用户的操作请求，当只有一个 NameNode 时，存在 NameNode 宕机无法提供服务及元数据丢失无法恢复的单点故障。
<img src="/images/kr/bigdata/hadoop/HDFS-HA.bmp" alt=""></p> <ul><li>Active NN：集群中任意时刻，只有一个 Active NN，负责客户端请求操作服务</li> <li>Standby NN：用来同步 Active NN 的状态信息，以提供快速的故障恢复能力（热备份）</li> <li>JournalNodes（JN）：保证 Active NN 和 Standby NN 节点状态同步，即元数据一致
<ul><li>通过一组独立的轻量级守护进程 JournalNodes（JN）同步 Editlog 信息</li> <li>当 Active NN 执行任何有关命名空间的修改，它需要持久化到一半 JN 以上</li> <li>而 Standby NN 负责读取从 JN 上发送过来的 Editlog 信息，并更新自己内部的命名空间</li> <li>当 Active NN 不可用，Standby NN 需保证从 JN 中读出全部 Editlog，再切换成 Active 状态</li> <li>如果有多个 Standby NN，则通过 Zookeeper 集群选举操作，选择一个切换为 Active 状态</li></ul></li></ul> <p>元数据同步（采用共享存储，即 JN）：</p> <ul><li>静态：由于 FsImage 是由 Editlog 合并生成的，所以只需要保证多个 NameNode 中 Editlog 内容的事务性同步，由 JournalNodes 集群进行同步</li> <li>动态：DataNode 上报数据块信息时需要向每个 NameNode 都上报一份，保证多个 NameNode 的元数据信息一致</li></ul> <p>HDFS HA 集群配置：</p> <ul><li>NameNode：Active NN 和 Standby NN 的机器应保持一致</li> <li>通过 Zookeeper 集群进行 NameNode 失败检测和 NameNode 选举，实现自动故障转移</li> <li>JournalNodes：通常部署奇数(N)个 JN 节点，则可容纳(N-1)/2个节点故障但不影响集群运行</li></ul> <blockquote><p>HA 集群不部署 SecondaryNameNode，SecondaryNameNode 检查点工作由 Standby NN 负责</p></blockquote> <h3 id="namenode-元数据共享存储方案"><a href="#namenode-元数据共享存储方案" class="header-anchor">#</a> NameNode 元数据共享存储方案</h3> <p>基于 QJM 的共享存储主要用于保存 EditLog 并不保存 FsImage，FsImage 还是在 NameNode 的本地磁盘上</p> <p>QJM 共享存储的基本思想来自于 Paxos 算法，采用多个称为 JournalNode 的节点组成 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 时，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要过半 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。</p> <h3 id="脑裂问题"><a href="#脑裂问题" class="header-anchor">#</a> 脑裂问题</h3> <p>脑裂：当 Zookeeper 与 Active NameNode 间由于某些原因（网络断开）造成心跳检测失败，ZK 认为该 NameNode 不可用，故从 Standby NameNode 中选举一个作为 Active NmaeNode，此时原先 NameNode 仍可能处于 Active 状态，这时集群中存在两个 Active NameNode，会造成数据不一致且无法恢复。
ZK 解决方案：隔离（fencing）原先的 Active NaemNode，使其不能对外提供服务：</p> <ol><li>首先尝试调用这个 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态</li> <li>如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：
<ul><li>sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死</li> <li>shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离</li></ul></li></ol> <h2 id="hdfs-federation-高扩展"><a href="#hdfs-federation-高扩展" class="header-anchor">#</a> HDFS Federation 高扩展</h2> <p>HDFS Federation 允许一个 HDFS 集群中存在多个 NameNode 同时对外提供服务，可以解决单一命名空间存在的问题，每个 NameNode 负责一个命名空间，彼此之间相互隔离独立，但共享底层 DataNode 存储资源，特性：
<img src="/images/kr/bigdata/hadoop/HDFS-Federation.bmp" alt=""></p> <ul><li>集群扩展性：多个 NameNode 分管不同命名空间，集群易扩展，不因内存限制制约文件存储数目</li> <li>性能更高效：多个 NameNode 管理不同数据，且同时对外提供服务，提高读写吞吐率</li> <li>良好隔离性：可根据需要将不同业务数据交由不同 NameNode 管理，这样不同业务之间影响很小</li> <li>DataNode 向所有 NameNode 发送心跳信号和块状态报告，同时执行所有 NameNode 的命令</li></ul> <h2 id="hdfs-文件读写流程"><a href="#hdfs-文件读写流程" class="header-anchor">#</a> HDFS 文件读写流程</h2> <p>图片引用：<a href="http://km.ciozj.com/Detail.aspx?AI=93617&amp;CI=218" target="_blank" rel="noopener noreferrer">http://km.ciozj.com/Detail.aspx?AI=93617&amp;CI=218<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="hdfs-读流程"><a href="#hdfs-读流程" class="header-anchor">#</a> HDFS 读流程</h3> <p><img src="/images/kr/bigdata/hadoop/HDFS-%E8%AF%BB%E6%B5%81%E7%A8%8B.png" alt=""></p> <ol><li>打开文件：HDFS 客户端调用 DistributedFileSystem.open()，向 NameNode 发送 RPC 请求，请求数据块位置</li> <li>读取数据块信息：NameNode 进行权限及文件是否存在校验，校验通过后会返回部分/全部块列表，其中包含每个数据块及其副本的 DataNode 地址
<ul><li>按照集群拓补结构得出 DataNode 与客户端的距离，按规则排序：</li> <li>群拓补结构中距离客户端近的靠前；心跳机制中超时汇报的 DataNode 状态为 STALE，靠后</li></ul></li> <li>读取块数据：客户端调用 FSDatatInputStream.read()，按照每个 DataNode 的距离从近到远依次读取
<ul><li>短路读取特性：若客户端本身就是 DataNode，那么将从本地直接获取数据</li></ul></li> <li>读取完一个块都会进行数据块校验和（checksum）验证：若读取 DataNode 时出现错误（/读取到本地的块与 HDFS 上的原始块进行校验，校验结果不一致），客户端会通知 NameNode，然后再从下一个拥有该 block 副本的 DataNode 继续读</li> <li>当读完块列表后，若文件读取还没有结束，客户端会继续向 NameNode 获取下一批 block 列表，重复2，3，4</li> <li>最终读取来所有的 block 会合并成一个完整的最终文件，调用 FsDataInputStream.close() 关闭文件</li></ol> <h3 id="hdfs-写流程"><a href="#hdfs-写流程" class="header-anchor">#</a> HDFS 写流程</h3> <p><img src="/images/kr/bigdata/hadoop/HDFS-%E5%86%99%E6%B5%81%E7%A8%8B.png" alt=""></p> <ol><li>创建文件：HDFS 客户端调用 DistributedFileSystem.create()，向 NameNode 发送 RPC 请求，请求创建新文件</li> <li>创建文件元数据：NameNode 进行权限及文件重名校验，校验通过后在命名空间创建一个新文件，并返回可上传信息</li> <li>写入数据块：流水线复制方式，客户端将文件分片，放入一个队列中，依次向 NameNode 申请数据块保存的 DataNode 节点
<ul><li>NameNode 根据网络拓扑和机架感知以及副本机制进行文件分配，返回可用的 DataNode 地址</li> <li>客户端将 DataNode 节点组成数据流管道，数据块（数据包为单位）发送到第一个节点，第一个节点再发送给第二个节点，依次类推</li></ul></li> <li>接收确认：当最后一个 DataNode 写好数据块后，就会返回一个确认包。最后一个数据节点发送给最后第二个数据节点以此类推，传回到第一个数据节点，再传回到客户端</li> <li>当一个块传输完成后, 客户端再次请求 NameNode 上传第二个块，重复3，4</li> <li>管道中所有的 DataNode 都保存完成后，调用 FileSystem.close() 关闭数据流</li></ol> <blockquote><p>客户端上传文件时与 DataNode 建立数据流管道，管道的正方向是客户端向 DataNode 发送的数据包，管道反向是 DataNode 向客户端发送 Ack 确认应答。
当 DataNode 突然挂掉了，客户端接收不到这个 DataNode 发送的 Ack 确认，客户端会通知 NameNode，NameNode 检查该块的副本与规定的不符，NameNode 会通知 DataNode 去复制副本，并将挂掉的 DataNode 作下线处理，不再让它参与文件上传与下载</p></blockquote> <blockquote><p>注：HDFS 文件写入时是串行写入，数据包按数据流管道依次发送给 DataNode；而 HDFS 文件读取是并行读取块所在的节点。</p> <p>扩展：网络拓补结构中的节点距离概念：两个节点到达最近的共同祖先的距离总和，以带宽作为距离的衡量标准</p></blockquote> <h2 id="hdfs-多副本机制"><a href="#hdfs-多副本机制" class="header-anchor">#</a> HDFS 多副本机制</h2> <p>文件存储成一系列数据块，数据块大小：Hadoop 1.0 默认为 64MB，Hadoop 2.0/3.0 默认为 128MB；通过副本冗余容错机制来保证数据的高可靠，文件的所有数据块都会有副本。
副本的存放是 HDFS 可靠性和性能的关键，副本存放策略：HDFS 采用一种称为<code>机架感知</code>(rack-aware)的策略来改进数据的可靠性、可用性和网络带宽的利用率。</p> <p>HDFS 机架感知存放策略：将一个副本存放在本地机架的节点上，一个副本存放在同一机架的另一个节点上，最后一个副本存放在不同机架的节点上。（副本系数默认为 3）</p> <blockquote><p>副本并不是均匀分布在不同的机架上，而是三分之一的副本在一个节点上，三分之二的副本在一个机架上，这一策略在不损害数据可靠性和读取性能的情况下改进了写的性能。
为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本。</p></blockquote> <h2 id="hdfs-数据组织"><a href="#hdfs-数据组织" class="header-anchor">#</a> HDFS 数据组织</h2> <ul><li>数据块存储：文件分块写入，一次写入、多次读取</li> <li>流水线复制：数据以流水线的方式从前一个 DataNode 复制到下一个 DataNode</li> <li>文件回收站：回收站目录 /trash，HDFS 会自动删除回收站中的保留时间超过 6 小时的文件</li></ul> <blockquote><p>文件分块：一个节点无法存储超大文件；网络传输时万一宕掉，可以小部分重传；简化了存储管理，同时元数据就不需要和块一同存储了，用一个单独的系统就可以管理这些块的元数据，所以块是 HDFS 中最基本的存储单位。</p></blockquote> <h2 id="hdfs-回收站"><a href="#hdfs-回收站" class="header-anchor">#</a> HDFS 回收站</h2> <p>HDFS 为每个用户创建一个回收站目录：/user/用户名/.Trash/，回收站默认不开启，其中文件目录有生存周期，开启配置：</p> <div class="language-bash core-site.xml line-numbers-mode"><pre class="language-bash"><code><span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>fs.trash.interval<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token number">144</span><span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">&gt;</span>     <span class="token comment"># 生存周期，单位分钟</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><blockquote><p>若删除文件超过回收站大小，则提示删除失败，需通过参数 -skipTrash 指示删除文件不会进回收站</p></blockquote> <h2 id="hdfs-文件限额"><a href="#hdfs-文件限额" class="header-anchor">#</a> HDFS 文件限额</h2> <p>HDFS 文件的限额配置允许以文件个数，或者文件大小来限制在某个目录下上传的文件数量或者文件内容总量。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs dfs -count -q -h /user/root/dir1				<span class="token comment"># 查看配额信息</span>
hdfs dfsadmin -setQuota <span class="token number">2</span> <span class="token function">dir</span> 						<span class="token comment"># 文件数量限额：给该文件夹下面设置最多上传两个文件</span>
hdfs dfsadmin -clrQuota /user/root/dir 				<span class="token comment"># 清除文件数量限额</span>
hdfs dfsadmin -setSpaceQuota 4k /user/root/dir 		<span class="token comment"># 空间大小限额：限制空间大小4KB</span>
hdfs dfsadmin -clrSpaceQuota /user/root/dir 		<span class="token comment"># 清除空间大小限额</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="hdfs-安全模式"><a href="#hdfs-安全模式" class="header-anchor">#</a> HDFS 安全模式</h2> <p>在集群启动时，HDFS 都会检查集群中文件信息是否完整，该时间段内是不允许对集群有修改操作的，等 HDFS 自检完毕，就会自动退出安全模式。
举例：在三副本机制下，在 DataNode 上就应该有三副本存在，假设只存在两个副本，则副本率为 2/3=0.666，小于默认副本率 0.999，因此系统会自动的复制副本到其他 DataNode，使得副本率不小于 0.999；如果系统中有五副本，超过三副本，那么系统也会删除多余的两个副本。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@xzx-hadoop-master /<span class="token punctuation">]</span><span class="token comment"># hdfs dfsadmin -safemode get     # 查看当前安全模式状态</span>
<span class="token punctuation">[</span>root@xzx-hadoop-master /<span class="token punctuation">]</span><span class="token comment"># hdfs dfsadmin -safemode leave   # 强制退出安全模式</span>
<span class="token punctuation">[</span>root@xzx-hadoop-master /<span class="token punctuation">]</span><span class="token comment"># hdfs dfsadmin -safemode enter   # 手动进入安全模式</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="hdfs-健壮性"><a href="#hdfs-健壮性" class="header-anchor">#</a> HDFS 健壮性</h2> <p>HDFS 主要目标是即使在出错的情况下也要保证数据存储的可靠性；HDFS 提供多种错误恢复手段，保障了系统的健壮性。</p> <ul><li>心跳检测：NameNode 检测 DataNaode 的状态</li> <li>副本重新复制：NameNode 检测数据块副本数，若低于指定值，则启动副本复制操作</li> <li>集群均衡： HDFS 架构支持数据均衡策略</li> <li>数据完整性：通过校验和(checkSum)检查，当创建新文件时，会计算文件每个数据块的校验和，并将校验和作为一个单独的隐藏文件保存在同一个 HDFS 名字空间下</li> <li>元数据磁盘错误：NameNode 可以配置成支持维护多个 FsImage/Editlog 的副本</li> <li>快照：支持某一特定时刻的数据的复制备份</li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">2022/6/8</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="prev">
          Hadoop概述及分布式集群容器化部署
        </a></span> <span class="next"><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html">
          分布式并行计算 MapReduce 概述及原理
        </a>
        →
      </span></p></div> </main></div> <aside class="page-sidebar"> <div class="page-side-toolbar"><div class="option-box-toc-fixed"><div class="toc-container-sidebar"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:650px"><div style="font-weight:bold;text-align:center;">分布式文件系统 HDFS 体系架构及原理</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-主从体系架构" class="toc-sidebar-link">HDFS 主从体系架构</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#namenode" class="toc-sidebar-link">NameNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#secondarynamenode" class="toc-sidebar-link">SecondaryNameNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#datanode" class="toc-sidebar-link">DataNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-high-available-ha-高可用" class="toc-sidebar-link">HDFS High Available（HA） 高可用</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#namenode-元数据共享存储方案" class="toc-sidebar-link">NameNode 元数据共享存储方案</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#脑裂问题" class="toc-sidebar-link">脑裂问题</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-federation-高扩展" class="toc-sidebar-link">HDFS Federation 高扩展</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-文件读写流程" class="toc-sidebar-link">HDFS 文件读写流程</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-读流程" class="toc-sidebar-link">HDFS 读流程</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-写流程" class="toc-sidebar-link">HDFS 写流程</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-多副本机制" class="toc-sidebar-link">HDFS 多副本机制</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-数据组织" class="toc-sidebar-link">HDFS 数据组织</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-回收站" class="toc-sidebar-link">HDFS 回收站</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-文件限额" class="toc-sidebar-link">HDFS 文件限额</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-安全模式" class="toc-sidebar-link">HDFS 安全模式</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-健壮性" class="toc-sidebar-link">HDFS 健壮性</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div> <div class="option-box-toc-over"><img src="/images/system/toc.png" class="nozoom"> <span class="show-txt">目录</span> <div class="toc-container"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:550px"><div style="font-weight:bold;text-align:center;">分布式文件系统 HDFS 体系架构及原理</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-主从体系架构" class="toc-sidebar-link">HDFS 主从体系架构</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#namenode" class="toc-sidebar-link">NameNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#secondarynamenode" class="toc-sidebar-link">SecondaryNameNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#datanode" class="toc-sidebar-link">DataNode</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-high-available-ha-高可用" class="toc-sidebar-link">HDFS High Available（HA） 高可用</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#namenode-元数据共享存储方案" class="toc-sidebar-link">NameNode 元数据共享存储方案</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#脑裂问题" class="toc-sidebar-link">脑裂问题</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-federation-高扩展" class="toc-sidebar-link">HDFS Federation 高扩展</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-文件读写流程" class="toc-sidebar-link">HDFS 文件读写流程</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-读流程" class="toc-sidebar-link">HDFS 读流程</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-写流程" class="toc-sidebar-link">HDFS 写流程</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-多副本机制" class="toc-sidebar-link">HDFS 多副本机制</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-数据组织" class="toc-sidebar-link">HDFS 数据组织</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-回收站" class="toc-sidebar-link">HDFS 回收站</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-文件限额" class="toc-sidebar-link">HDFS 文件限额</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-安全模式" class="toc-sidebar-link">HDFS 安全模式</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS-%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8E%9F%E7%90%86.html#hdfs-健壮性" class="toc-sidebar-link">HDFS 健壮性</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div></div>  </aside></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.cfd60917.js" defer></script><script src="/assets/js/4.8234885e.js" defer></script><script src="/assets/js/3.1429892b.js" defer></script><script src="/assets/js/22.80eaa289.js" defer></script>
  </body>
</html>
