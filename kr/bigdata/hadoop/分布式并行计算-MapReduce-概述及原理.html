<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>分布式并行计算 MapReduce 概述及原理 | Keep Running</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.png">
    <script charset="utf-8" async="async" src="/js/jquery.min.js"></script>
    <script charset="utf-8" async="async" src="/js/global.js"></script>
    <script charset="utf-8" async="async" src="/js/fingerprint2.min.js"></script>
    <meta name="description" content="">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <meta name="apple-mobile-web-app-capable" content="yes">
    
    <link rel="preload" href="/assets/css/0.styles.42b858ce.css" as="style"><link rel="preload" href="/assets/js/app.cfd60917.js" as="script"><link rel="preload" href="/assets/js/4.8234885e.js" as="script"><link rel="preload" href="/assets/js/3.1429892b.js" as="script"><link rel="preload" href="/assets/js/21.fe05d239.js" as="script"><link rel="prefetch" href="/assets/js/10.0f0de338.js"><link rel="prefetch" href="/assets/js/11.0c47d372.js"><link rel="prefetch" href="/assets/js/12.b45ce082.js"><link rel="prefetch" href="/assets/js/13.f2032214.js"><link rel="prefetch" href="/assets/js/14.0a8927b2.js"><link rel="prefetch" href="/assets/js/15.9ab1d206.js"><link rel="prefetch" href="/assets/js/16.f03f2e40.js"><link rel="prefetch" href="/assets/js/17.c6bbe2be.js"><link rel="prefetch" href="/assets/js/18.e08bb862.js"><link rel="prefetch" href="/assets/js/19.c00af7cb.js"><link rel="prefetch" href="/assets/js/20.35396483.js"><link rel="prefetch" href="/assets/js/22.80eaa289.js"><link rel="prefetch" href="/assets/js/23.bce5e854.js"><link rel="prefetch" href="/assets/js/24.fa104861.js"><link rel="prefetch" href="/assets/js/25.2c725be9.js"><link rel="prefetch" href="/assets/js/26.fc7addb7.js"><link rel="prefetch" href="/assets/js/27.fc831a66.js"><link rel="prefetch" href="/assets/js/28.3784f580.js"><link rel="prefetch" href="/assets/js/29.7e78aa5c.js"><link rel="prefetch" href="/assets/js/30.b074fddd.js"><link rel="prefetch" href="/assets/js/31.059ebf27.js"><link rel="prefetch" href="/assets/js/32.12570018.js"><link rel="prefetch" href="/assets/js/33.d0dc971f.js"><link rel="prefetch" href="/assets/js/34.c9b46696.js"><link rel="prefetch" href="/assets/js/35.77a81c6a.js"><link rel="prefetch" href="/assets/js/36.6048e328.js"><link rel="prefetch" href="/assets/js/37.b9f285de.js"><link rel="prefetch" href="/assets/js/38.ac5a2abf.js"><link rel="prefetch" href="/assets/js/39.97ca52cb.js"><link rel="prefetch" href="/assets/js/40.1689d33f.js"><link rel="prefetch" href="/assets/js/41.4d2d8182.js"><link rel="prefetch" href="/assets/js/42.8647a8ff.js"><link rel="prefetch" href="/assets/js/43.f867a280.js"><link rel="prefetch" href="/assets/js/44.a51272ee.js"><link rel="prefetch" href="/assets/js/45.c31e6474.js"><link rel="prefetch" href="/assets/js/46.fe85ae54.js"><link rel="prefetch" href="/assets/js/47.dc8a97d4.js"><link rel="prefetch" href="/assets/js/48.c97f7726.js"><link rel="prefetch" href="/assets/js/49.ac219d14.js"><link rel="prefetch" href="/assets/js/5.963fada3.js"><link rel="prefetch" href="/assets/js/50.926ecfa5.js"><link rel="prefetch" href="/assets/js/51.e776b5b1.js"><link rel="prefetch" href="/assets/js/52.4938314c.js"><link rel="prefetch" href="/assets/js/53.6b4d7266.js"><link rel="prefetch" href="/assets/js/54.bfaf622b.js"><link rel="prefetch" href="/assets/js/55.c6d160b9.js"><link rel="prefetch" href="/assets/js/56.31f6843c.js"><link rel="prefetch" href="/assets/js/57.55cbf7b8.js"><link rel="prefetch" href="/assets/js/58.8174871d.js"><link rel="prefetch" href="/assets/js/59.3eee2bde.js"><link rel="prefetch" href="/assets/js/6.b2e36a75.js"><link rel="prefetch" href="/assets/js/60.233a32ed.js"><link rel="prefetch" href="/assets/js/61.defb83ac.js"><link rel="prefetch" href="/assets/js/62.442070cd.js"><link rel="prefetch" href="/assets/js/63.cc121456.js"><link rel="prefetch" href="/assets/js/64.c8f83f5d.js"><link rel="prefetch" href="/assets/js/65.b9bc8c1c.js"><link rel="prefetch" href="/assets/js/7.fb6689bf.js"><link rel="prefetch" href="/assets/js/8.e390cc6b.js"><link rel="prefetch" href="/assets/js/9.c03c9dfe.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.db8a86c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.42b858ce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Keep Running</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="sidebar-link">Hadoop概述及分布式集群容器化部署</a></li><li><a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="sidebar-link">分布式文件系统 HDFS 体系架构及原理</a></li><li><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html" class="active sidebar-link">分布式并行计算 MapReduce 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html" class="sidebar-link">集群资源管理与调度平台 YARN 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/MapReduce-实例-WordCount.html" class="sidebar-link">MapReduce 经典案例：WordCount</a></li><li><a href="/kr/bigdata/hadoop/HDFS-3-X-纠删码.html" class="sidebar-link">HDFS 3.X 纠删码</a></li><li><a href="/kr/bigdata/hadoop/大数据生态圈与离线实时数据平台实践.html" class="sidebar-link">大数据生态圈与离线实时数据平台实践</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hive/分布式数据仓库-Hive.html" class="sidebar-link">分布式数据仓库 Hive</a></li><li><a href="/kr/bigdata/hive/Hive-SQL.html" class="sidebar-link">Hive SQL 执行计划|数据倾斜|性能优化</a></li><li><a href="/kr/bigdata/hive/HiveSQL-编译过程.html" class="sidebar-link">Hive 工作原理：Hive SQL 编译过程</a></li><li><a href="/kr/bigdata/hive/Hive-function.html" class="sidebar-link">Hive Function</a></li><li><a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="sidebar-link">Hive SQL Examples</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="sidebar-link">Spark 概述与集群部署模式</a></li><li><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html" class="sidebar-link">Spark RDD 弹性分布式数据集</a></li><li><a href="/kr/bigdata/spark/Spark-运行架构.html" class="sidebar-link">Spark 运行架构及作业提交流程</a></li><li><a href="/kr/bigdata/spark/Spark-Streaming.html" class="sidebar-link">Spark Streaming</a></li><li><a href="/kr/bigdata/spark/Spark-sql.html" class="sidebar-link">Spark SQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Other</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/Canal-MySQL-binlog-增量订阅与消费组件.html" class="sidebar-link">Canal：MySQL Binlog 增量订阅与消费组件</a></li><li><a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="sidebar-link">Sqoop 数据迁移工具</a></li><li><a href="/kr/bigdata/Flume-基本架构及应用场景.html" class="sidebar-link">Flume 基本架构及应用场景</a></li><li><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html" class="sidebar-link">Azkaban 编译镜像及基本使用</a></li><li><a href="/kr/bigdata/Maxwell.html" class="sidebar-link">Maxwell</a></li><li><a href="/kr/bigdata/Elaticsearch.html" class="sidebar-link">Elaticsearch</a></li><li><a href="/kr/bigdata/大数据可视化交互平台-Hue.html" class="sidebar-link">大数据可视化交互平台 Hue</a></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-default-content content__default"><h1 id="分布式并行计算-mapreduce-概述及原理"><a href="#分布式并行计算-mapreduce-概述及原理" class="header-anchor">#</a> 分布式并行计算 MapReduce 概述及原理</h1> <blockquote><p>MapReduce 是一种并行分布式计算模型，凭借其强大的并行计算能力和本地优先计算性，非常适合用于大规模数据集的并行计算。“Map”（映射）和“Reduce”（归约）是它的主要思想；实现是指定一个 Map（映射）函数，实现任务的分配，指定并发的 Reduce（归约）函数，用来任务的汇总</p> <p>MapReduce 改变了组织大规模数据计算的方式，它代表了第一个有别于冯·诺依曼结构的计算模型，是在集群规模而非单个机器上组织大规模计算的新的抽象模型上的第一个重大突破，是到目前为止所见到的最为成功的基于大规模计算资源的计算模型。</p></blockquote> <p>MapReduce 是一种面向大规模数据处理的并行计算模型、框架和平台，将运行于大规模集群上的复杂并行计算过程高度地抽象为两个函数：Map和Reduce，三层含义：</p> <ul><li>MapReduce 是一个并行程序设计模型与方法</li> <li>MapReduce 是一个基于集群的高性能并行计算平台</li> <li>MapReduce 是一个并行计算与运行软件框架</li></ul> <p>主要功能：</p> <ul><li>数据划分/任务调度：划分数据块，并负责分配调度计算节点处理数据块，及监控节点执行状态</li> <li>数据/代码互定位：为了减少数据通信，一个基本原则是本地化数据处理，即代码向数据迁移</li> <li>系统优化：系统计算性能优化处理，如对最慢计算任务采用多备份执行、选最快完成者作为结果</li> <li>出错检测和恢复：能检测并隔离出错节点，调度分配新节点接管出错节点的计算任务，还将用多备份冗余存储机制提高数据存储的可靠性，并能及时检测和恢复出错的数据</li></ul> <p>优缺点：</p> <ul><li>易于编程：通过简单地实现一些接口，就可以完成一个 MapReduce 分布式计算程序</li> <li>良好扩展：当计算资源无法满足时，可以通过简单的增加机器来扩展集群的计算能力</li> <li>高容错性：MapReduce 分布式程序能够部署在廉价机器上，这就要求它具有高容错性</li> <li>海量数据的离线处理：可以实现上千台服务器集群并发处理海量数据</li> <li>不擅长/不适合：实时计算、流式计算、DAG（有向无环图）计算</li></ul> <h2 id="编程模型"><a href="#编程模型" class="header-anchor">#</a> 编程模型</h2> <p>一个完整 MapReduce 作业由 n 个 Map 任务和 m 个 Reduce 任务组成，MapReduce 作业的并行计算过程是先将待处理数据切分为 n 个独立数据集，然后分别交由 n 个 Map 任务进行计算，将计算结果进行分区排序之后持久化到 Map 任务所在机器磁盘，之后由 Reduce 任务读取 Map 任务的输出结果并进行聚合计算。
MapReduce 作业可以容忍 Map 任务或者 Reduce 任务失败，针对运行失败的任务会进行重试，而且为了避免出现木桶效应，可以开启推测执行机制，即针对运行时间比平均时间慢的任务再启动一个运行实例，等某个运行实例任务运行结束之后将其他任务杀掉，避免因为某个任务运行时间较长而延长整个作业的执行时间。
<img src="/images/kr/bigdata/hadoop/MapReduce-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt=""></p> <ul><li>Split：MapReduce 会根据输入文件计算输入分片，每个输入分片对应一个 Map 任务
<ul><li>输入分片存储的并非数据本身，而是一个分片长度和一个记录数据位置的数组</li> <li>输入分片与 HDFS 块数据密切相关</li></ul></li> <li>Map：映射，调用 Map 函数处理接收到的分片，逐行执行并输出键值对</li> <li>Combiner：该阶段可选，是 Map 计算后的一种本地化 Reduce 操作
<ul><li>在 Map 计算出中间结果前做一个简单的合并重复键值的操作</li> <li>该阶段是有风险的，使用原则是 Combiner 的输出不会影响到 Reduce 计算的最终输入</li></ul></li> <li>Shuffle：将 Map 输出进一步处理并交给 Reduce，决定了 Map 输出如何高效地传送给 Reduce
<ul><li>Shuffle 阶段包含在 Map 和 Reduce 两个阶段中</li> <li>Map-Shuffle 阶段是对 Map 的结果进行分区、排序和分隔，再将属于同一个分区的输出合并写到磁盘上，同时按照不同分区划分发送给对应的 Reduce 的整个过程</li> <li>Reduce-Shuffle 阶段将各个 Map 输出的同一个分区划分的输出进行合并，再对合并的结果进行排序，最后交给 Reduce 处理的整个过程</li></ul></li> <li>Reduce：调用 Reduce 函数，将具有相同 key 的 value 进行处理后再输出新键值对作为最终结果</li></ul> <h3 id="分片机制"><a href="#分片机制" class="header-anchor">#</a> 分片机制</h3> <p>数据块：物理上的数据分块，是 HDFS 的数据存储单位
数据分片：逻辑上的数据分片，是 MapReduce 计算输入数据的单位
MapTask 并行度与分片机制：</p> <ul><li>MapTask 并行度决定 Map 阶段任务处理并发度，进而影响整个 Job 处理速度</li> <li>一个 Job 的 Map 并行度由客户端在提交 Job 时的分片数决定，一个分片启动一个 MapTask</li> <li>简单按照文件内容长度进行分片，默认情况下，数据分片大小为数据块大小</li> <li>分片时不考虑数据集整体，而是逐个针对每一个文件单独分片</li></ul> <p>FileInputFormat 接口实现类：
TextInputFormat：</p> <h3 id="map-shuffle-阶段"><a href="#map-shuffle-阶段" class="header-anchor">#</a> Map-Shuffle 阶段</h3> <ul><li>Map 输出时会在内存里开启一个环形内存缓存区，并为 Map 输出操作启动一个守护线程</li> <li>分隔：若缓存区内存达到了阈值（默认 80%），则该守护线程会把这 80% 内存区内容写到磁盘上，另外 20% 内存可以供 Map 输出继续使用</li> <li>写入磁盘和写入内存操作是互不干扰的，若缓存区满了，那么 Map 就会阻塞写入内存操作，待写入磁盘操作完成后再继续执行写入内存操作</li> <li>缓存区内容分隔到磁盘前，会首先进行分区操作，分区数目由 Reduce 数目决定，然后对每个分区，后台线程还会按照键值对将需要写出的数据进行排序</li> <li>若配置 Combiner 函数，则进行 Combiner 操作，以使更少地数据被写入磁盘并发送给 Reducer</li> <li>每次分隔操作都会生成一个分隔文件，全部 Map 输出完成后，可能会有很多分隔文件</li> <li>因此在 Map 任务结束前，还要进行合并操作，即将这些分隔文件按照分区合并为单独文件</li> <li>在合并过程中，同样也会进行排序，若定义 Combiner 函数，则进行 Combiner 操作</li> <li>至此，Map 阶段的所有工作都已结束，最终生成的文件也会存放在某个本地目录内</li> <li>每个 Reduce 不断地获取 Map 是否完成的信息，若 Reduce 得到通知，获知某个 Map 执行完成，Reduce-Shuffle 阶段便开始启动</li></ul> <h3 id="reduce-shuffle-阶段"><a href="#reduce-shuffle-阶段" class="header-anchor">#</a> Reduce-Shuffle 阶段</h3> <p>可以分为三个子阶段：Copy Map 输出、Merge 阶段和 Reduce 处理</p> <ul><li>Copy Map 输出：Reduce 任务启动 Copy 线程，通过 HTTP 请求复制 Map 输出文件</li> <li>Merge 阶段：复制过来的数据会首先放入内存缓冲区中进行合并</li> <li>Reduce 处理：不断合并后，最后会生成一个最终结果（可能在内存，也可能在磁盘），至此 Reduce 输入准备完毕，下一步就是 Reduce 操作</li></ul> <p>一个完整 MapReduce 程序在分布式运行时有三类实例进程（MR 程序运行在 YARN 上）</p> <ul><li>MrAppMaster：负责整个程序的过程调度及状态协调</li> <li>MapTask：负责 Map 阶段的整个数据处理流程</li> <li>ReduceTask：负责 Reduce 阶段的整个数据处理流程</li></ul> <h2 id="运行机制"><a href="#运行机制" class="header-anchor">#</a> 运行机制</h2> <h3 id="maptask-工作机制"><a href="#maptask-工作机制" class="header-anchor">#</a> MapTask 工作机制</h3> <p><img src="/images/kr/bigdata/hadoop/MapTask-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" alt=""></p> <ol><li>Read 阶段：MapTask 通过 RecordReader(默认 LineRecordReader)，从 InputSplit 中以 \n 分隔符进行读取，读取每一行并解析出成 &lt;k,v&gt;
<ul><li>k 表示每行首字符偏移值，v 表示这一行文本内容</li></ul></li> <li>Map 阶段：该阶段主要是将解析出的 &lt;k,v&gt; 交给用户编写的 map() 函数处理，并产生新的 &lt;k,v&gt;</li> <li>Collect 阶段：Map 处理完成后，一般调用 OutputCollector.collect() 进行数据收集
<ul><li>并调用 HashPartitioner 进行分区处理，同时写入一个环形内存缓冲区中</li> <li>Partitioner 接口：根据 k/v 及 Reduce 数量决定当前这对输出数据应该交由哪个 ReduceTask 处理，默认 key hash 后再以 Reduce 数量取模</li></ul></li> <li>Spill 阶段：当环形缓冲区满80%后，MapReduce 会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序（先对partition排序，在对key排序保证每个分区内有序），并在必要时对数据进行合并压缩操作。</li></ol> <p>①利用快速排序算法对缓存区内的数据进行排序，排序方式是先按照分区编号排序，然后按照key排序。经过排序后数据以分区为单位聚集在一起，且统一分区内所有数据按照key有序；</p> <p>②按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N代表当前溢写次数）中。如果用户设置了Combiner则写入文件之前，对每个分区中的数据进行一次聚集操作；</p> <p>③将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spliiN.out.index中</p> <ol start="5"><li>Combine 阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</li></ol> <p>所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相对应的索引文件output/file.out.index</p> <p>在文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多伦递归合并的方式，每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件</p> <p>让每个MapTask最终只会生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销</p> <h3 id="reducetask-工作机制"><a href="#reducetask-工作机制" class="header-anchor">#</a> ReduceTask 工作机制</h3> <h3 id="shuffle-机制"><a href="#shuffle-机制" class="header-anchor">#</a> Shuffle 机制</h3> <h2 id="编程规范"><a href="#编程规范" class="header-anchor">#</a> 编程规范</h2> <ul><li>Map 阶段
<ul><li>设置 InputFormat 类, 将数据切分为 <strong>(K1，V1)</strong> 对</li> <li>自定义 Map 逻辑, 将 <strong>(K1，V1)</strong> 对转换成 <strong>(K2，V2)</strong> 对，输出结果</li></ul></li> <li>Shuffle 阶段
<ul><li>对输出的 <strong>(K2，V2)</strong> 对进行<strong>分区</strong></li> <li>对不同分区的数据按照相同 Key <strong>排序</strong></li> <li>(可选) 对分组过的数据初步<strong>规约</strong>, 降低数据的网络拷贝</li> <li>对数据进行<strong>分组</strong>, 相同 Key 的 Value 放入一个集合中</li></ul></li> <li>Reduce 阶段
<ul><li>对多个 Map 结果进行排序合并, 编写 Reduce 函数实现对输入的 Key-Value 进行处理, 转为 <strong>(K3，V3)</strong> 输出</li> <li>设置 OutputFormat 处理并保存 Reduce 输出的 Key-Value 数据</li></ul></li></ul> <h3 id="mapper-类"><a href="#mapper-类" class="header-anchor">#</a> Mapper 类</h3> <div class="language-java Mapper.java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// hadoop-3.2.2</span>
<span class="token annotation punctuation">@InterfaceAudience.Public</span>
<span class="token annotation punctuation">@InterfaceStability.Stable</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span>KEYIN<span class="token punctuation">,</span> VALUEIN<span class="token punctuation">,</span> KEYOUT<span class="token punctuation">,</span> VALUEOUT<span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
  <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">class</span> <span class="token class-name">Context</span> <span class="token keyword">implements</span> <span class="token class-name">MapContext</span><span class="token generics"><span class="token punctuation">&lt;</span>KEYIN<span class="token punctuation">,</span>VALUEIN<span class="token punctuation">,</span>KEYOUT<span class="token punctuation">,</span>VALUEOUT<span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token comment">// Mapper 类当中的初始化方法</span>
  <span class="token punctuation">}</span>
  <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">&quot;unchecked&quot;</span><span class="token punctuation">)</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">KEYIN</span> key<span class="token punctuation">,</span> <span class="token class-name">VALUEIN</span> value<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span>KEYOUT<span class="token punctuation">)</span> key<span class="token punctuation">,</span> <span class="token punctuation">(</span>VALUEOUT<span class="token punctuation">)</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 读取每一行数据，调用该方法处理</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">cleanup</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token comment">// 整个 maptask 执行完成之后，会马上调用该方法，主要是用于做一些清理工作，例如连接的断开，资源的关闭等等</span>
  <span class="token punctuation">}</span>
  <span class="token comment">// 更精确地控制 MapTask 的执行</span>
  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token function">setup</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">nextKeyValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">map</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">getCurrentKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token punctuation">.</span><span class="token function">getCurrentValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
      <span class="token function">cleanup</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h3 id="reduce-类"><a href="#reduce-类" class="header-anchor">#</a> Reduce 类</h3> <div class="language-java Reduce.java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// hadoop-3.2.2</span>
<span class="token annotation punctuation">@Checkpointable</span>
<span class="token annotation punctuation">@InterfaceAudience.Public</span>
<span class="token annotation punctuation">@InterfaceStability.Stable</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span>KEYIN<span class="token punctuation">,</span>VALUEIN<span class="token punctuation">,</span>KEYOUT<span class="token punctuation">,</span>VALUEOUT<span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
  <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">class</span> <span class="token class-name">Context</span> <span class="token keyword">implements</span> <span class="token class-name">ReduceContext</span><span class="token generics"><span class="token punctuation">&lt;</span>KEYIN<span class="token punctuation">,</span>VALUEIN<span class="token punctuation">,</span>KEYOUT<span class="token punctuation">,</span>VALUEOUT<span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token comment">// Reduce 类的初始化方法</span>
  <span class="token punctuation">}</span>
  <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">&quot;unchecked&quot;</span><span class="token punctuation">)</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">KEYIN</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span>VALUEIN<span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token comment">// 处理从 MapTask 发送过来的数据</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>VALUEIN value<span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span>KEYOUT<span class="token punctuation">)</span> key<span class="token punctuation">,</span> <span class="token punctuation">(</span>VALUEOUT<span class="token punctuation">)</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">cleanup</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token comment">// 整个 Reducetask 执行完成之后，会马上调用该方法，主要是用于做一些清理工作，例如连接的断开，资源的关闭等等</span>
  <span class="token punctuation">}</span>
  <span class="token comment">// 更精确地控制 ReduceTask 的执行</span>
  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token function">setup</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">nextKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">reduce</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">getCurrentKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token punctuation">.</span><span class="token function">getValues</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// If a back up store is used, reset it</span>
        <span class="token class-name">Iterator</span><span class="token generics"><span class="token punctuation">&lt;</span>VALUEIN<span class="token punctuation">&gt;</span></span> iter <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getValues</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>iter <span class="token keyword">instanceof</span> <span class="token class-name">ReduceContext<span class="token punctuation">.</span>ValueIterator</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
          <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">ReduceContext<span class="token punctuation">.</span>ValueIterator</span><span class="token generics"><span class="token punctuation">&lt;</span>VALUEIN<span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>iter<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">resetBackupStore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
      <span class="token function">cleanup</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br></div></div><h2 id="运行模式"><a href="#运行模式" class="header-anchor">#</a> 运行模式</h2> <h3 id="本地运行模式"><a href="#本地运行模式" class="header-anchor">#</a> 本地运行模式</h3> <div class="language-properties line-numbers-mode"><pre class="language-properties"><code><span class="token comment"># 本地运行模式：MapReduce 程序是被提交给 LocalJobRunner 在本地以单进程形式运行，而处理的数据及输出结果可以在本地文件系统，也可以在 hdfs 上</span>
<span class="token comment"># 本地模式非常便于进行业务逻辑的 debug，只要在 idea 中打断点即可</span>
<span class="token comment"># 本地运行模式配置参数</span>
<span class="token key attr-name">mapreduce.framework.name</span><span class="token punctuation">=</span><span class="token value attr-value">local</span>
<span class="token key attr-name">yarn.resourcemanager.hostname</span><span class="token punctuation">=</span><span class="token value attr-value">local</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="集群运行模式"><a href="#集群运行模式" class="header-anchor">#</a> 集群运行模式</h3> <p>将 MapReduce 程序提交给 YARN 集群，分发到很多节点上并发执行，处理的数据和输出结果应该位于 hdfs 文件系统上，提交集群的实现：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 将程序打成 JAR 包，然后在集群的任意一个节点上用 hadoop 命令启动</span>
<span class="token function">yarn</span> jar hadoop_hdfs_operate-1.0-SNAPSHOT.jar cn.itcast.hdfs.demo1.JobMain
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="序列化与反序列化"><a href="#序列化与反序列化" class="header-anchor">#</a> 序列化与反序列化</h2> <ul><li>序列化：将内存对象转为字节序列，用于磁盘存储和网络传输</li> <li>反序列化：将字节序列转为内存对象，用于内存计算使用</li></ul> <p>Java 序列化是一个重量级序列化框架(Serializable)，一个对象被序列化后会附带额外的信息，不便于网络传输，Hadoop 开发了一套序列化机制(Writable)，特点：</p> <ul><li>紧凑：高效使用存储空间</li> <li>快速：读写数据额外开销小</li> <li>交互操作：支持多语言交互</li></ul> <p>Bean 对象的序列化和反序列化实现：</p> <ul><li>必须实现 Writable 接口</li> <li>反序列化时，需要反射调用空参构造函数，故必须有空参构造函数</li> <li>重写序列化方法和方序列化方法（顺序完全一致）</li> <li>若想把结果显示在文件中，需重写 toString()</li> <li>若 Bean 对象放在 key 中传输，则需实现 Comparable 接口，因 Shuffle 阶段要求 key 必须能排序</li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">2022/6/8</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="prev">
          分布式文件系统 HDFS 体系架构及原理
        </a></span> <span class="next"><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html">
          集群资源管理与调度平台 YARN 概述及原理
        </a>
        →
      </span></p></div> </main></div> <aside class="page-sidebar"> <div class="page-side-toolbar"><div class="option-box-toc-fixed"><div class="toc-container-sidebar"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:650px"><div style="font-weight:bold;text-align:center;">分布式并行计算 MapReduce 概述及原理</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#编程模型" class="toc-sidebar-link">编程模型</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#分片机制" class="toc-sidebar-link">分片机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#map-shuffle-阶段" class="toc-sidebar-link">Map-Shuffle 阶段</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reduce-shuffle-阶段" class="toc-sidebar-link">Reduce-Shuffle 阶段</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#运行机制" class="toc-sidebar-link">运行机制</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#maptask-工作机制" class="toc-sidebar-link">MapTask 工作机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reducetask-工作机制" class="toc-sidebar-link">ReduceTask 工作机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#shuffle-机制" class="toc-sidebar-link">Shuffle 机制</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#编程规范" class="toc-sidebar-link">编程规范</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#mapper-类" class="toc-sidebar-link">Mapper 类</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reduce-类" class="toc-sidebar-link">Reduce 类</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#运行模式" class="toc-sidebar-link">运行模式</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#本地运行模式" class="toc-sidebar-link">本地运行模式</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#集群运行模式" class="toc-sidebar-link">集群运行模式</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#序列化与反序列化" class="toc-sidebar-link">序列化与反序列化</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div> <div class="option-box-toc-over"><img src="/images/system/toc.png" class="nozoom"> <span class="show-txt">目录</span> <div class="toc-container"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:550px"><div style="font-weight:bold;text-align:center;">分布式并行计算 MapReduce 概述及原理</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#编程模型" class="toc-sidebar-link">编程模型</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#分片机制" class="toc-sidebar-link">分片机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#map-shuffle-阶段" class="toc-sidebar-link">Map-Shuffle 阶段</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reduce-shuffle-阶段" class="toc-sidebar-link">Reduce-Shuffle 阶段</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#运行机制" class="toc-sidebar-link">运行机制</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#maptask-工作机制" class="toc-sidebar-link">MapTask 工作机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reducetask-工作机制" class="toc-sidebar-link">ReduceTask 工作机制</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#shuffle-机制" class="toc-sidebar-link">Shuffle 机制</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#编程规范" class="toc-sidebar-link">编程规范</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#mapper-类" class="toc-sidebar-link">Mapper 类</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#reduce-类" class="toc-sidebar-link">Reduce 类</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#运行模式" class="toc-sidebar-link">运行模式</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#本地运行模式" class="toc-sidebar-link">本地运行模式</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#集群运行模式" class="toc-sidebar-link">集群运行模式</a></li></ul></li><li><a href="/kr/bigdata/hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-MapReduce-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86.html#序列化与反序列化" class="toc-sidebar-link">序列化与反序列化</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div></div>  </aside></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.cfd60917.js" defer></script><script src="/assets/js/4.8234885e.js" defer></script><script src="/assets/js/3.1429892b.js" defer></script><script src="/assets/js/21.fe05d239.js" defer></script>
  </body>
</html>
