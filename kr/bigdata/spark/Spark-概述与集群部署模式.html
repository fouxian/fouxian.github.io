<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark 概述与集群部署模式 | Keep Running</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.png">
    <script charset="utf-8" async="async" src="/js/jquery.min.js"></script>
    <script charset="utf-8" async="async" src="/js/global.js"></script>
    <script charset="utf-8" async="async" src="/js/fingerprint2.min.js"></script>
    <meta name="description" content="">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <meta name="apple-mobile-web-app-capable" content="yes">
    
    <link rel="preload" href="/assets/css/0.styles.42b858ce.css" as="style"><link rel="preload" href="/assets/js/app.cfd60917.js" as="script"><link rel="preload" href="/assets/js/4.8234885e.js" as="script"><link rel="preload" href="/assets/js/3.1429892b.js" as="script"><link rel="preload" href="/assets/js/33.d0dc971f.js" as="script"><link rel="prefetch" href="/assets/js/10.0f0de338.js"><link rel="prefetch" href="/assets/js/11.0c47d372.js"><link rel="prefetch" href="/assets/js/12.b45ce082.js"><link rel="prefetch" href="/assets/js/13.f2032214.js"><link rel="prefetch" href="/assets/js/14.0a8927b2.js"><link rel="prefetch" href="/assets/js/15.9ab1d206.js"><link rel="prefetch" href="/assets/js/16.f03f2e40.js"><link rel="prefetch" href="/assets/js/17.c6bbe2be.js"><link rel="prefetch" href="/assets/js/18.e08bb862.js"><link rel="prefetch" href="/assets/js/19.c00af7cb.js"><link rel="prefetch" href="/assets/js/20.35396483.js"><link rel="prefetch" href="/assets/js/21.fe05d239.js"><link rel="prefetch" href="/assets/js/22.80eaa289.js"><link rel="prefetch" href="/assets/js/23.bce5e854.js"><link rel="prefetch" href="/assets/js/24.fa104861.js"><link rel="prefetch" href="/assets/js/25.2c725be9.js"><link rel="prefetch" href="/assets/js/26.fc7addb7.js"><link rel="prefetch" href="/assets/js/27.fc831a66.js"><link rel="prefetch" href="/assets/js/28.3784f580.js"><link rel="prefetch" href="/assets/js/29.7e78aa5c.js"><link rel="prefetch" href="/assets/js/30.b074fddd.js"><link rel="prefetch" href="/assets/js/31.059ebf27.js"><link rel="prefetch" href="/assets/js/32.12570018.js"><link rel="prefetch" href="/assets/js/34.c9b46696.js"><link rel="prefetch" href="/assets/js/35.77a81c6a.js"><link rel="prefetch" href="/assets/js/36.6048e328.js"><link rel="prefetch" href="/assets/js/37.b9f285de.js"><link rel="prefetch" href="/assets/js/38.ac5a2abf.js"><link rel="prefetch" href="/assets/js/39.97ca52cb.js"><link rel="prefetch" href="/assets/js/40.1689d33f.js"><link rel="prefetch" href="/assets/js/41.4d2d8182.js"><link rel="prefetch" href="/assets/js/42.8647a8ff.js"><link rel="prefetch" href="/assets/js/43.f867a280.js"><link rel="prefetch" href="/assets/js/44.a51272ee.js"><link rel="prefetch" href="/assets/js/45.c31e6474.js"><link rel="prefetch" href="/assets/js/46.fe85ae54.js"><link rel="prefetch" href="/assets/js/47.dc8a97d4.js"><link rel="prefetch" href="/assets/js/48.c97f7726.js"><link rel="prefetch" href="/assets/js/49.ac219d14.js"><link rel="prefetch" href="/assets/js/5.963fada3.js"><link rel="prefetch" href="/assets/js/50.926ecfa5.js"><link rel="prefetch" href="/assets/js/51.e776b5b1.js"><link rel="prefetch" href="/assets/js/52.4938314c.js"><link rel="prefetch" href="/assets/js/53.6b4d7266.js"><link rel="prefetch" href="/assets/js/54.bfaf622b.js"><link rel="prefetch" href="/assets/js/55.c6d160b9.js"><link rel="prefetch" href="/assets/js/56.31f6843c.js"><link rel="prefetch" href="/assets/js/57.55cbf7b8.js"><link rel="prefetch" href="/assets/js/58.8174871d.js"><link rel="prefetch" href="/assets/js/59.3eee2bde.js"><link rel="prefetch" href="/assets/js/6.b2e36a75.js"><link rel="prefetch" href="/assets/js/60.233a32ed.js"><link rel="prefetch" href="/assets/js/61.defb83ac.js"><link rel="prefetch" href="/assets/js/62.442070cd.js"><link rel="prefetch" href="/assets/js/63.cc121456.js"><link rel="prefetch" href="/assets/js/64.c8f83f5d.js"><link rel="prefetch" href="/assets/js/65.b9bc8c1c.js"><link rel="prefetch" href="/assets/js/7.fb6689bf.js"><link rel="prefetch" href="/assets/js/8.e390cc6b.js"><link rel="prefetch" href="/assets/js/9.c03c9dfe.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.db8a86c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.42b858ce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Keep Running</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="sidebar-link">Hadoop概述及分布式集群容器化部署</a></li><li><a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="sidebar-link">分布式文件系统 HDFS 体系架构及原理</a></li><li><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html" class="sidebar-link">分布式并行计算 MapReduce 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html" class="sidebar-link">集群资源管理与调度平台 YARN 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/MapReduce-实例-WordCount.html" class="sidebar-link">MapReduce 经典案例：WordCount</a></li><li><a href="/kr/bigdata/hadoop/HDFS-3-X-纠删码.html" class="sidebar-link">HDFS 3.X 纠删码</a></li><li><a href="/kr/bigdata/hadoop/大数据生态圈与离线实时数据平台实践.html" class="sidebar-link">大数据生态圈与离线实时数据平台实践</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hive/分布式数据仓库-Hive.html" class="sidebar-link">分布式数据仓库 Hive</a></li><li><a href="/kr/bigdata/hive/Hive-SQL.html" class="sidebar-link">Hive SQL 执行计划|数据倾斜|性能优化</a></li><li><a href="/kr/bigdata/hive/HiveSQL-编译过程.html" class="sidebar-link">Hive 工作原理：Hive SQL 编译过程</a></li><li><a href="/kr/bigdata/hive/Hive-function.html" class="sidebar-link">Hive Function</a></li><li><a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="sidebar-link">Hive SQL Examples</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="active sidebar-link">Spark 概述与集群部署模式</a></li><li><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html" class="sidebar-link">Spark RDD 弹性分布式数据集</a></li><li><a href="/kr/bigdata/spark/Spark-运行架构.html" class="sidebar-link">Spark 运行架构及作业提交流程</a></li><li><a href="/kr/bigdata/spark/Spark-Streaming.html" class="sidebar-link">Spark Streaming</a></li><li><a href="/kr/bigdata/spark/Spark-sql.html" class="sidebar-link">Spark SQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Other</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/Canal-MySQL-binlog-增量订阅与消费组件.html" class="sidebar-link">Canal：MySQL Binlog 增量订阅与消费组件</a></li><li><a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="sidebar-link">Sqoop 数据迁移工具</a></li><li><a href="/kr/bigdata/Flume-基本架构及应用场景.html" class="sidebar-link">Flume 基本架构及应用场景</a></li><li><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html" class="sidebar-link">Azkaban 编译镜像及基本使用</a></li><li><a href="/kr/bigdata/Maxwell.html" class="sidebar-link">Maxwell</a></li><li><a href="/kr/bigdata/Elaticsearch.html" class="sidebar-link">Elaticsearch</a></li><li><a href="/kr/bigdata/大数据可视化交互平台-Hue.html" class="sidebar-link">大数据可视化交互平台 Hue</a></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-default-content content__default"><h1 id="spark-概述与集群部署模式"><a href="#spark-概述与集群部署模式" class="header-anchor">#</a> Spark 概述与集群部署模式</h1> <blockquote><p>Spark 是一种由 Scala 开发的基于内存的快速、通用、可扩展的大数据分析计算引擎，Spark 的计算模式也是 MapReduce。</p></blockquote> <blockquote><p>Apache Spark - A unified analytics engine for large-scale data processing.</p> <p>Spark 是一种由 Scala 开发的基于内存的快速、通用、可扩展的大数据分析计算引擎。</p> <p>Hadoop 是由 Java 编写的，在分布式服务器集群上存储并计算海量数据的分布式计算引擎。</p> <p>Spark 和 Hadoop 的根本差异是多个作业间的数据通信问题：Spark 数据通信是基于内存，而 Hadoop 是基于磁盘。</p> <p>Spark 的计算模式也是 MapReduce，Spark 是对 MR 的优化。</p> <p>MR 中的 Map/Reduce Task 是 JVM 进程级别，每次启动都需要重新申请资源，而 Spark Task 是基于线程模型，复用线程池中的线程。</p></blockquote> <p><img src="/images/kr/bigdata/spark/Spark.png" alt=""></p> <p>Apache Spark 具有以下特点：</p> <ul><li>使用先进的 DAG 调度程序，查询优化器和物理执行引擎，以实现性能上的保证</li> <li>多语言支持，目前支持的有 Java，Scala，Python 和 R</li> <li>提供了 80 多个高级 API，可以轻松地构建应用程序</li> <li>支持批处理、交互式查询、实时流处理、机器学习、图计算和复杂的业务分析</li> <li>丰富的类库支持：包括 SQL，MLlib，GraphX 和 Spark Streaming 等库，并且可以无缝组合</li> <li>丰富的部署模式：支持本地模式和自带集群模式，支持在 Hadoop，Mesos，Kubernetes 上运行</li> <li>多数据源支持：支持访问 HDFS，Alluxio，Cassandra，HBase，Hive 等</li></ul> <h2 id="spark-核心组件"><a href="#spark-核心组件" class="header-anchor">#</a> Spark 核心组件</h2> <ul><li>Spark Core：Spark 最基础最核心的功能</li> <li>Spark SQL：用来操作结构化数据的组件</li> <li>Spark Streaming：针对实时数据进行流式计算的组件</li> <li>Spark MLlib：机器学习算法库</li> <li>Spark GraphX：面向图计算提供的框架与算法库</li></ul> <h3 id="spark-sql"><a href="#spark-sql" class="header-anchor">#</a> Spark SQL</h3> <p>Spark SQL 主要用于结构化数据的处理，其具有以下特点：</p> <ul><li>能够将 SQL 与 Spark 程序无缝混合，允许使用 SQL 或 DataFrame API 对结构化数据进行查询</li> <li>支持多种数据源，包括 Hive，Avro，Parquet，ORC，JSON 和 JDBC</li> <li>支持 HiveQL 语法以及用户自定义函数 (UDF)，允许访问现有的 Hive 仓库</li> <li>支持标准的 JDBC 和 ODBC 连接</li> <li>支持优化器，列式存储和代码生成等特性，以提高查询效率</li></ul> <h3 id="spark-streaming"><a href="#spark-streaming" class="header-anchor">#</a> Spark Streaming</h3> <p>Spark Streaming 主要用于快速构建可扩展、高吞吐量、高容错的流处理程序，支持从 HDFS，Flume，Kafka，Twitter 和 ZeroMQ 读取数据，并进行处理
<img src="/images/kr/bigdata/spark/spark-streaming-arch.png" alt=""></p> <p>Spark Streaming 的本质是微批处理，它将数据流进行极小粒度的拆分，拆分为多个批处理，从而达到接近于流处理的效果
<img src="/images/kr/bigdata/spark/spark-streaming-flow.png" alt=""></p> <h3 id="spark-mllib"><a href="#spark-mllib" class="header-anchor">#</a> Spark MLlib</h3> <p>MLlib 是 Spark 的机器学习赛算法库，其设计目标是使得机器学习变得简单且可扩展，它提供了以下工具：</p> <ul><li>常见的机器学习算法：如分类，回归，聚类和协同过滤</li> <li>特征化：特征提取，转换，降维和选择</li> <li>管道：用于构建，评估和调整 ML 管道的工具</li> <li>持久性：保存和加载算法，模型，管道数据</li> <li>实用工具：线性代数，统计，数据处理等</li></ul> <h3 id="spark-graphx"><a href="#spark-graphx" class="header-anchor">#</a> Spark GraphX</h3> <p>GraphX 是 Spark 中用于图形计算和图形并行计算的新组件。在高层次上，GraphX 通过引入一个新的图形抽象来扩展 RDD(一种具有附加到每个顶点和边缘的属性的定向多重图形)。为了支持图计算，GraphX 提供了一组基本运算符（如： subgraph，joinVertices 和 aggregateMessages）以及优化后的 Pregel API。此外，GraphX 还包括越来越多的图形算法和构建器，以简化图形分析任务。</p> <h2 id="作业提交"><a href="#作业提交" class="header-anchor">#</a> 作业提交</h2> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># Spark 所有模式均使用 spark-submit 命令提交作业</span>
bin/spark-submit 
    --class <span class="token operator">&lt;</span>main-class<span class="token operator">&gt;</span>            <span class="token comment"># 应用程序主入口类</span>
    --master <span class="token operator">&lt;</span>master-url<span class="token operator">&gt;</span>           <span class="token comment"># 集群的 Master Url：local[*]、spark://host:port、Yarn</span>
    --deploy-mode <span class="token operator">&lt;</span>deploy-mode<span class="token operator">&gt;</span>     <span class="token comment"># 部署模式</span>
    --executor-memory               <span class="token comment"># 指定每个 executor 可用内存</span>
    --total-executor-cores          <span class="token comment"># 指定所有 executor 使用的 CPU 核数量</span>
    --executor-cores                <span class="token comment"># 指定每个 executor 使用的 CPU 核数量</span>
    --conf <span class="token operator">&lt;</span>key<span class="token operator">&gt;=</span><span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>            <span class="token comment"># 可选配置  </span>
    <span class="token operator">&lt;</span>application-jar<span class="token operator">&gt;</span>               <span class="token comment"># Jar 包路径，集群环境下，必须都能被集群中所有节点访问</span>
    <span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span>         <span class="token comment"># 传递给主入口类的参数  </span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>deploy-mode 部署模式有两个可选参数：cluster、client（默认），在 Spark On Yarn 模式下：</p> <ul><li>cluster：Spark Drvier 在应用程序的 Master 进程内运行，该进程由集群上的 YARN 管理，提交作业的客户端可以在启动应用程序后关闭，适用于生产环境</li> <li>client：Spark Drvier 在提交作业的客户端进程中运行，Master 进程仅用于从 YARN 请求资源，适用于交互、调试，希望立即看到 app 输出</li></ul> <p>master-url 的可选参数：</p> <ul><li>local：使用一个线程本地运行 Spark</li> <li>local[K]：使用 K 个 worker 线程本地运行 Spark</li> <li>local[K,F]：使用 K 个 worker 线程本地运行 Spark, 第二个参数为 Task 的失败重试次数</li> <li>local[*]：使用与 CPU 核心数一样的线程数本地运行 Spark</li> <li>local[*,F]：使用与 CPU 核心数一样的线程数本地运行 Spark，第二个参数为 Task 的失败重试次数</li> <li>spark://HOST:PORT：连接至指定的 standalone 集群的 master 节点，端口号默认是 7077</li> <li>spark://HOST1:PORT1,HOST2:PORT2：如果 standalone 集群采用 Zookeeper 实现高可用，则必须包含由 zookeeper 设置的所有 master 主机地址</li> <li>mesos://HOST:PORT：连接至给定的 Mesos 集群，端口默认是 5050。对于使用了 ZooKeeper 的 Mesos cluster 来说，使用 mesos://zk://... 来指定地址，使用 --deploy-mode cluster 模式来提交</li> <li>yarn：连接至一个 YARN 集群，集群由配置的 HADOOP_CONF_DIR 或者 YARN_CONF_DIR 来决定。使用 --deploy-mode 参数来配置 client 或 cluster 模式</li></ul> <h2 id="spark-运行环境"><a href="#spark-运行环境" class="header-anchor">#</a> Spark 运行环境</h2> <p><a href="https://gitee.com/fouxian/spark-docker" target="_blank" rel="noopener noreferrer">代码仓库<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="local"><a href="#local" class="header-anchor">#</a> Local</h3> <p>Local 模式：不需要其它任何节点资源即可在本地执行 Spark 代码的环境，采用单节点多线程方式运行，不用部署，开箱即用，适合日常测试开发
<img src="/images/kr/bigdata/spark/Spark-Shell.png" alt=""></p> <div class="language-txt wordCount.txt line-numbers-mode"><pre class="language-txt"><code>Hello World
Hello Hadoop
Hello Hive
Hello Spark
Hello HBase
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code>scala<span class="token operator">&gt;</span> sc.textFile<span class="token punctuation">(</span><span class="token string">&quot;/usr/local/data/test/wordCount.txt&quot;</span><span class="token punctuation">)</span>.flatMap<span class="token punctuation">(</span>_.split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">))</span>.map<span class="token variable"><span class="token punctuation">((</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">))</span></span>.reduceByKey<span class="token punctuation">(</span>_+_<span class="token punctuation">)</span>.collect
res0: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>Hello<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>World<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Hive<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Spark<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>HBase<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Hadoop<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">))</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><img src="/images/kr/bigdata/spark/Spark-Shell-UI.png" alt=""></p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>bin/spark-submit --class org.apache.spark.examples.SparkPi --master local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 本地模式提交作业</span>
    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar <span class="token number">1000</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><img src="/images/kr/bigdata/spark/Spark-Pi-UI.png" alt=""></p> <h3 id="standalone"><a href="#standalone" class="header-anchor">#</a> Standalone</h3> <p>Standalone（独立部署）模式：Spark 提供的一种内置的基于 Master-Slave 的集群模式，采用内置的资源管理器进行管理。</p> <ul><li>Master(Cluster Manager)：主要负责资源的调度和分配，并进行集群的监控等职责，类似于 Yarn 的 RM</li> <li>Worker：由 Master 分配资源对数据进行并行的处理和计算，类似于 Yarn 的 NM</li></ul> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 以 client 模式提交到 standalone 集群 </span>
spark-submit <span class="token punctuation">\</span>
    --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
    --master spark://spark-alone-master:7077 <span class="token punctuation">\</span>
    --executor-memory 2G --total-executor-cores <span class="token number">10</span> <span class="token punctuation">\</span>
    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar <span class="token number">100</span>
<span class="token comment"># 以 cluster 模式提交到 standalone 集群 </span>
spark-submit <span class="token punctuation">\</span>
    --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
    --master spark://spark-alone-master:7077 <span class="token punctuation">\</span>
    --deploy-mode cluster <span class="token punctuation">\</span>
    --supervise     <span class="token comment"># 配置此参数代表开启监督，如果主应用程序异常退出，则自动重启 Driver</span>
    --executor-memory 2G --total-executor-cores <span class="token number">10</span> 
    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p><img src="/images/kr/bigdata/spark/Spark-Master.png" alt=""></p> <p><img src="/images/kr/bigdata/spark/Spark-History.png" alt=""> <img src="/images/kr/bigdata/spark/Spark-History-Log.png" alt=""></p> <h3 id="spark-on-yarn"><a href="#spark-on-yarn" class="header-anchor">#</a> Spark On Yarn</h3> <p>基于 Yarn 资源管理与调度的 Spark 运行环境</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 以 client 模式提交到 Yarn 集群，适用于交互、调试，希望立即看到 app 输出 </span>
spark-submit <span class="token punctuation">\</span>
    --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
    --master <span class="token function">yarn</span> --deploy-mode client <span class="token punctuation">\</span>
    --executor-memory 2G --num-executors <span class="token number">10</span> <span class="token punctuation">\</span>
    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar <span class="token number">10</span>
<span class="token comment"># 以 cluster 模式提交到 Yarn 集群，适用于生产环境</span>
spark-submit <span class="token punctuation">\</span>
    --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
    --master <span class="token function">yarn</span> --deploy-mode cluster <span class="token punctuation">\</span>
    --executor-memory 2G --num-executors <span class="token number">10</span> <span class="token punctuation">\</span>
    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p><img src="/images/kr/bigdata/spark/Yarn-UI.png" alt=""> <img src="/images/kr/bigdata/spark/Spark-History-Yarn.png" alt=""> <img src="/images/kr/bigdata/spark/Spark-History-Yarn-Log.png" alt=""></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">2022/6/8</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="prev">
          Hive SQL Examples
        </a></span> <span class="next"><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html">
          Spark RDD 弹性分布式数据集
        </a>
        →
      </span></p></div> </main></div> <aside class="page-sidebar"> <div class="page-side-toolbar"><div class="option-box-toc-fixed"><div class="toc-container-sidebar"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:650px"><div style="font-weight:bold;text-align:center;">Spark 概述与集群部署模式</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-核心组件" class="toc-sidebar-link">Spark 核心组件</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-sql" class="toc-sidebar-link">Spark SQL</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-streaming" class="toc-sidebar-link">Spark Streaming</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-mllib" class="toc-sidebar-link">Spark MLlib</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-graphx" class="toc-sidebar-link">Spark GraphX</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#作业提交" class="toc-sidebar-link">作业提交</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-运行环境" class="toc-sidebar-link">Spark 运行环境</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#local" class="toc-sidebar-link">Local</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#standalone" class="toc-sidebar-link">Standalone</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-on-yarn" class="toc-sidebar-link">Spark On Yarn</a></li></ul></li></ul></div></div></div></div></div> <div class="option-box-toc-over"><img src="/images/system/toc.png" class="nozoom"> <span class="show-txt">目录</span> <div class="toc-container"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:550px"><div style="font-weight:bold;text-align:center;">Spark 概述与集群部署模式</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-核心组件" class="toc-sidebar-link">Spark 核心组件</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-sql" class="toc-sidebar-link">Spark SQL</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-streaming" class="toc-sidebar-link">Spark Streaming</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-mllib" class="toc-sidebar-link">Spark MLlib</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-graphx" class="toc-sidebar-link">Spark GraphX</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#作业提交" class="toc-sidebar-link">作业提交</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-运行环境" class="toc-sidebar-link">Spark 运行环境</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#local" class="toc-sidebar-link">Local</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#standalone" class="toc-sidebar-link">Standalone</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-%E6%A6%82%E8%BF%B0%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F.html#spark-on-yarn" class="toc-sidebar-link">Spark On Yarn</a></li></ul></li></ul></div></div></div></div></div></div>  </aside></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.cfd60917.js" defer></script><script src="/assets/js/4.8234885e.js" defer></script><script src="/assets/js/3.1429892b.js" defer></script><script src="/assets/js/33.d0dc971f.js" defer></script>
  </body>
</html>
