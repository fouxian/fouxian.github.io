<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark RDD 弹性分布式数据集 | Keep Running</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.png">
    <script charset="utf-8" async="async" src="/js/jquery.min.js"></script>
    <script charset="utf-8" async="async" src="/js/global.js"></script>
    <script charset="utf-8" async="async" src="/js/fingerprint2.min.js"></script>
    <meta name="description" content="">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <meta name="apple-mobile-web-app-capable" content="yes">
    
    <link rel="preload" href="/assets/css/0.styles.42b858ce.css" as="style"><link rel="preload" href="/assets/js/app.cfd60917.js" as="script"><link rel="preload" href="/assets/js/4.8234885e.js" as="script"><link rel="preload" href="/assets/js/3.1429892b.js" as="script"><link rel="preload" href="/assets/js/30.b074fddd.js" as="script"><link rel="prefetch" href="/assets/js/10.0f0de338.js"><link rel="prefetch" href="/assets/js/11.0c47d372.js"><link rel="prefetch" href="/assets/js/12.b45ce082.js"><link rel="prefetch" href="/assets/js/13.f2032214.js"><link rel="prefetch" href="/assets/js/14.0a8927b2.js"><link rel="prefetch" href="/assets/js/15.9ab1d206.js"><link rel="prefetch" href="/assets/js/16.f03f2e40.js"><link rel="prefetch" href="/assets/js/17.c6bbe2be.js"><link rel="prefetch" href="/assets/js/18.e08bb862.js"><link rel="prefetch" href="/assets/js/19.c00af7cb.js"><link rel="prefetch" href="/assets/js/20.35396483.js"><link rel="prefetch" href="/assets/js/21.fe05d239.js"><link rel="prefetch" href="/assets/js/22.80eaa289.js"><link rel="prefetch" href="/assets/js/23.bce5e854.js"><link rel="prefetch" href="/assets/js/24.fa104861.js"><link rel="prefetch" href="/assets/js/25.2c725be9.js"><link rel="prefetch" href="/assets/js/26.fc7addb7.js"><link rel="prefetch" href="/assets/js/27.fc831a66.js"><link rel="prefetch" href="/assets/js/28.3784f580.js"><link rel="prefetch" href="/assets/js/29.7e78aa5c.js"><link rel="prefetch" href="/assets/js/31.059ebf27.js"><link rel="prefetch" href="/assets/js/32.12570018.js"><link rel="prefetch" href="/assets/js/33.d0dc971f.js"><link rel="prefetch" href="/assets/js/34.c9b46696.js"><link rel="prefetch" href="/assets/js/35.77a81c6a.js"><link rel="prefetch" href="/assets/js/36.6048e328.js"><link rel="prefetch" href="/assets/js/37.b9f285de.js"><link rel="prefetch" href="/assets/js/38.ac5a2abf.js"><link rel="prefetch" href="/assets/js/39.97ca52cb.js"><link rel="prefetch" href="/assets/js/40.1689d33f.js"><link rel="prefetch" href="/assets/js/41.4d2d8182.js"><link rel="prefetch" href="/assets/js/42.8647a8ff.js"><link rel="prefetch" href="/assets/js/43.f867a280.js"><link rel="prefetch" href="/assets/js/44.a51272ee.js"><link rel="prefetch" href="/assets/js/45.c31e6474.js"><link rel="prefetch" href="/assets/js/46.fe85ae54.js"><link rel="prefetch" href="/assets/js/47.dc8a97d4.js"><link rel="prefetch" href="/assets/js/48.c97f7726.js"><link rel="prefetch" href="/assets/js/49.ac219d14.js"><link rel="prefetch" href="/assets/js/5.963fada3.js"><link rel="prefetch" href="/assets/js/50.926ecfa5.js"><link rel="prefetch" href="/assets/js/51.e776b5b1.js"><link rel="prefetch" href="/assets/js/52.4938314c.js"><link rel="prefetch" href="/assets/js/53.6b4d7266.js"><link rel="prefetch" href="/assets/js/54.bfaf622b.js"><link rel="prefetch" href="/assets/js/55.c6d160b9.js"><link rel="prefetch" href="/assets/js/56.31f6843c.js"><link rel="prefetch" href="/assets/js/57.55cbf7b8.js"><link rel="prefetch" href="/assets/js/58.8174871d.js"><link rel="prefetch" href="/assets/js/59.3eee2bde.js"><link rel="prefetch" href="/assets/js/6.b2e36a75.js"><link rel="prefetch" href="/assets/js/60.233a32ed.js"><link rel="prefetch" href="/assets/js/61.defb83ac.js"><link rel="prefetch" href="/assets/js/62.442070cd.js"><link rel="prefetch" href="/assets/js/63.cc121456.js"><link rel="prefetch" href="/assets/js/64.c8f83f5d.js"><link rel="prefetch" href="/assets/js/65.b9bc8c1c.js"><link rel="prefetch" href="/assets/js/7.fb6689bf.js"><link rel="prefetch" href="/assets/js/8.e390cc6b.js"><link rel="prefetch" href="/assets/js/9.c03c9dfe.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.db8a86c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.42b858ce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Keep Running</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="sidebar-link">Hadoop概述及分布式集群容器化部署</a></li><li><a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="sidebar-link">分布式文件系统 HDFS 体系架构及原理</a></li><li><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html" class="sidebar-link">分布式并行计算 MapReduce 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html" class="sidebar-link">集群资源管理与调度平台 YARN 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/MapReduce-实例-WordCount.html" class="sidebar-link">MapReduce 经典案例：WordCount</a></li><li><a href="/kr/bigdata/hadoop/HDFS-3-X-纠删码.html" class="sidebar-link">HDFS 3.X 纠删码</a></li><li><a href="/kr/bigdata/hadoop/大数据生态圈与离线实时数据平台实践.html" class="sidebar-link">大数据生态圈与离线实时数据平台实践</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hive/分布式数据仓库-Hive.html" class="sidebar-link">分布式数据仓库 Hive</a></li><li><a href="/kr/bigdata/hive/Hive-SQL.html" class="sidebar-link">Hive SQL 执行计划|数据倾斜|性能优化</a></li><li><a href="/kr/bigdata/hive/HiveSQL-编译过程.html" class="sidebar-link">Hive 工作原理：Hive SQL 编译过程</a></li><li><a href="/kr/bigdata/hive/Hive-function.html" class="sidebar-link">Hive Function</a></li><li><a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="sidebar-link">Hive SQL Examples</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="sidebar-link">Spark 概述与集群部署模式</a></li><li><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html" class="active sidebar-link">Spark RDD 弹性分布式数据集</a></li><li><a href="/kr/bigdata/spark/Spark-运行架构.html" class="sidebar-link">Spark 运行架构及作业提交流程</a></li><li><a href="/kr/bigdata/spark/Spark-Streaming.html" class="sidebar-link">Spark Streaming</a></li><li><a href="/kr/bigdata/spark/Spark-sql.html" class="sidebar-link">Spark SQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Other</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/Canal-MySQL-binlog-增量订阅与消费组件.html" class="sidebar-link">Canal：MySQL Binlog 增量订阅与消费组件</a></li><li><a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="sidebar-link">Sqoop 数据迁移工具</a></li><li><a href="/kr/bigdata/Flume-基本架构及应用场景.html" class="sidebar-link">Flume 基本架构及应用场景</a></li><li><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html" class="sidebar-link">Azkaban 编译镜像及基本使用</a></li><li><a href="/kr/bigdata/Maxwell.html" class="sidebar-link">Maxwell</a></li><li><a href="/kr/bigdata/Elaticsearch.html" class="sidebar-link">Elaticsearch</a></li><li><a href="/kr/bigdata/大数据可视化交互平台-Hue.html" class="sidebar-link">大数据可视化交互平台 Hue</a></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-default-content content__default"><h1 id="spark-rdd-弹性分布式数据集"><a href="#spark-rdd-弹性分布式数据集" class="header-anchor">#</a> Spark RDD 弹性分布式数据集</h1> <blockquote><p>RDD 是 Spark 中最基本的数据处理模型，是一个抽象类，代表一个弹性的、不可变、可分区、元素可并行计算的集合</p></blockquote> <p>Spark 计算引擎为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景，三大数据结构分别是：</p> <ul><li>RDD : 弹性分布式数据集</li> <li>累加器：分布式共享只写变量</li> <li>广播变量：分布式共享只读变量</li></ul> <h2 id="rdd-弹性分布式数据集"><a href="#rdd-弹性分布式数据集" class="header-anchor">#</a> RDD 弹性分布式数据集</h2> <p>RDD（Resilient Distributed Datasets）是 Spark 中最基本的数据处理模型，是一个抽象类，代表一个弹性的、不可变、可分区、元素可并行计算的集合。</p> <ul><li>弹性
<ul><li>存储的弹性：内存与磁盘的自动转换</li> <li>容错的弹性：数据丢失可以自动恢复</li> <li>计算的弹性：计算出错重试机制</li> <li>分片的弹性：可根据需要重新分片</li></ul></li> <li>分布式：数据存储在大数据集群不同节点上</li> <li>数据集：RDD 封装了计算逻辑，并不保存数据</li> <li>数据抽象：RDD 是一个抽象类，需要子类具体实现</li> <li>不可变：RDD 封装了计算逻辑，是不可改变的，若要改变，只能产生新 RDD</li> <li>可分区、并行计算</li></ul> <h2 id="rdd-核心属性"><a href="#rdd-核心属性" class="header-anchor">#</a> RDD 核心属性</h2> <ul><li>一个 RDD 由一个或者多个分区（Partitions）组成，每个分区会被一个计算任务所处理，在创建 RDD 时可以指定其分区个数，若没有指定，则默认采用程序所分配到的 CPU 的核心数</li> <li>RDD 拥有一个用于计算分区的函数 compute</li> <li>RDD 会保存彼此间的依赖关系，RDD 的每次转换都会生成一个新的依赖关系。在部分分区数据丢失后，可以通过这种依赖关系重新计算丢失的分区数据，而不是对 RDD 的所有分区进行重新计算</li> <li>Key-Value 型的 RDD 还拥有 Partitioner(分区器)，用于决定数据被存储在哪个分区中，目前 Spark 支持 HashPartitioner(按照哈希分区) 和 RangeParationer(按照范围进行分区)</li> <li>一个优先位置列表 (可选)，用于存储每个分区的优先位置 (prefered location)。对于 HDFS 文件来说，这个列表保存的就是每个分区所在的块的位置，按照“移动数据不如移动计算“的理念，Spark 在进行任务调度时，会尽可能将计算任务分配到其所要处理数据块的存储位置</li></ul> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">/**
 * RDD 核心属性
 * Internally, each RDD is characterized by five main properties:
 * A list of partitions
 * A function for computing each split
 * A list of dependencies on other RDDs
 * Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
 * Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file) 
 */</span>
<span class="token comment">// 分区列表：RDD 数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要性</span>
<span class="token keyword">protected</span> <span class="token keyword">def</span> getPartitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span>
<span class="token comment">// 分区计算函数：Spark 在计算时，是使用分区函数对每一个分区进行计算</span>
<span class="token annotation punctuation">@DeveloperApi</span>
<span class="token keyword">def</span> compute<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// RDD 间的依赖关系：RDD 是计算模型的封装，当需求中需要将多个计算模型进行组合时，就需要将多个 RDD 建立依赖关系</span>
<span class="token keyword">protected</span> <span class="token keyword">def</span> getDependencies<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> deps
<span class="token comment">// 分区器：当数据为 KV 类型数据时，可以通过设定分区器自定义数据的分区</span>
<span class="token annotation punctuation">@transient</span> <span class="token keyword">val</span> partitioner<span class="token operator">:</span> Option<span class="token punctuation">[</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> None
<span class="token comment">// 首选位置：计算数据时，可以根据计算节点的状态选择不同的节点位置进行计算</span>
<span class="token keyword">protected</span> <span class="token keyword">def</span> getPreferredLocations<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">)</span><span class="token operator">:</span> Seq<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Nil
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h2 id="rdd-on-yarn"><a href="#rdd-on-yarn" class="header-anchor">#</a> RDD ON YARN</h2> <p>从计算角度看，数据处理过程中需要计算资源（内存/CPU）和计算模型（逻辑），执行时，需要将计算资源和计算模型进行协调和整合。
Spark 在执行时，先申请资源，然后将应用程序的数据处理逻辑分解成一个个计算任务，再将任务分发到已经分配资源的计算节点上，按照指定计算模型进行数据计算，得到最终结果。
RDD 是 Spark 中用于数据处理的核心模型，其在 Yarn 环境中工作原理：</p> <ul><li>Spark 向 Yarn 申请资源创建调度节点和计算节点</li> <li>Spark 根据需求将计算逻辑分区划分成不同的任务</li> <li>调度节点将任务根据计算节点状态发送到对应的计算节点进行计算</li></ul> <p>总结：RDD 在整个流程中主要用于封装逻辑，并生成 Task 发送给 Executor 节点执行计算。</p> <h2 id="rdd-创建"><a href="#rdd-创建" class="header-anchor">#</a> RDD 创建</h2> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sparkContext <span class="token operator">=</span> <span class="token keyword">new</span> sparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>
<span class="token comment">// 在 Spark 中创建 RDD 的方式：</span>
<span class="token comment">// 从集合（内存）中创建 RDD，方法：parallelize/makeRDD（底层就是调用 parallelize）</span>
<span class="token keyword">val</span> dataRDD1 <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> dataRDD2 <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num<span class="token punctuation">)</span>     <span class="token comment">// num：指定并行度</span>
dataRDD1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>printIn<span class="token punctuation">)</span>
dataRDD2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>printIn<span class="token punctuation">)</span>
<span class="token comment">/**
 * 引用外部存储系统中的数据集，例如本地文件系统，HDFS，HBase 或支持 Hadoop InputFormat 的任何数据源
 * 如果在集群环境下从本地文件系统读取数据，则要求该文件必须在集群中所有机器上都存在，且路径相同
 * 支持目录路径，支持压缩文件，支持使用通配符
 */</span>
<span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">,</span> num<span class="token punctuation">)</span>      <span class="token comment">// num：指定并行度</span>
fileRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>printIn<span class="token punctuation">)</span>
sparkContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">/**
 * textFile &amp; wholeTextFiles，两者都可以用来读取外部文件，但是返回格式是不同的：
 * textFile：其返回格式是 RDD[String]，返回的是文件内容，RDD 中每一个元素对应一行数据
 * wholeTextFiles：其返回格式是 RDD[(String, String)]，元组中第一个参数是文件路径，第二个参数是文件内容
 * 两者都提供第二个参数 minPartitions 来控制最小分区数
 * 从 HDFS 上读取文件时，Spark 会为每个块创建一个分区
 */</span>
<span class="token keyword">def</span> textFile<span class="token punctuation">(</span>path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> defaultMinPartitions<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>
<span class="token keyword">def</span> wholeTextFiles<span class="token punctuation">(</span>path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> defaultMinPartitions<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><h2 id="rdd-持久化"><a href="#rdd-持久化" class="header-anchor">#</a> RDD 持久化</h2> <h3 id="rdd-缓存"><a href="#rdd-缓存" class="header-anchor">#</a> RDD 缓存</h3> <p>Spark 速度非常快的一个原因是 RDD 支持缓存，默认情况下会把数据缓存在 JVM 堆内存中。虽然缓存有丢失数据风险，但由于 RDD 之间的依赖关系，若某个分区的缓存数据丢失，只需要重新计算该分区即可。Spark 的缓存存储级别（StorageLevel）：
<img src="/images/kr/bigdata/spark/StorageLevel.png" alt=""></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token annotation punctuation">@DeveloperApi</span>
<span class="token keyword">class</span> StorageLevel <span class="token keyword">private</span><span class="token punctuation">(</span>                 <span class="token comment">// StorageLevel 私有主构造器</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> _useDisk<span class="token operator">:</span> <span class="token builtin">Boolean</span><span class="token punctuation">,</span>          <span class="token comment">// 使用磁盘（外存）</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> _useMemory<span class="token operator">:</span> <span class="token builtin">Boolean</span><span class="token punctuation">,</span>        <span class="token comment">// 使用内存</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> _useOffHeap<span class="token operator">:</span> <span class="token builtin">Boolean</span><span class="token punctuation">,</span>       <span class="token comment">// 使用堆外内存</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> _deserialized<span class="token operator">:</span> <span class="token builtin">Boolean</span><span class="token punctuation">,</span>     <span class="token comment">// 反序列化</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> _replication<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>      <span class="token comment">// 备份数，每个分区在集群中的 ? 个节点上建立副本，默认 1</span>
  <span class="token keyword">extends</span> Externalizable <span class="token punctuation">{</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>DISK_ONLY：只在磁盘上缓存 RDD</li> <li>MEMORY_ONLY：
<ul><li>默认缓存级别，将 RDD 以反序列化的 Java 对象形式存储在 JVM 堆内存中</li> <li>若内存空间不够，则部分分区数据将不再缓存</li></ul></li> <li>MEMORY_ONLY_SER：
<ul><li>将 RDD 以序列化的 Java 对象形式进行存储（每个分区为一个 byte 数组）</li> <li>该方式比反序列化对象节省存储空间，但在读取时会增加 CPU 计算负担，仅支持 Java/Scala</li></ul></li> <li>MEMORY_AND_DISK
<ul><li>将 RDD 以反序列化的 Java 对象形式存储在 JVM 堆内存中</li> <li>若内存空间不够，将未缓存的分区数据溢写到磁盘，在需要使用这些分区时从磁盘读取</li></ul></li> <li>MEMORY_AND_DISK_SER：
<ul><li>类似于 MEMORY_ONLY_SER，仅支持 Java/Scala</li> <li>若内存空间不够，则溢出的分区数据会溢写到磁盘，而不是在用到它们时重新计算</li></ul></li> <li>OFF_HEAP：与 MEMORY_ONLY_SER 类似，但将数据存储在堆外内存中</li></ul> <p>启动堆外内存需要配置两个参数：</p> <ul><li>spark.memory.offHeap.enabled：是否开启堆外内存，默认值为 false</li> <li>spark.memory.offHeap.size：堆外内存空间大小，默认值为 0</li></ul> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 缓存数据方法：persist/cache；cache 是 persist 的特殊化形式，内部是调用 persist</span>
<span class="token comment">// 这两个方法被调用时并不立即缓存，而是触发后面的 action 算子时，该 RDD 将会被缓存在计算节点的内存中</span>
fileRDD<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_AND_DISK<span class="token punctuation">)</span> 
fileRDD<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">// 等价于 fileRDD.persist(StorageLevel.MEMORY_ONLY)</span>
<span class="token comment">// Spark 会自动监视每个节点上的缓存使用情况，并按照最近最少使用（LRU）的规则删除旧数据分区</span>
fileRDD<span class="token punctuation">.</span>unpersist<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment">// 也可手动删除缓存</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="rdd-检查点"><a href="#rdd-检查点" class="header-anchor">#</a> RDD 检查点</h3> <p>RDD CheckPoint 检查点：通过将 RDD 中间结果写入磁盘；由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，若检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销；对RDD 进行检查点操作并不会马上被执行，必须执行 action 操作才能触发。
缓存与检查点的区别：</p> <ul><li>Cache 缓存只是将数据保存起来，不切断血缘依赖，Checkpoint 检查点切断血缘依赖</li> <li>Cache 缓存的数据通常存储在磁盘、内存等，可靠性低，Checkpoint 的数据通常存储在 HDFS 等容错、高可用的文件系统，可靠性高</li> <li>建议对 checkpoint() 的 RDD 使用 Cache 缓存，这样 checkpoint 的 job 只需从 Cache 缓存中读取数据即可，否则需要再从头计算一次 RDD</li></ul> <h2 id="rdd-算子"><a href="#rdd-算子" class="header-anchor">#</a> RDD 算子</h2> <p>RDD 支持两种类型的操作：</p> <ul><li>transformations：转换，从现有数据集创建新数据集，延迟执行（lazy），返回新的 RDD</li> <li>actions：在数据集上运行计算后将值返回到驱动程序</li></ul> <p>RDD 中的所有转换操作都是惰性的，它们只是记住这些转换操作，但不会立即执行，只有遇到 action 操作后才会真正的进行计算，这类似于函数式编程中的惰性求值。</p> <h3 id="转换算子"><a href="#转换算子" class="header-anchor">#</a> 转换算子</h3> <p>RDD 根据数据处理方式的不同将算子整体上分为 <strong>Value 类型、双 Value 类型和 Key-Value 类型</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// Value 类型</span>
<span class="token comment">// 将处理的数据逐条进行映射转换（类型转换/值转换）</span>
<span class="token keyword">def</span> map<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> U<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span>
<span class="token comment">// 将待处理的数据以分区为单位发送到计算节点进行处理</span>
<span class="token keyword">def</span> mapPartitions<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
    f<span class="token operator">:</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token keyword">=&gt;</span> Iterator<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">,</span>
    preservesPartitioning<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span>
<span class="token comment">// 将待处理的数据以分区为单位发送到计算节点进行处理，在处理时同时可以获取当前分区索引</span>
<span class="token keyword">def</span> mapPartitionsWithIndex<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
    f<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> Iterator<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">,</span>
    preservesPartitioning<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span>
<span class="token comment">// 将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射</span>
<span class="token keyword">def</span> flatMap<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> TraversableOnce<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span>
<span class="token comment">// 将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变</span>
<span class="token keyword">def</span> glom<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token comment">// 将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，将这样的操作称之为 Shuffle</span>
<span class="token comment">// 极限情况下，数据可能被分在同一个分区中</span>
<span class="token keyword">def</span> groupBy<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> K<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> kt<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃</span>
<span class="token comment">// 当数据进行筛选过滤后，分区不变，但是分区内的数据可能不均衡，生产环境下，可能会出现数据倾斜</span>
<span class="token keyword">def</span> filter<span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> <span class="token builtin">Boolean</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 根据指定的规则从数据集中抽取数据</span>
<span class="token keyword">def</span> sample<span class="token punctuation">(</span>
    withReplacement<span class="token operator">:</span> <span class="token builtin">Boolean</span><span class="token punctuation">,</span>
    fraction<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">,</span>
    seed<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> Utils<span class="token punctuation">.</span>random<span class="token punctuation">.</span>nextLong<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 将数据集中重复的数据去重</span>
<span class="token keyword">def</span> distinct<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token keyword">def</span> distinct<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率</span>
<span class="token comment">// 当 Spark 程序中，存在过多的小任务时，通过 coalesce 方法，收缩合并分区，减少分区的个数，减小任务调度成本</span>
<span class="token keyword">def</span> coalesce<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> shuffle<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
    partitionCoalescer<span class="token operator">:</span> Option<span class="token punctuation">[</span>PartitionCoalescer<span class="token punctuation">]</span> <span class="token operator">=</span> Option<span class="token punctuation">.</span>empty<span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 该操作内部其实执行的是 coalesce 操作，参数 shuffle 的默认值为 true</span>
<span class="token comment">// repartition 操作都可以完成分区数多的 RDD 与分区数少的 RDD 之间相互转换，因为无论如何都会经 shuffle 过程</span>
<span class="token keyword">def</span> repartition<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 该操作用于排序数据。在排序之前，可以将数据通过f函数进行处理，并排序结果，默认为升序排列</span>
<span class="token comment">// 排序后新产生的 RDD 的分区数与原 RDD 的分区数一致，中间存在 Shuffle 的过程</span>
<span class="token keyword">def</span> sortBy<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">(</span>
    f<span class="token operator">:</span> <span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> K<span class="token punctuation">,</span>
    ascending<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">,</span> ctag<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br></div></div><p>map 与 mapPartitions 区别：</p> <ul><li>数据处理角度
<ul><li>Map 算子是分区内数据串行执行操作</li> <li>mapPartitions 算子是以分区为单位进行批处理操作</li></ul></li> <li>功能的角度
<ul><li>Map 算子主要目的将数据源中的数据进行转换和改变，但是不会减少或增多数据</li> <li>MapPartitions 算子需要传递一个迭代器，返回一个迭代器，可以增加或减少数据</li></ul></li> <li>性能的角度
<ul><li>Map 算子串行操作，性能比较低，而 mapPartitions 批处理，所以性能较高</li> <li>mapPartitions 算子会长时间占用内存，在内存有限的情况下推荐使用 map</li></ul></li></ul> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 双 Value 类型</span>
<span class="token comment">// 对源 RDD 和参数 RDD 求交集后返回一个新的 RDD</span>
<span class="token keyword">def</span> intersection<span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 对源 RDD 和参数 RDD 求并集后返回一个新的 RDD</span>
<span class="token keyword">def</span> union<span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 以一个 RDD 元素为主，去除两个 RDD 中重复元素，将其他元素保留下来。求差集</span>
<span class="token keyword">def</span> subtract<span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 将两个 RDD 中的元素，以键值对的形式进行合并</span>
<span class="token comment">// 其中，键值对中的 Key 为第 1 个 RDD 中的元素，Value 为第 2 个 RDD 中的相同位置元素</span>
<span class="token keyword">def</span> zip<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> U<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// key-value 类型</span>
<span class="token comment">// 将数据按照指定 Partitioner 重新进行分区，Spark 默认的分区器是 HashPartitioner</span>
<span class="token keyword">def</span> partitionBy<span class="token punctuation">(</span>partitioner<span class="token operator">:</span> Partitioner<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 可以将数据按照相同的 Key 对 Value 进行聚合</span>
<span class="token keyword">def</span> reduceByKey<span class="token punctuation">(</span>func<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> reduceByKey<span class="token punctuation">(</span>func<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">,</span> numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 将数据源的数据根据 key 对 value 进行分组</span>
<span class="token keyword">def</span> groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> groupByKey<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> groupByKey<span class="token punctuation">(</span>partitioner<span class="token operator">:</span> Partitioner<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 将数据根据不同的规则进行分区内计算和分区间计算</span>
<span class="token keyword">def</span> aggregateByKey<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>zeroValue<span class="token operator">:</span> U<span class="token punctuation">)</span><span class="token punctuation">(</span>seqOp<span class="token operator">:</span> <span class="token punctuation">(</span>U<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> U<span class="token punctuation">,</span>combOp<span class="token operator">:</span> <span class="token punctuation">(</span>U<span class="token punctuation">,</span> U<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> U<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> U<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 当分区内计算规则和分区间计算规则相同时，aggregateByKey 就可以简化为 foldByKey</span>
<span class="token keyword">def</span> foldByKey<span class="token punctuation">(</span>zeroValue<span class="token operator">:</span> V<span class="token punctuation">)</span><span class="token punctuation">(</span>func<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 最通用的对 key-value 型 rdd 进行聚集操作的聚集函数（aggregation function）</span>
<span class="token comment">// 类似于 aggregate()，combineByKey() 允许用户返回值的类型与输入不一致</span>
<span class="token keyword">def</span> combineByKey<span class="token punctuation">[</span>C<span class="token punctuation">]</span><span class="token punctuation">(</span>
    createCombiner<span class="token operator">:</span> V <span class="token keyword">=&gt;</span> C<span class="token punctuation">,</span>
    mergeValue<span class="token operator">:</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> C<span class="token punctuation">,</span>
    mergeCombiners<span class="token operator">:</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span> C<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> C<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 在一个(K,V)的RDD上调用，K必须实现Ordered接口(特质)，返回一个按照key进行排序的</span>
<span class="token keyword">def</span> sortByKey<span class="token punctuation">(</span>ascending<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">,</span> numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token keyword">self</span><span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素连接在一起的(K,(V,W))的RDD</span>
<span class="token keyword">def</span> join<span class="token punctuation">[</span>W<span class="token punctuation">]</span><span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 类似于SQL语句的左外连接</span>
<span class="token keyword">def</span> leftOuterJoin<span class="token punctuation">[</span>W<span class="token punctuation">]</span><span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> Option<span class="token punctuation">[</span>W<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">// 在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable&lt;V&gt;,Iterable&lt;W&gt;))类型的RDD</span>
<span class="token keyword">def</span> cogroup<span class="token punctuation">[</span>W<span class="token punctuation">]</span><span class="token punctuation">(</span>other<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> <span class="token punctuation">(</span>Iterable<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>W<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><p>reduceByKey 和 groupByKey 的区别：</p> <ul><li>从 shuffle 的角度：reduceByKey 和 groupByKey 都存在 shuffle 的操作，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行预聚合（combine）功能，这样会减少落盘的数据量，而 groupByKey 只是进行分组，不存在数据量减少的问题，reduceByKey 性能比较高。</li> <li>从功能的角度：reduceByKey 其实包含分组和聚合的功能。GroupByKey 只能分组，不能聚合，所以在分组聚合的场合下，推荐使用 reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用 groupByKey</li></ul> <p>reduceByKey、foldByKey、aggregateByKey、combineByKey的区别？</p> <ul><li>reduceByKey: 相同key的第一个数据不进行任何计算，分区内和分区间计算规则相同</li> <li>FoldByKey: 相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则相同</li> <li>AggregateByKey：相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则可以不相同</li> <li>CombineByKey:当计算时，发现数据结构不满足要求时，可以让第一个数据转换结构。分区内和分区间计算规则不相同。</li></ul> <h3 id="行动算子"><a href="#行动算子" class="header-anchor">#</a> 行动算子</h3> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 行动算子</span>
<span class="token comment">// 聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据</span>
<span class="token keyword">def</span> reduce<span class="token punctuation">(</span>f<span class="token operator">:</span> <span class="token punctuation">(</span>T<span class="token punctuation">,</span> T<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> T<span class="token punctuation">)</span><span class="token operator">:</span> T
<span class="token comment">// 在驱动程序中，以数组Array的形式返回数据集的所有元素</span>
<span class="token keyword">def</span> collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Array<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 返回RDD中元素的个数</span>
<span class="token keyword">def</span> count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span>
<span class="token comment">// 返回RDD中的第一个元素</span>
<span class="token keyword">def</span> first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> T
<span class="token comment">// 返回一个由RDD的前n个元素组成的数组</span>
<span class="token keyword">def</span> take<span class="token punctuation">(</span>num<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> Array<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 返回该RDD排序后的前n个元素组成的数组</span>
<span class="token keyword">def</span> takeOrdered<span class="token punctuation">(</span>num<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Array<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
<span class="token comment">// 分区的数据通过初始值和分区内的数据进行聚合，然后再和初始值进行分区间的数据聚合</span>
<span class="token keyword">def</span> aggregate<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>zeroValue<span class="token operator">:</span> U<span class="token punctuation">)</span><span class="token punctuation">(</span>seqOp<span class="token operator">:</span> <span class="token punctuation">(</span>U<span class="token punctuation">,</span> T<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> U<span class="token punctuation">,</span> combOp<span class="token operator">:</span> <span class="token punctuation">(</span>U<span class="token punctuation">,</span> U<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> U<span class="token punctuation">)</span><span class="token operator">:</span> U
<span class="token comment">// 折叠操作，aggregate的简化版操作</span>
<span class="token keyword">def</span> fold<span class="token punctuation">(</span>zeroValue<span class="token operator">:</span> T<span class="token punctuation">)</span><span class="token punctuation">(</span>op<span class="token operator">:</span> <span class="token punctuation">(</span>T<span class="token punctuation">,</span> T<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> T<span class="token punctuation">)</span><span class="token operator">:</span> T
<span class="token comment">// 统计每种key的个数</span>
<span class="token keyword">def</span> countByKey<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Map<span class="token punctuation">[</span>K<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span>
<span class="token comment">// 将数据保存到不同格式的文件中</span>
<span class="token keyword">def</span> saveAsTextFile<span class="token punctuation">(</span>path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span>
<span class="token keyword">def</span> saveAsObjectFile<span class="token punctuation">(</span>path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span>
<span class="token keyword">def</span> saveAsSequenceFile<span class="token punctuation">(</span>
    path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span>
    codec<span class="token operator">:</span> Option<span class="token punctuation">[</span>Class<span class="token punctuation">[</span>_ <span class="token operator">&lt;</span><span class="token operator">:</span> CompressionCodec<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> None<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span>
<span class="token comment">// 分布式遍历RDD中的每一个元素，调用指定函数</span>
<span class="token keyword">def</span> foreach<span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> <span class="token builtin">Unit</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>
    <span class="token keyword">val</span> cleanF <span class="token operator">=</span> sc<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>runJob<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>iter<span class="token operator">:</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>cleanF<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><h2 id="rdd-序列化"><a href="#rdd-序列化" class="header-anchor">#</a> RDD 序列化</h2> <p>闭包检测：
从计算的角度, 算子以外的代码都是在 Driver 端执行, 算子里面的代码都是在 Executor 端执行。那么在 scala 函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给 Executor 端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化，这个操作我们称之为闭包检测
Java的序列化能够序列化任何的类。但是比较重（字节多），序列化后，对象的提交也比较大。Spark出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制。Kryo速度是Serializable的10倍。当RDD在Shuffle数据的时候，简单数据类型、数组和字符串类型已经在Spark内部使用Kryo来序列化。
注意：即使使用Kryo序列化，也要继承Serializable接口</p> <h2 id="rdd-分区器"><a href="#rdd-分区器" class="header-anchor">#</a> RDD 分区器</h2> <p>分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区，进而决定了Reduce的个数</p> <ul><li>只有Key-Value类型的RDD才有分区器，非Key-Value类型的RDD分区的值是None</li> <li>每个RDD的分区ID范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的</li></ul> <p>Hash分区：对于给定的key，计算其hashCode,并除以分区个数取余
Range分区：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序</p> <p>RDD 依赖关系
RDD 血缘关系</p> <p>RDD任务切分中间分为：Application、Job、Stage和Task
⚫ Application：初始化一个SparkContext即生成一个Application；
⚫ Job：一个Action算子就会生成一个Job；
⚫ Stage：Stage等于宽依赖(ShuffleDependency)的个数加1；
⚫ Task：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数。
注意：Application-&gt;Job-&gt;Stage-&gt;Task每一层都是1对n的关系</p> <h2 id="累加器"><a href="#累加器" class="header-anchor">#</a> 累加器</h2></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">2022/6/8</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="prev">
          Spark 概述与集群部署模式
        </a></span> <span class="next"><a href="/kr/bigdata/spark/Spark-运行架构.html">
          Spark 运行架构及作业提交流程
        </a>
        →
      </span></p></div> </main></div> <aside class="page-sidebar"> <div class="page-side-toolbar"><div class="option-box-toc-fixed"><div class="toc-container-sidebar"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:650px"><div style="font-weight:bold;text-align:center;">Spark RDD 弹性分布式数据集</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-弹性分布式数据集" class="toc-sidebar-link">RDD 弹性分布式数据集</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-核心属性" class="toc-sidebar-link">RDD 核心属性</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-on-yarn" class="toc-sidebar-link">RDD ON YARN</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-创建" class="toc-sidebar-link">RDD 创建</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-持久化" class="toc-sidebar-link">RDD 持久化</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-缓存" class="toc-sidebar-link">RDD 缓存</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-检查点" class="toc-sidebar-link">RDD 检查点</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-算子" class="toc-sidebar-link">RDD 算子</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#转换算子" class="toc-sidebar-link">转换算子</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#行动算子" class="toc-sidebar-link">行动算子</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-序列化" class="toc-sidebar-link">RDD 序列化</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-分区器" class="toc-sidebar-link">RDD 分区器</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#累加器" class="toc-sidebar-link">累加器</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div> <div class="option-box-toc-over"><img src="/images/system/toc.png" class="nozoom"> <span class="show-txt">目录</span> <div class="toc-container"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:550px"><div style="font-weight:bold;text-align:center;">Spark RDD 弹性分布式数据集</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-弹性分布式数据集" class="toc-sidebar-link">RDD 弹性分布式数据集</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-核心属性" class="toc-sidebar-link">RDD 核心属性</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-on-yarn" class="toc-sidebar-link">RDD ON YARN</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-创建" class="toc-sidebar-link">RDD 创建</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-持久化" class="toc-sidebar-link">RDD 持久化</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-缓存" class="toc-sidebar-link">RDD 缓存</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-检查点" class="toc-sidebar-link">RDD 检查点</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-算子" class="toc-sidebar-link">RDD 算子</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#转换算子" class="toc-sidebar-link">转换算子</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#行动算子" class="toc-sidebar-link">行动算子</a></li></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-序列化" class="toc-sidebar-link">RDD 序列化</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#rdd-分区器" class="toc-sidebar-link">RDD 分区器</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/spark/Spark-RDD-%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86.html#累加器" class="toc-sidebar-link">累加器</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div></div>  </aside></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.cfd60917.js" defer></script><script src="/assets/js/4.8234885e.js" defer></script><script src="/assets/js/3.1429892b.js" defer></script><script src="/assets/js/30.b074fddd.js" defer></script>
  </body>
</html>
