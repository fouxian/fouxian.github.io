<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Flume 基本架构及应用场景 | Keep Running</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.png">
    <script charset="utf-8" async="async" src="/js/jquery.min.js"></script>
    <script charset="utf-8" async="async" src="/js/global.js"></script>
    <script charset="utf-8" async="async" src="/js/fingerprint2.min.js"></script>
    <meta name="description" content="">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <meta name="apple-mobile-web-app-capable" content="yes">
    
    <link rel="preload" href="/assets/css/0.styles.42b858ce.css" as="style"><link rel="preload" href="/assets/js/app.cfd60917.js" as="script"><link rel="preload" href="/assets/js/4.8234885e.js" as="script"><link rel="preload" href="/assets/js/3.1429892b.js" as="script"><link rel="preload" href="/assets/js/15.9ab1d206.js" as="script"><link rel="prefetch" href="/assets/js/10.0f0de338.js"><link rel="prefetch" href="/assets/js/11.0c47d372.js"><link rel="prefetch" href="/assets/js/12.b45ce082.js"><link rel="prefetch" href="/assets/js/13.f2032214.js"><link rel="prefetch" href="/assets/js/14.0a8927b2.js"><link rel="prefetch" href="/assets/js/16.f03f2e40.js"><link rel="prefetch" href="/assets/js/17.c6bbe2be.js"><link rel="prefetch" href="/assets/js/18.e08bb862.js"><link rel="prefetch" href="/assets/js/19.c00af7cb.js"><link rel="prefetch" href="/assets/js/20.35396483.js"><link rel="prefetch" href="/assets/js/21.fe05d239.js"><link rel="prefetch" href="/assets/js/22.80eaa289.js"><link rel="prefetch" href="/assets/js/23.bce5e854.js"><link rel="prefetch" href="/assets/js/24.fa104861.js"><link rel="prefetch" href="/assets/js/25.2c725be9.js"><link rel="prefetch" href="/assets/js/26.fc7addb7.js"><link rel="prefetch" href="/assets/js/27.fc831a66.js"><link rel="prefetch" href="/assets/js/28.3784f580.js"><link rel="prefetch" href="/assets/js/29.7e78aa5c.js"><link rel="prefetch" href="/assets/js/30.b074fddd.js"><link rel="prefetch" href="/assets/js/31.059ebf27.js"><link rel="prefetch" href="/assets/js/32.12570018.js"><link rel="prefetch" href="/assets/js/33.d0dc971f.js"><link rel="prefetch" href="/assets/js/34.c9b46696.js"><link rel="prefetch" href="/assets/js/35.77a81c6a.js"><link rel="prefetch" href="/assets/js/36.6048e328.js"><link rel="prefetch" href="/assets/js/37.b9f285de.js"><link rel="prefetch" href="/assets/js/38.ac5a2abf.js"><link rel="prefetch" href="/assets/js/39.97ca52cb.js"><link rel="prefetch" href="/assets/js/40.1689d33f.js"><link rel="prefetch" href="/assets/js/41.4d2d8182.js"><link rel="prefetch" href="/assets/js/42.8647a8ff.js"><link rel="prefetch" href="/assets/js/43.f867a280.js"><link rel="prefetch" href="/assets/js/44.a51272ee.js"><link rel="prefetch" href="/assets/js/45.c31e6474.js"><link rel="prefetch" href="/assets/js/46.fe85ae54.js"><link rel="prefetch" href="/assets/js/47.dc8a97d4.js"><link rel="prefetch" href="/assets/js/48.c97f7726.js"><link rel="prefetch" href="/assets/js/49.ac219d14.js"><link rel="prefetch" href="/assets/js/5.963fada3.js"><link rel="prefetch" href="/assets/js/50.926ecfa5.js"><link rel="prefetch" href="/assets/js/51.e776b5b1.js"><link rel="prefetch" href="/assets/js/52.4938314c.js"><link rel="prefetch" href="/assets/js/53.6b4d7266.js"><link rel="prefetch" href="/assets/js/54.bfaf622b.js"><link rel="prefetch" href="/assets/js/55.c6d160b9.js"><link rel="prefetch" href="/assets/js/56.31f6843c.js"><link rel="prefetch" href="/assets/js/57.55cbf7b8.js"><link rel="prefetch" href="/assets/js/58.8174871d.js"><link rel="prefetch" href="/assets/js/59.3eee2bde.js"><link rel="prefetch" href="/assets/js/6.b2e36a75.js"><link rel="prefetch" href="/assets/js/60.233a32ed.js"><link rel="prefetch" href="/assets/js/61.defb83ac.js"><link rel="prefetch" href="/assets/js/62.442070cd.js"><link rel="prefetch" href="/assets/js/63.cc121456.js"><link rel="prefetch" href="/assets/js/64.c8f83f5d.js"><link rel="prefetch" href="/assets/js/65.b9bc8c1c.js"><link rel="prefetch" href="/assets/js/7.fb6689bf.js"><link rel="prefetch" href="/assets/js/8.e390cc6b.js"><link rel="prefetch" href="/assets/js/9.c03c9dfe.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.db8a86c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.42b858ce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Keep Running</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/kr/java/jvm/自动内存管理.html" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/kr/database/database.html" class="nav-link">
  数据库
</a></div><div class="nav-item"><a href="/kr/spring/MVC-IOC-AOP.html" class="nav-link">
  Spring
</a></div><div class="nav-item"><a href="/kr/middleware/redis/redis-base.html" class="nav-link">
  Redis/Zookeeper/Kafka
</a></div><div class="nav-item"><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="nav-link">
  大数据
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hadoop/Hadoop-分布式集群容器部署.html" class="sidebar-link">Hadoop概述及分布式集群容器化部署</a></li><li><a href="/kr/bigdata/hadoop/分布式文件系统-HDFS-体系架构及原理.html" class="sidebar-link">分布式文件系统 HDFS 体系架构及原理</a></li><li><a href="/kr/bigdata/hadoop/分布式并行计算-MapReduce-概述及原理.html" class="sidebar-link">分布式并行计算 MapReduce 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/集群资源管理与调度平台-YARN-概述及原理.html" class="sidebar-link">集群资源管理与调度平台 YARN 概述及原理</a></li><li><a href="/kr/bigdata/hadoop/MapReduce-实例-WordCount.html" class="sidebar-link">MapReduce 经典案例：WordCount</a></li><li><a href="/kr/bigdata/hadoop/HDFS-3-X-纠删码.html" class="sidebar-link">HDFS 3.X 纠删码</a></li><li><a href="/kr/bigdata/hadoop/大数据生态圈与离线实时数据平台实践.html" class="sidebar-link">大数据生态圈与离线实时数据平台实践</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/hive/分布式数据仓库-Hive.html" class="sidebar-link">分布式数据仓库 Hive</a></li><li><a href="/kr/bigdata/hive/Hive-SQL.html" class="sidebar-link">Hive SQL 执行计划|数据倾斜|性能优化</a></li><li><a href="/kr/bigdata/hive/HiveSQL-编译过程.html" class="sidebar-link">Hive 工作原理：Hive SQL 编译过程</a></li><li><a href="/kr/bigdata/hive/Hive-function.html" class="sidebar-link">Hive Function</a></li><li><a href="/kr/bigdata/hive/Hive-SQL-Examples.html" class="sidebar-link">Hive SQL Examples</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/spark/Spark-概述与集群部署模式.html" class="sidebar-link">Spark 概述与集群部署模式</a></li><li><a href="/kr/bigdata/spark/Spark-RDD-弹性分布式数据集.html" class="sidebar-link">Spark RDD 弹性分布式数据集</a></li><li><a href="/kr/bigdata/spark/Spark-运行架构.html" class="sidebar-link">Spark 运行架构及作业提交流程</a></li><li><a href="/kr/bigdata/spark/Spark-Streaming.html" class="sidebar-link">Spark Streaming</a></li><li><a href="/kr/bigdata/spark/Spark-sql.html" class="sidebar-link">Spark SQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Other</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/kr/bigdata/Canal-MySQL-binlog-增量订阅与消费组件.html" class="sidebar-link">Canal：MySQL Binlog 增量订阅与消费组件</a></li><li><a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="sidebar-link">Sqoop 数据迁移工具</a></li><li><a href="/kr/bigdata/Flume-基本架构及应用场景.html" class="active sidebar-link">Flume 基本架构及应用场景</a></li><li><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html" class="sidebar-link">Azkaban 编译镜像及基本使用</a></li><li><a href="/kr/bigdata/Maxwell.html" class="sidebar-link">Maxwell</a></li><li><a href="/kr/bigdata/Elaticsearch.html" class="sidebar-link">Elaticsearch</a></li><li><a href="/kr/bigdata/大数据可视化交互平台-Hue.html" class="sidebar-link">大数据可视化交互平台 Hue</a></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-default-content content__default"><h1 id="flume-基本架构及应用场景"><a href="#flume-基本架构及应用场景" class="header-anchor">#</a> Flume 基本架构及应用场景</h1> <p>Apache Flume 是 Cloudera 提供的一个高可用，高可靠，分布式的海量日志采集系统，能够有效的采集、聚合、传输大量日志数据。Flume 支持在日志系统中定制各类数据发送方，用于收集数据，也提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力，通常用于日志数据的收集，Flume 特性：</p> <ul><li>提供上下文路由特征</li> <li>Flume Channel 是基于事务，保证了数据在传送和接收时的一致性</li> <li>具有简单灵活的基于流的数据流架构</li> <li>具有负载均衡机制和故障转移机制，具有健壮性和容错性</li> <li>一个简单可扩展的数据模型(Source、Channel、Sink)，三个组件是可灵活组合的</li></ul> <h2 id="架构和原理"><a href="#架构和原理" class="header-anchor">#</a> 架构和原理</h2> <h3 id="基本架构"><a href="#基本架构" class="header-anchor">#</a> 基本架构</h3> <p><img src="/images/kr/bigdata/flume/flume-architecture.jpg" alt="">
外部数据源以特定格式向 Flume 发送 Event (事件)，当 Source 接收到 Event 时，将其存储到一个或多个 Channel，Channe 会一直保存 Event 直到它被 Sink 所消费。</p> <ul><li>Agent：一个独立 JVM 进程（Flume 代理，提供持续传输数据服务），包含 Source、 Channel、 Sink 等组件</li> <li>Event：Flume NG 数据传输的基本单元，也是事务的基本单位，由 Header 和 Body 组成：
<ul><li>Header：为键-值映射，用来存储 Event 一些属性信息</li> <li>Body：为字节数组，存放采集的具体原始数据</li></ul></li> <li>Source：数据采集组件，从外部数据源采集数据并存储到 Channel，可处理各种类型/格式的数据</li> <li>Channel：是 Source/Sink 之间的管道（缓冲区），允许 Source/Sink 运作在不同的速率上；Channel 是线程安全的，可同时处理多个 Source 的写入操作和多个 Sink 的读取操作。用于临时存储数据，可以是内存或持久化文件系统：
<ul><li>Memory Channel：内存中的队列，优点是速度快，但数据可能会丢失</li> <li>File Channel：持久化文件系统，优点是能保证数据不丢失，但是速度慢</li></ul></li> <li>Sink：主要功能是从 Channel 中轮询读取 Event，并存入外部存储系统或转发到下一个 Source，成功后再从 Channel 中移除 Event</li></ul> <h3 id="组件类型"><a href="#组件类型" class="header-anchor">#</a> 组件类型</h3> <p>Flume 中的每一个组件都提供了丰富的类型，适用于不同场景：
Source：</p> <ul><li>Avro Source：监听网络端口并采集 Avro 序列化的端口数据</li> <li>Thrift Source：监听 Thrift 端口并从外部 Thrift 客户端流接收数据</li> <li>Exec Source：启动指定的 Shell 命令并采集该命令下的输出</li> <li>SpoolDir Source：监控指定文件夹并采集该文件夹中新文件的数据，（注：文件不可变）</li> <li>Taildir Source：监控指定目录下多个文件，采集多个文件中追加的数据</li> <li>Kafka Source：使用 kafka consumer 原理采集 kafka 中的数据</li> <li>NetCat Source：启动 Socket 服务监听端口，并采集端口数据</li></ul> <p>Channel：</p> <ul><li>Memory Channel：Event 存储在内存中，读写速度快，但数据易丢失</li> <li>Jdbc Channel：Event 被持久化到数据库中，目前支持 Derby，适用于可恢复的场景</li> <li>Kafka Channel：Agent 使用 Kafka 作为 Channel 的数据缓存</li> <li>File Channel：Event 被缓存在本地磁盘文件中，可靠性高，不会丢失，但可能会重复数据</li> <li>Spillable Memory Channel：Event 存储在内存和磁盘中，内存充当主存储，磁盘充当溢出</li></ul> <p>Sink：</p> <ul><li>HDFS Sink：数据写入 HDFS，支持 text/sequence 文件且支持压缩，支持多种写入策略</li> <li>Hive Sink：将 Event 以 text/json 数据格式直接存储到 Hive 分区表</li> <li>Logger Sink：数据输出到日志中，通常用于 debug</li> <li>Avro Sink：Avro Sink 可向 Avro Source 发送 Avro 序列化数据，实现 Agent 之间的级联</li> <li>Thrift Sink：同avro sink</li> <li>File Roll Sink：数据存储到本地文件系统</li> <li>Null Sink：直接丢弃</li> <li>HBase Sink：数据存储到 HBase 中</li> <li>ElasticSearch Sink：直接存储到 ES 中</li> <li>Kafka Sink：将数据存储到 Kafka 中</li> <li>HTTP Sink：将接收到的数据通过 Post 请求发送到远程服务，Event 内容作为请求体发送</li></ul> <h2 id="flume-架构模式"><a href="#flume-架构模式" class="header-anchor">#</a> Flume 架构模式</h2> <h3 id="简单串联"><a href="#简单串联" class="header-anchor">#</a> 简单串联</h3> <p><img src="/images/kr/bigdata/flume/%E7%AE%80%E5%8D%95%E4%B8%B2%E8%81%94.png" alt=""></p> <p>Flume 支持跨越多个 Agent 的数据传递，这要求前一个 Agent 的 Sink 和下一个 Agent 的 Source 都必须是 Avro 类型，Sink 指向 Source 所在主机名 (或 IP 地址) 和端口；此模式不建议桥接过多的 Flume 数量，Flume 数量过多不仅会影响传输速率，而且一旦传输过程中某个节点 Flume 宕机，会影响整个传输系统</p> <h3 id="聚合"><a href="#聚合" class="header-anchor">#</a> 聚合</h3> <p><img src="/images/kr/bigdata/flume/%E8%81%9A%E5%90%88.png" alt=""></p> <p>日志收集中常常存在大量的客户端（比如分布式 web 服务），Flume 支持使用多个 Agent 分别收集日志，然后通过一个或者多个 Agent 聚合后再存储到文件系统中</p> <h3 id="复制和多路复用"><a href="#复制和多路复用" class="header-anchor">#</a> 复制和多路复用</h3> <p><img src="/images/kr/bigdata/flume/%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" alt=""></p> <p>Flume 支持从一个 Source 向多个 Channel，也就是向多个 Sink 传递事件，这个操作称之为 Fan Out(扇出)。默认情况下 Fan Out 是向所有的 Channel 复制 Event，即所有 Channel 收到的数据都是相同的。同时 Flume 也支持在 Source 上自定义一个复用选择器 (multiplexing selector) 来实现自定义的路由规则</p> <h3 id="负载均衡和故障转移"><a href="#负载均衡和故障转移" class="header-anchor">#</a> 负载均衡和故障转移</h3> <p><img src="/images/kr/bigdata/flume/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.png" alt=""></p> <p>Flume 支持使用将多个 Sink 逻辑上分到一个 Sink 组，Sink 组配合不同的 SinkProcessor 可以实现负载均衡和故障转移的功能</p> <h2 id="flume-事务"><a href="#flume-事务" class="header-anchor">#</a> Flume 事务</h2> <p><img src="/images/kr/bigdata/flume/Flume-%E4%BA%8B%E5%8A%A1.png" alt=""></p> <p>Channel 使用被动存储机制，依靠 Source 完成数据写入（推送），Sink 完成数据读取（拉取）：
Channel 是先进先出的 Event 队列，Source 到 Channel 是事务性的，Channel 到 Sink 也是完全事务性的，每个 Sink 用 Channel 启用一个事务，批量 Event 一旦成功写到存储系统或下一个 Agent，Sink 就用 Channel 提交事务，事务一旦提交，该 Channel 从自己内部缓冲区删除 Event
Flume 推送事务流程</p> <ul><li>doPut：将批数据先写入临时缓冲区 putList，不是来一条 Event 就处理，是来一批 Event 才处理</li> <li>doCommit：检查 Channel 内存队列空间是否充足，充足则直接写入 Channel 内存队列</li> <li>doRollback：Channel 内存队列空间不足，则回滚数据到 putList，等待重新传递</li></ul> <p>Flume 拉取事务流程</p> <ul><li>doTake：先将数据取到临时缓冲区 takeList，并将数据发送到 HDFS</li> <li>doCommit：如果数据全部发送成功，则清除临时缓冲区 takeList</li> <li>doRollback：数据发送过程中如果出现异常，将临时缓冲区 takeList 中的数据回滚到 Channel 内存队列，等待重新传递</li></ul> <h2 id="flume-agent-内部原理"><a href="#flume-agent-内部原理" class="header-anchor">#</a> Flume Agent 内部原理</h2> <p><img src="/images/kr/bigdata/flume/Agent-%E5%8E%9F%E7%90%86.png" alt=""></p> <ul><li>Source Interceptors：Source 可以指定多个拦截器按先后顺序依次对采集到的数据进行处理</li> <li>Channel Selectors：Source 发送数据到具体 Channel 的选择策略</li> <li>Sink Processors：从 Channel 获取数据的具体 Sink 的选择策略</li></ul> <p>Source Interceptors：</p> <ul><li>Timestamp Interceptor：向 Event 中 Header 添加 Timestamp 时间戳信息</li> <li>Host Interceptor：向 Event 中 Header 添加 Host 属性</li> <li>Search and Replace Interceptor：根据指定规则替换 Event 中 Body 数据</li> <li>Static Interceptor：向 Event 中 Header 添加固定 key/value</li> <li>Regex Extractor Interceptor：根据指定规则从 Event 中 Body 抽取数据，生成 key/value，再把 key/value 添加到 Header 中</li></ul> <p>Channel Selectors：</p> <ul><li>Replicating Selector：复制选择器，默认，将 Event 复制发送到所有 Channel</li> <li>Multiplexing Selector：多路复用选择器，根据 Event 中 Header 将 Event 发送到不同 Channel</li></ul> <p>Sink Processors：</p> <ul><li>Default Processor：默认，不用配置 Sink Group，一个 Channel 接一个 Sink 形式</li> <li>Load balancing Processor：负载均衡处理器，一个 Channle 接多个 Sink(Sink Group)，根据指定的算法进行轮询或随机发送，减轻单个 Sink 压力</li> <li>Failover Processor：故障转移处理器，一个 Channle 接一个 Sink Group，按照 Sink 优先级，默认先让优先级高的 Sink 来处理数据，而低优先级的 Sink 处于等待状态；若发生故障，则由下易优先级的 Sink 处理</li></ul> <h2 id="flume-配置及启动"><a href="#flume-配置及启动" class="header-anchor">#</a> Flume 配置及启动</h2> <div class="language-xml template.conf line-numbers-mode"><pre class="language-xml"><code># 代理及其上组件命名
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sources = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SourceName</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sinks = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SinkName</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.channels = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName1</span><span class="token punctuation">&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName2</span><span class="token punctuation">&gt;</span></span> ...
# 将 Source/Sink 绑定到 Channel
# 一个 Source 可以配置多个 Channel，但一个 Sink 只能配置一个 Channel
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sources.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SourceName</span><span class="token punctuation">&gt;</span></span>.channels = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName1</span><span class="token punctuation">&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName2</span><span class="token punctuation">&gt;</span></span> ...
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sinks.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SinkName</span><span class="token punctuation">&gt;</span></span>.channel = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName1</span><span class="token punctuation">&gt;</span></span>
# 组件属性设置
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sources.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SourceName</span><span class="token punctuation">&gt;</span></span>.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someProperty</span><span class="token punctuation">&gt;</span></span> = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someValue</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.channels.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ChannelName</span><span class="token punctuation">&gt;</span></span>.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someProperty</span><span class="token punctuation">&gt;</span></span> = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someValue</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AgentName</span><span class="token punctuation">&gt;</span></span>.sinks.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>SinkName</span><span class="token punctuation">&gt;</span></span>.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someProperty</span><span class="token punctuation">&gt;</span></span> = <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>someValue</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 开启 Agent 代理，nohup Command &amp;：将 Agent 置为后台服务</span>
<span class="token comment"># --name：Agent name</span>
<span class="token comment"># --conf：flume 安装路径 conf 目录</span>
<span class="token comment"># --conf-file：Agent 配置文件</span>
<span class="token comment"># -Dflume.root.logger=INFO,console：-D：动态修改 flume.root.logger 属性值，并将控制台日志级别设置为 INFO</span>
<span class="token function">nohup</span> flume-ng agent --name agent_name --conf <span class="token variable">$FLUME_HOME</span>/conf/ --conf-file template.conf 
    -Dflume.root.logger<span class="token operator">=</span>INFO,console <span class="token operator">&gt;</span> agent_name.log <span class="token operator">&amp;</span>
<span class="token function">nohup</span> flume-ng agent -n agent_name -c <span class="token variable">$FLUME_HOME</span>/conf/ --f template.conf 
    -Dflume.root.logger<span class="token operator">=</span>INFO,console <span class="token operator">&gt;</span> agent_name.log <span class="token operator">&amp;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="flume-镜像"><a href="#flume-镜像" class="header-anchor">#</a> Flume 镜像</h2> <div class="language-bash Dockerfile line-numbers-mode"><pre class="language-bash"><code>FROM xzx/jdk-1.8
RUN yum -y <span class="token function">install</span> <span class="token function">wget</span>
<span class="token comment"># 下载 Flume 并解压</span>
<span class="token comment"># -nv : wget 关闭详尽输出，但不进入安静模式</span>
<span class="token comment"># 不单独将 wget 当一行命令，因为下载下来的文件在容器中消失</span>
<span class="token comment"># &gt; /dev/null : 丢弃日志输出</span>
RUN <span class="token function">wget</span> -nv https://mirrors.bfsu.edu.cn/apache/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">tar</span> -zxvf apache-flume-1.9.0-bin.tar.gz -C /usr/local <span class="token operator">&gt;</span> /dev/null <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">rm</span> apache-flume-1.9.0-bin.tar.gz <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">mv</span> /usr/local/apache-flume-1.9.0-bin /usr/local/apache-flume-1.9.0
<span class="token comment"># 配置环境变量</span>
ENV FLUME_HOME /usr/local/apache-flume-1.9.0
<span class="token comment"># 将环境变量添加到系统变量中</span>
ENV <span class="token environment constant">PATH</span> <span class="token variable">$FLUME_HOME</span>/bin:<span class="token environment constant">$PATH</span>
<span class="token comment"># 修改配置</span>
RUN <span class="token function">cp</span> <span class="token variable">$FLUME_HOME</span>/conf/flume-env.sh.template <span class="token variable">$FLUME_HOME</span>/conf/flume-env.sh
<span class="token comment"># 导入 hadoop 依赖包</span>
RUN <span class="token function">wget</span> -nv https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">tar</span> -zxvf hadoop-3.2.2.tar.gz -C /usr/local <span class="token operator">&gt;</span> /dev/null <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">cp</span> /usr/local/hadoop-3.2.2/share/hadoop/common/*.jar <span class="token variable">$FLUME_HOME</span>/lib <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">cp</span> /usr/local/hadoop-3.2.2/share/hadoop/common/lib/*.jar <span class="token variable">$FLUME_HOME</span>/lib <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">cp</span> /usr/local/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-*.jar <span class="token variable">$FLUME_HOME</span>/lib <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">rm</span> hadoop-3.2.2.tar.gz <span class="token operator">&amp;&amp;</span> <span class="token punctuation">\</span>
        <span class="token function">rm</span> -rf /usr/local/hadoop-3.2.2
<span class="token comment"># 解决包冲突：flume 的为低版本，删掉即可</span>
RUN <span class="token function">rm</span> <span class="token variable">$FLUME_HOME</span>/lib/guava-11.0.2.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><h2 id="flume-案例"><a href="#flume-案例" class="header-anchor">#</a> Flume 案例</h2> <h3 id="案例一-监控本机端口数据"><a href="#案例一-监控本机端口数据" class="header-anchor">#</a> 案例一：监控本机端口数据</h3> <p>使用 Flume 监听本机一个端口，收集该端口数据，并打印到控制台</p> <div class="language-bash flume-netcat-logger.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 监听本机端口数据</span>
fnl.sources <span class="token operator">=</span> fnl_r
fnl.sinks <span class="token operator">=</span> fnl_k
fnl.channels <span class="token operator">=</span> fnl_c
fnl.sources.fnl_r.type <span class="token operator">=</span> netcat                 <span class="token comment"># 输入类型为 netcat 端口类型</span>
fnl.sources.fnl_r.bind <span class="token operator">=</span> xzx-flume              <span class="token comment"># 监听本机</span>
fnl.sources.fnl_r.port <span class="token operator">=</span> <span class="token number">44444</span>                  <span class="token comment"># 监听端口</span>
fnl.sinks.fnl_k.type <span class="token operator">=</span> logger                   <span class="token comment"># 输出目的地：控制台</span>
fnl.channels.fnl_c.type <span class="token operator">=</span> memory                <span class="token comment"># channel 类型为内存</span>
fnl.channels.fnl_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>              <span class="token comment"># channel 总量 1000 个事件</span>
fnl.channels.fnl_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>    <span class="token comment"># channel 采集了 100 个事件再提交事务</span>
fnl.sources.fnl_r.channels <span class="token operator">=</span> fnl_c
fnl.sinks.fnl_k.channel <span class="token operator">=</span> fnl_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 先启动 flume agent 监听本机端口</span>
<span class="token function">nohup</span> flume-ng agent --name fnl --conf <span class="token variable">$FLUME_HOME</span>/conf/ --conf-file flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console <span class="token operator">&gt;</span> logs/fnl.log <span class="token operator">&amp;</span>
<span class="token comment"># 使用 netcat 工具发送数据至本机端口</span>
<span class="token function">nc</span> xzx-flume <span class="token number">444444</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="案例二-实时监控单个追加文件"><a href="#案例二-实时监控单个追加文件" class="header-anchor">#</a> 案例二：实时监控单个追加文件</h3> <p>实时监控 Hive 日志，并上传到 HDFS 中</p> <div class="language-bash flume-file-hdfs.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 实时监控单个追加文件</span>
ffh.sources <span class="token operator">=</span> ffh_r
ffh.sinks <span class="token operator">=</span> ffh_k
ffh.channels <span class="token operator">=</span> ffh_c
ffh.sources.ffh_r.type <span class="token operator">=</span> <span class="token builtin class-name">exec</span>                   <span class="token comment"># exec 可执行命令</span>
ffh.sources.ffh_r.command <span class="token operator">=</span> <span class="token function">tail</span> -F hive.log
ffh.sources.ffh_r.shell <span class="token operator">=</span> /bin/bash -c          <span class="token comment"># 执行 shell 脚本的绝对路径</span>
ffh.sinks.ffh_k.type <span class="token operator">=</span> hdfs
ffh.sinks.ffh_k.hdfs.path <span class="token operator">=</span> hdfs://xzx-hadoop-master:9000/flume/%Y%m%d/%H
ffh.sinks.ffh_k.hdfs.filePrefix <span class="token operator">=</span> logs-         <span class="token comment"># 上传文件的前缀</span>
ffh.sinks.ffh_k.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>               <span class="token comment"># 是否按照时间滚动文件夹</span>
ffh.sinks.ffh_k.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>             <span class="token comment"># 多少时间单位创建一个新文件夹</span>
ffh.sinks.ffh_k.hdfs.roundUnit <span class="token operator">=</span> hour           <span class="token comment"># 定义时间单位</span>
ffh.sinks.ffh_k.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>   <span class="token comment"># 是否使用本地时间戳</span>
ffh.sinks.ffh_k.hdfs.batchSize <span class="token operator">=</span> <span class="token number">1000</span>           <span class="token comment"># 多少个 Event 才 flush 到 HDFS 一次</span>
ffh.sinks.ffh_k.hdfs.fileType <span class="token operator">=</span> DataStream      <span class="token comment"># 设置文件类型，可支持压缩</span>
ffh.sinks.ffh_k.hdfs.codeC <span class="token operator">=</span> lzop               <span class="token comment"># 支持压缩方式</span>
ffh.sinks.ffh_k.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">30</span>          <span class="token comment"># 多久生成一个新的文件</span>
ffh.sinks.ffh_k.hdfs.roolSize <span class="token operator">=</span> <span class="token number">134217700</span>       <span class="token comment"># 设置每个文件的滚动大小，128M</span>
ffh.sinks.ffh_k.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>              <span class="token comment"># 文件的滚动与 Event 数量无关</span>
ffh.channels.ffh_c.type <span class="token operator">=</span> memory
ffh.channels.ffh_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
ffh.channels.ffh_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
ffh.sources.ffh_r.channels <span class="token operator">=</span> ffh_c
ffh.sinks.ffh_k.channel <span class="token operator">=</span> ffh_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># HDFS Sink 采用 lzo 压缩时，需要 hadoop 配置 lzo 支持，并建立以下软连接，以便找到压缩相关类</span>
<span class="token function">ln</span> -s /usr/local/hadoop-3.1.3/etc/hadoop/core-site.xml /usr/local/flume-1.9.0/conf/core-site.xml
lrwxrwxrwx. <span class="token number">1</span> root root   <span class="token number">48</span> Sep <span class="token number">26</span> 08:45 core-site.xml -<span class="token operator">&gt;</span> /usr/local/hadoop-3.1.3/etc/hadoop/core-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="案例三-实时监控目录下多个新文件"><a href="#案例三-实时监控目录下多个新文件" class="header-anchor">#</a> 案例三：实时监控目录下多个新文件</h3> <p>使用 Flume 监听整个目录的文件，并上传至 HDFS</p> <div class="language-bash flume-dir-hdfs.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 实时监控目录下单个新文件，不要在监控目录中创建并持续修改文件，被监控文件夹每500 毫秒扫描一次文件</span>
fdh.sources <span class="token operator">=</span> fdh_r
fdh.sinks <span class="token operator">=</span> fdh_k
fdh.channels <span class="token operator">=</span> fdh_c
fdh.sources.fdh_r.type <span class="token operator">=</span> spooldir                   <span class="token comment"># 目录类型</span>
fdh.sources.fdh_r.spooldir <span class="token operator">=</span> /flume/upload          <span class="token comment"># 监控目录</span>
fdh.sources.fdh_r.fileSuffix <span class="token operator">=</span> .COMPLETED           <span class="token comment"># 文件上传完后的文件后缀</span>
fdh.sources.fdh_r.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span>                 <span class="token comment"># 是否有文件头</span>
fdh.sources.fdh_r.ignorePattern <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>^ <span class="token punctuation">]</span>*<span class="token punctuation">\</span>.tmp<span class="token punctuation">)</span>      <span class="token comment"># 忽略所有 .tmp 后缀的文件，不上传</span>
fdh.sinks.fdh_k.type <span class="token operator">=</span> hdfs
fdh.sinks.fdh_k.hdfs.path <span class="token operator">=</span> hdfs://xzx-hadoop-master:9000/flume/upload/%Y%m%d/%H
fdh.sinks.fdh_k.hdfs.filePrefix <span class="token operator">=</span> upload-           <span class="token comment"># 上传文件到 HDFS 的前缀</span>
fdh.sinks.fdh_k.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>                   <span class="token comment"># 是否按时间滚动文件</span>
fdh.sinks.fdh_k.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>                 <span class="token comment"># 多少时间单位创建一个新文件夹</span>
fdh.sinks.fdh_k.hdfs.roundUnit <span class="token operator">=</span> hour               <span class="token comment"># 时间单位</span>
fdh.sinks.fdh_k.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>       <span class="token comment"># 是否使用本地时间戳</span>
fdh.sinks.fdh_k.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>                <span class="token comment"># 多少个 Event 才 flush 到 HDFS 一次</span>
fdh.sinks.fdh_k.hdfs.fileType <span class="token operator">=</span> DataStream          <span class="token comment"># 设置文件类型，可支持压缩</span>
fdh.sinks.fdh_k.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">60</span>              <span class="token comment"># 多久生成新文件</span>
fdh.sinks.fdh_k.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>           <span class="token comment"># 设置每个文件的滚动大小，128M</span>
fdh.sinks.fds_k.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>                  <span class="token comment"># 文件的滚动与 Event 数量无关</span>
fdh.channels.fdh_c.type <span class="token operator">=</span> memory
fdh.channels.fdh_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
fdh.channels.fdh_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
fdh.sources.fdh_r.channels <span class="token operator">=</span> fdh_c
fdh.sinks.fdh_k.channel <span class="token operator">=</span> fdh_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><h3 id="案例四-实时监控目录下的多个追加文件"><a href="#案例四-实时监控目录下的多个追加文件" class="header-anchor">#</a> 案例四：实时监控目录下的多个追加文件</h3> <ul><li>Exec source：适用于监控一个实时追加的文件，但不能保证数据不丢失</li> <li>Spooldir Source：能够保证数据不丢失，且能够实现断点续传，但延迟较高，不能实时监控</li> <li>Taildir Source 既能够实现断点续传，又可以保证数据不丢失，还能够进行实时监控</li></ul> <p>使用 Flume 监听整个目录的实时追加文件，并上传至 HDFS</p> <div class="language-bash flume-taildir-hdfs.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 实时监控目录下的多个追加文件</span>
fth.sources <span class="token operator">=</span> fth_r
fth.sinks <span class="token operator">=</span> fth_k
fth.channels <span class="token operator">=</span> fth_c
fth.sources.fth_r.type <span class="token operator">=</span> TAILDIR
fth.sources.fth_r.positionFile <span class="token operator">=</span> /flume/upload/tail_dir.json
fth.sources.fth_r.filegroups <span class="token operator">=</span> fl
fth.sources.fth_r.filegroups.fl <span class="token operator">=</span> /opt/module/flume/files/file.*
fth.sinks.fth_k.type <span class="token operator">=</span> hdfs
fth.sinks.fth_k.hdfs.path <span class="token operator">=</span> hdfs://xzx-hadoop-master:9000/flume/upload/%Y%m%d/%H
fth.sinks.fth_k.hdfs.filePrefix <span class="token operator">=</span> upload-
fth.sinks.fth_k.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
fth.sinks.fth_k.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
fth.sinks.fth_k.hdfs.roundUnit <span class="token operator">=</span> hour
fth.sinks.fth_k.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
fth.sinks.fth_k.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>
fth.sinks.fth_k.hdfs.fileType <span class="token operator">=</span> DataStream
fth.sinks.fth_k.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">60</span>
fth.sinks.fth_k.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>
fth.sinks.fts_k.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>
fth.channels.fth_c.type <span class="token operator">=</span> memory
fth.channels.fth_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
fth.channels.fth_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
fth.sources.fth_r.channels <span class="token operator">=</span> fth_c
fth.sinks.fth_k.channel <span class="token operator">=</span> fth_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>Taildir 说明：
Taildir Source 维护了一个 json 格式的 position File，其会定期的往 position File 中更新每个文件读取到的最新的位置，因此能够实现断点续传。
Position File 的格式如下：</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span><span class="token property">&quot;inode&quot;</span><span class="token operator">:</span><span class="token number">2496272</span><span class="token punctuation">,</span><span class="token property">&quot;pos&quot;</span><span class="token operator">:</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token property">&quot;file&quot;</span><span class="token operator">:</span><span class="token string">&quot;/opt/module/flume/files/file1.txt&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;inode&quot;</span><span class="token operator">:</span><span class="token number">2496275</span><span class="token punctuation">,</span><span class="token property">&quot;pos&quot;</span><span class="token operator">:</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token property">&quot;file&quot;</span><span class="token operator">:</span><span class="token string">&quot;/opt/module/flume/files/file2.txt&quot;</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><blockquote><p>Linux 中储存文件元数据的区域叫 inode，每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件，Unix/Linux 系统内部不使用文件名，而使用 inode 号码来识别文件</p></blockquote> <h3 id="案例五-复制和多路复用"><a href="#案例五-复制和多路复用" class="header-anchor">#</a> 案例五：复制和多路复用</h3> <p>使用 Flume-1 监控文件变动，Flume-1 将变动内容传递给 Flume-2，Flume-2 负责存储到 HDFS；同时 Flume-1 将变动内容传递给 Flume-3，Flume-3 负责输出到 Local FileSystem</p> <div class="language-bash flume-file-flume.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 复制和多路复用</span>
fff.sources <span class="token operator">=</span> fff_r
fff.sinks <span class="token operator">=</span> fff_k1 fff_k2
fff.channels <span class="token operator">=</span> fff_c1 fff_c2
fff.sources.fff_r.selector.type <span class="token operator">=</span> replicating           <span class="token comment"># 将数据流复制给所有 Channel</span>
fff.sources.fff_r.type <span class="token operator">=</span> <span class="token builtin class-name">exec</span>
fff.sources.fff_r.command <span class="token operator">=</span> <span class="token function">tail</span> -F hive.log
fff.sources.fff_r.shell <span class="token operator">=</span> /bin/bash -c
fff.sinks.fff_k1.type <span class="token operator">=</span> avro                            <span class="token comment"># sink 端的 avro 是一个数据发送者</span>
fff.sinks.fff_k1.hostname <span class="token operator">=</span> xzx-flume
fff.sinks.fff_k1.port <span class="token operator">=</span> <span class="token number">4141</span>
fff.sinks.fff_k2.type <span class="token operator">=</span> avro
fff.sinks.fff_k2.hostname <span class="token operator">=</span> xzx-flume
fff.sinks.fff_k2.port <span class="token operator">=</span> <span class="token number">4142</span>
fff.channels.fff_c1.type <span class="token operator">=</span> memory
fff.channels.fff_c1.capacity <span class="token operator">=</span> <span class="token number">1000</span>
fff.channels.fff_c1.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
fff.channels.fff_c2.type <span class="token operator">=</span> memory
fff.channels.fff_c2.capacity <span class="token operator">=</span> <span class="token number">1000</span>
fff.channels.fff_c2.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
fff.sources.fff_r.channels <span class="token operator">=</span> fff_c1 fff_c2
fff.sinks.fff_k1.channel <span class="token operator">=</span> fff_c1
fff.sinks.fff_k2.channel <span class="token operator">=</span> fff_c2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><div class="language-bash flume-flume-hdfs.conf line-numbers-mode"><pre class="language-bash"><code>ffh.sources <span class="token operator">=</span> ffh_r
ffh.sinks <span class="token operator">=</span> ffh_k
ffh.channels <span class="token operator">=</span> ffh_c
ffh.sources.ffh_r.type <span class="token operator">=</span> avro               <span class="token comment"># source 端的 avro 是一个数据接收服务</span>
ffh.sources.ffh_r.bind <span class="token operator">=</span> xzx-flume
ffh.sources.ffh_r.port <span class="token operator">=</span> <span class="token number">4141</span>
ffh.sinks.ffh_k.type <span class="token operator">=</span> hdfs
ffh.sinks.ffh_k.hdfs.path <span class="token operator">=</span> hdfs://xzx-hadoop-master:9000/flume/%Y%m%d/%H
ffh.sinks.ffh_k.hdfs.filePrefix <span class="token operator">=</span> flume-
ffh.sinks.ffh_k.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
ffh.sinks.ffh_k.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
ffh.sinks.ffh_k.hdfs.roundUnit <span class="token operator">=</span> hour
ffh.sinks.ffh_k.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
ffh.sinks.ffh_k.hdfs.batchSize <span class="token operator">=</span> <span class="token number">1000</span>
ffh.sinks.ffh_k.hdfs.fileType <span class="token operator">=</span> DataStream
ffh.sinks.ffh_k.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">600</span>
ffh.sinks.ffh_k.hdfs.roolSize <span class="token operator">=</span> <span class="token number">134217700</span>
ffh.sinks.ffh_k.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>
ffh.channels.ffh_c.type <span class="token operator">=</span> memory
ffh.channels.ffh_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
ffh.channels.ffh_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
ffh.sources.ffh_r.channels <span class="token operator">=</span> ffh_c
ffh.sinks.ffh_k.channel <span class="token operator">=</span> ffh_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><div class="language-bash flume-flume-dir.conf line-numbers-mode"><pre class="language-bash"><code>ffd.sources <span class="token operator">=</span> ffd_r
ffd.sinks <span class="token operator">=</span> ffd_k
ffd.channels <span class="token operator">=</span> ffd_c
ffd.sources.ffd_r.type <span class="token operator">=</span> avro
ffd.sources.ffd_r.bind <span class="token operator">=</span> xzx-flume
ffd.sources.ffd_r.port <span class="token operator">=</span> <span class="token number">4142</span>
ffd.sinks.ffd_k.type <span class="token operator">=</span> file_roll
ffd.sinks.ffd_k.directory <span class="token operator">=</span> /flume          <span class="token comment"># 本地已经存在的目录，不存在也不会自动创建</span>
ffd.channels.ffd_c.type <span class="token operator">=</span> memory
ffd.channels.ffd_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
ffd.channels.ffd_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
ffd.sources.ffd_r.channels <span class="token operator">=</span> ffd_c
ffd.sinks.ffd_k.channel <span class="token operator">=</span> ffd_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><h3 id="案例六-负载均衡和故障转移"><a href="#案例六-负载均衡和故障转移" class="header-anchor">#</a> 案例六：负载均衡和故障转移</h3> <p>使用 Flume 监控一个端口，其 Sink 组中的 Sink 分别对接 Flume2 和 Flume3，采用 FailoverSinkProcessor 实现故障转移的功能</p> <div class="language-bash flume-netcat-flume.conf line-numbers-mode"><pre class="language-bash"><code>fnf.sources <span class="token operator">=</span> fnf_r
fnf.channels <span class="token operator">=</span> fnf_c
fnf.sinkgroups <span class="token operator">=</span> fnf_g
fnf.sinks <span class="token operator">=</span> fnf_k1 fnf_k2
fnf.sources.fnf_r.type <span class="token operator">=</span> netcat
fnf.sources.fnf_r.bind <span class="token operator">=</span> xzx-flume
fnf.sources.fnf_r.port <span class="token operator">=</span> <span class="token number">44444</span>
fnf.sinkgroups.fnf_g.processor.type <span class="token operator">=</span> failover
fnf.sinkgroups.fnf_g.processor.priority.fnf_k1 <span class="token operator">=</span> <span class="token number">5</span>
fnf.sinkgroups.fnf_g.processor.priority.fnf_k2 <span class="token operator">=</span> <span class="token number">10</span>
fnf.sinkgroups.fnf_g.processor.maxpenalty <span class="token operator">=</span> <span class="token number">10000</span>
fnf.sinks.fnf_k1.type <span class="token operator">=</span> avro
fnf.sinks.fnf_k1.hostname <span class="token operator">=</span> xzx-flume
fnf.sinks.fnf_k1.port <span class="token operator">=</span> <span class="token number">4141</span>
fnf.sinks.fnf_k2.type <span class="token operator">=</span> avro
fnf.sinks.fnf_k2.hostname <span class="token operator">=</span> xzx-flume
fnf.sinks.fnf_k2.port <span class="token operator">=</span> <span class="token number">4142</span>
fnf.channels.fnf_c.type <span class="token operator">=</span> memory
fnf.channels.fnf_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
fnf.channels.fnf_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
fnf.sources.fnf_r.channels <span class="token operator">=</span> fnf_c
fnf.sinkgroups.fnf_g.sinks <span class="token operator">=</span> fnf_k1 fnf_k2
fnf.sinks.fnf_k1.channel <span class="token operator">=</span> fnf_c
fnf.sinks.fnf_k2.channel <span class="token operator">=</span> fnf_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><div class="language-bash flume-flume-console1.conf line-numbers-mode"><pre class="language-bash"><code>ffc1.sources <span class="token operator">=</span> ffc1_r
ffc1.sinks <span class="token operator">=</span> ffc1_k
ffc1.channels <span class="token operator">=</span> ffc1_c
ffc1.sources.ffc1_r.type <span class="token operator">=</span> avro
ffc1.sources.ffc1_r.bind <span class="token operator">=</span> xzx-flume
ffc1.sources.ffc1_r.port <span class="token operator">=</span> <span class="token number">4141</span>
ffc1.sinks.ffc1_k.type <span class="token operator">=</span> logger
ffc1.channels.ffc1_c.type <span class="token operator">=</span> memory
ffc1.channels.ffc1_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
ffc1.channels.ffc1_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
ffc1.sources.ffc1_r.channels <span class="token operator">=</span> ffc1_c
ffc1.sinks.ffc1_k.channel <span class="token operator">=</span> ffc1_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><div class="language-bash flume-flume-console2.conf line-numbers-mode"><pre class="language-bash"><code>ffc2.sources <span class="token operator">=</span> ffc2_r
ffc2.sinks <span class="token operator">=</span> ffc2_k
ffc2.channels <span class="token operator">=</span> ffc2_c
ffc2.sources.ffc2_r.type <span class="token operator">=</span> avro
ffc2.sources.ffc2_r.bind <span class="token operator">=</span> xzx-flume
ffc2.sources.ffc2_r.port <span class="token operator">=</span> <span class="token number">4142</span>
ffc2.sinks.ffc2_k.type <span class="token operator">=</span> logger
ffc2.channels.ffc2_c.type <span class="token operator">=</span> memory
ffc2.channels.ffc2_c.capacity <span class="token operator">=</span> <span class="token number">1000</span>
ffc2.channels.ffc2_c.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
ffc2.sources.ffc2_r.channels <span class="token operator">=</span> ffc2_c
ffc2.sinks.ffc2_k.channel <span class="token operator">=</span> ffc2_c
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h2 id="整合-kafka"><a href="#整合-kafka" class="header-anchor">#</a> 整合 Kafka</h2> <p>以实时流处理项目（如电商平台）为例，由于采集数据量可能存在峰值和峰谷，如果直接将 Flume 聚合后数据输入到 Storm 等分布式计算框架中，可能会超过集群处理能力，通过采用 Kafka 起到削峰作用。
<img src="/images/kr/bigdata/flume/flume-kafka.png" alt="">
Flume 发送数据到 Kafka 上主要是通过 KafkaSink 来实现：</p> <div class="language-bash exec-memory-kafka.properties line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 监听 kafka.log 文件，当文件内容有变化时，将新增加的内容发送到 Kafka 的 flume-kafka 主题上</span>
a1.sources <span class="token operator">=</span> s1
a1.channels <span class="token operator">=</span> c1
a1.sinks <span class="token operator">=</span> k1                                                                                        
a1.sources.s1.type<span class="token operator">=</span>exec
a1.sources.s1.command<span class="token operator">=</span>tail -F /tmp/kafka.log
a1.sources.s1.channels<span class="token operator">=</span>c1 

<span class="token comment">#设置 Kafka 接收器</span>
a1.sinks.k1.type<span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
<span class="token comment">#设置 Kafka 地址</span>
a1.sinks.k1.brokerList<span class="token operator">=</span>xzx:9092
<span class="token comment">#设置发送到 Kafka 上的主题</span>
a1.sinks.k1.topic<span class="token operator">=</span>flume-kafka
<span class="token comment">#设置序列化方式</span>
a1.sinks.k1.serializer.class<span class="token operator">=</span>kafka.serializer.StringEncoder
a1.sinks.k1.channel<span class="token operator">=</span>c1     

a1.channels.c1.type<span class="token operator">=</span>memory
a1.channels.c1.capacity<span class="token operator">=</span><span class="token number">10000</span>
a1.channels.c1.transactionCapacity<span class="token operator">=</span><span class="token number">100</span>   
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><h2 id="flume-优化"><a href="#flume-优化" class="header-anchor">#</a> Flume 优化</h2> <h3 id="flume-进程内存"><a href="#flume-进程内存" class="header-anchor">#</a> Flume 进程内存</h3> <p>Flume 进程内存根据 Agent 读取的数据量大小及速度决定，一般建议内存设置为 1G~2G，内存太小频繁 GC ，影响执行效率。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 查看进程 GC 信息，1000：每一秒刷新一次</span>
jstat -gcutil PID <span class="token number">1000</span>
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">96.81</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">96.81</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">97.70</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">97.70</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">97.70</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">97.70</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">97.70</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">98.59</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
 <span class="token number">10.42</span>   <span class="token number">0.00</span>  <span class="token number">98.59</span>  <span class="token number">40.49</span>  <span class="token number">96.87</span>  <span class="token number">91.64</span>     <span class="token number">12</span>    <span class="token number">0.025</span>     <span class="token number">0</span>    <span class="token number">0.000</span>    <span class="token number">0.025</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li>YGC：：表示新生代堆内存 GC 次数</li> <li>YGCT：表示新生代堆内存 GC 消耗的总时间</li> <li>FGC：FULL GC 发生次数，若发生 FUCC GC，则 Flume 进程会进入暂停状态，FUCC GC 执行完以后 Flume 才会继续工作</li> <li>GCT：所有类型的 GC 消耗的总时间</li></ul> <div class="language-bash flume-env.sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 调整 Flume 进程内存，Xms/Xmx 建议一样大，避免内存交换，内存交换也比较耗性能</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_OPTS</span><span class="token operator">=</span><span class="token string">&quot;-Xms1024m -Xmx1024m -Dcom.sun.management.jmxremote&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="区分日志文件"><a href="#区分日志文件" class="header-anchor">#</a> 区分日志文件</h3> <p>在一台服务器启动多个 Agent 时，建议修改配置区分日志文件。
在 conf 目录下有 log4j.properties，在这里面指定了日志文件的名称和位置，所有使用 conf 目录下面配置启动的 Agent 产生的日志都会记录到同一个日志文件中。
拷贝多个 conf 目录，然后修改对应 conf 目录中 log4j.properties 日志的文件名称(可以保证多个 Agent 的日志分别存储)，并且把日志级别调整为 warn(减少垃圾日志的产生)。</p> <h2 id="flume-进程监控"><a href="#flume-进程监控" class="header-anchor">#</a> Flume 进程监控</h2> <p>针对 Flume 中 Agent 单进程的单点故障问题，实现一个监控告警机制，并且尝试自动重启的思路：</p> <ul><li>首先需要有一个配置文件，配置文件中指定需要监控的 Agent</li> <li>通过 Shell 脚本负责读取配置文件，定时挨个检查 Agent 对应的进程还在不在，如果发现对应的进程不在，则记录错误信息，然后告警(发短信或者发邮件) 并尝试重启</li></ul> <div class="language-bash monlist.conf line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 配置需要监控的 Agent 及对应的进程启动脚本</span>
<span class="token assign-left variable">a1</span><span class="token operator">=</span>startAgent.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><div class="language-bash startAgent.sh line-numbers-mode"><pre class="language-bash"><code><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Agent 启动脚本</span>
<span class="token assign-left variable">flume_path</span><span class="token operator">=</span>/usr/local/apache-flume-1.9.0
<span class="token comment"># Agent 启动</span>
<span class="token function">nohup</span> <span class="token variable">${flume_path}</span>/bin/flume-ng agent --name a1 --conf <span class="token variable">${flume_path}</span>/conf/ --conf-file /data/flume/conf/exec-memory-logger.properties <span class="token operator">&amp;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><div class="language-bash monlist.sh line-numbers-mode"><pre class="language-bash"><code><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># 监控检查某个 Agent 进程是否存在，不存在则重启该进程</span>
<span class="token assign-left variable">monlist</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">cat</span> monlist.conf<span class="token variable">`</span></span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;start check Flume Agent ...&quot;</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">item</span> <span class="token keyword">in</span> <span class="token variable">${monlist}</span>
<span class="token keyword">do</span>
        <span class="token comment"># 设置字段分隔符</span>
        <span class="token assign-left variable">OLD_IFS</span><span class="token operator">=</span><span class="token environment constant">$IFS</span>
        <span class="token assign-left variable"><span class="token environment constant">IFS</span></span><span class="token operator">=</span><span class="token string">&quot;=&quot;</span>
        <span class="token comment"># 把一行内容转成多列[数组]</span>
        <span class="token assign-left variable">arr</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token variable">$item</span><span class="token punctuation">)</span>
        <span class="token comment"># 获取 Agent 唯一标识</span>
        <span class="token assign-left variable">name</span><span class="token operator">=</span><span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span>
        <span class="token comment"># 获取 Agent 启动脚本</span>
        <span class="token assign-left variable">script</span><span class="token operator">=</span><span class="token variable">${arr<span class="token punctuation">[</span>1<span class="token punctuation">]</span>}</span>
        <span class="token builtin class-name">echo</span> <span class="token string">&quot;time is:&quot;</span><span class="token variable"><span class="token variable">`</span><span class="token function">date</span> +<span class="token string">&quot;%Y-%m-%d %H:%M:%S&quot;</span><span class="token variable">`</span></span><span class="token string">&quot; check &quot;</span><span class="token variable">$name</span>
        <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable"><span class="token variable">`</span>jps -m <span class="token operator">|</span> <span class="token function">grep</span> $name <span class="token operator">|</span> <span class="token function">wc</span> -l<span class="token variable">`</span></span> -eq <span class="token number">0</span> <span class="token punctuation">]</span>
        <span class="token keyword">then</span>
                <span class="token comment"># 发短信或者邮件告警</span>
                <span class="token builtin class-name">echo</span> <span class="token variable"><span class="token variable">`</span><span class="token function">date</span> +<span class="token string">&quot;%Y-%m-%d %H:%M:%S&quot;</span><span class="token variable">`</span></span><span class="token variable">$name</span> <span class="token string">&quot;is none&quot;</span>
                <span class="token function">sh</span> -x ./<span class="token variable">${script}</span>
        <span class="token keyword">fi</span>
<span class="token keyword">done</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># crontab 定时调度 monlist.sh 监控脚本</span>
* * * * * root /bin/bash /data/soft/monlist.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">2022/6/8</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/kr/bigdata/Sqoop-数据迁移工具.html" class="prev">
          Sqoop 数据迁移工具
        </a></span> <span class="next"><a href="/kr/bigdata/Azkaban-编译镜像及基本使用.html">
          Azkaban 编译镜像及基本使用
        </a>
        →
      </span></p></div> </main></div> <aside class="page-sidebar"> <div class="page-side-toolbar"><div class="option-box-toc-fixed"><div class="toc-container-sidebar"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:650px"><div style="font-weight:bold;text-align:center;">Flume 基本架构及应用场景</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#架构和原理" class="toc-sidebar-link">架构和原理</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#基本架构" class="toc-sidebar-link">基本架构</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#组件类型" class="toc-sidebar-link">组件类型</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-架构模式" class="toc-sidebar-link">Flume 架构模式</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#简单串联" class="toc-sidebar-link">简单串联</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#聚合" class="toc-sidebar-link">聚合</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#复制和多路复用" class="toc-sidebar-link">复制和多路复用</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#负载均衡和故障转移" class="toc-sidebar-link">负载均衡和故障转移</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-事务" class="toc-sidebar-link">Flume 事务</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-agent-内部原理" class="toc-sidebar-link">Flume Agent 内部原理</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-配置及启动" class="toc-sidebar-link">Flume 配置及启动</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-镜像" class="toc-sidebar-link">Flume 镜像</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-案例" class="toc-sidebar-link">Flume 案例</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例一-监控本机端口数据" class="toc-sidebar-link">案例一：监控本机端口数据</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例二-实时监控单个追加文件" class="toc-sidebar-link">案例二：实时监控单个追加文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例三-实时监控目录下多个新文件" class="toc-sidebar-link">案例三：实时监控目录下多个新文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例四-实时监控目录下的多个追加文件" class="toc-sidebar-link">案例四：实时监控目录下的多个追加文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例五-复制和多路复用" class="toc-sidebar-link">案例五：复制和多路复用</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例六-负载均衡和故障转移" class="toc-sidebar-link">案例六：负载均衡和故障转移</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#整合-kafka" class="toc-sidebar-link">整合 Kafka</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-优化" class="toc-sidebar-link">Flume 优化</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-进程内存" class="toc-sidebar-link">Flume 进程内存</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#区分日志文件" class="toc-sidebar-link">区分日志文件</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-进程监控" class="toc-sidebar-link">Flume 进程监控</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div> <div class="option-box-toc-over"><img src="/images/system/toc.png" class="nozoom"> <span class="show-txt">目录</span> <div class="toc-container"><div class="pos-box"><div class="icon-arrow"></div> <div class="scroll-box" style="max-height:550px"><div style="font-weight:bold;text-align:center;">Flume 基本架构及应用场景</div> <hr> <div class="toc-box"><ul class="toc-sidebar-links"><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#架构和原理" class="toc-sidebar-link">架构和原理</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#基本架构" class="toc-sidebar-link">基本架构</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#组件类型" class="toc-sidebar-link">组件类型</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-架构模式" class="toc-sidebar-link">Flume 架构模式</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#简单串联" class="toc-sidebar-link">简单串联</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#聚合" class="toc-sidebar-link">聚合</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#复制和多路复用" class="toc-sidebar-link">复制和多路复用</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#负载均衡和故障转移" class="toc-sidebar-link">负载均衡和故障转移</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-事务" class="toc-sidebar-link">Flume 事务</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-agent-内部原理" class="toc-sidebar-link">Flume Agent 内部原理</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-配置及启动" class="toc-sidebar-link">Flume 配置及启动</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-镜像" class="toc-sidebar-link">Flume 镜像</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-案例" class="toc-sidebar-link">Flume 案例</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例一-监控本机端口数据" class="toc-sidebar-link">案例一：监控本机端口数据</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例二-实时监控单个追加文件" class="toc-sidebar-link">案例二：实时监控单个追加文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例三-实时监控目录下多个新文件" class="toc-sidebar-link">案例三：实时监控目录下多个新文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例四-实时监控目录下的多个追加文件" class="toc-sidebar-link">案例四：实时监控目录下的多个追加文件</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例五-复制和多路复用" class="toc-sidebar-link">案例五：复制和多路复用</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#案例六-负载均衡和故障转移" class="toc-sidebar-link">案例六：负载均衡和故障转移</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#整合-kafka" class="toc-sidebar-link">整合 Kafka</a><ul class="toc-sidebar-sub-headers"></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-优化" class="toc-sidebar-link">Flume 优化</a><ul class="toc-sidebar-sub-headers"><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-进程内存" class="toc-sidebar-link">Flume 进程内存</a></li><li class="toc-sidebar-sub-header"><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#区分日志文件" class="toc-sidebar-link">区分日志文件</a></li></ul></li><li><a href="/kr/bigdata/Flume-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html#flume-进程监控" class="toc-sidebar-link">Flume 进程监控</a><ul class="toc-sidebar-sub-headers"></ul></li></ul></div></div></div></div></div></div>  </aside></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.cfd60917.js" defer></script><script src="/assets/js/4.8234885e.js" defer></script><script src="/assets/js/3.1429892b.js" defer></script><script src="/assets/js/15.9ab1d206.js" defer></script>
  </body>
</html>
