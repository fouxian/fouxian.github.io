(window.webpackJsonp=window.webpackJsonp||[]).push([[23],{479:function(a,t,v){"use strict";v.r(t);var _=v(34),i=Object(_.a)({},(function(){var a=this,t=a.$createElement,v=a._self._c||t;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("h1",{attrs:{id:"大数据生态圈与离线实时数据平台实践"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大数据生态圈与离线实时数据平台实践"}},[a._v("#")]),a._v(" 大数据生态圈与离线实时数据平台实践")]),a._v(" "),v("blockquote",[v("p",[a._v("“不谋万世者，不足谋一时；不谋全局者，不足谋一域”")])]),a._v(" "),v("h2",{attrs:{id:"大数据技术生态体系"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大数据技术生态体系"}},[a._v("#")]),a._v(" 大数据技术生态体系")]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB.png",alt:""}})]),a._v(" "),v("p",[a._v("1）Sqoop：Sqoop 是一款开源的工具，主要用于在Hadoop、Hive 与传统的数据库（MySQL）\n间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进\n到Hadoop 的HDFS 中，也可以将HDFS 的数据导进到关系型数据库中。\n2）Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，\nFlume 支持在日志系统中定制各类数据发送方，用于收集数据；\n3）Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统；4）Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于Hadoop 上存储的大数\n据进行计算。\n5）Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。\n6）Oozie：Oozie 是一个管理Hadoop 作业（job）的工作流程调度管理系统。\n7）Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，\n它是一个适合于非结构化数据存储的数据库。\n8）Hive：Hive 是基于Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张\n数据库表，并提供简单的SQL 查询功能，可以将SQL 语句转换为MapReduce 任务进行运\n行。其优点是学习成本低，可以通过类SQL 语句快速实现简单的MapReduce 统计，不必开\n发专门的MapReduce 应用，十分适合数据仓库的统计分析。\n9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、\n名字服务、分布式同步、组服务等")]),a._v(" "),v("p",[a._v("数据是原油，数据是生产资料，数据和技术驱动，人类正从 IT 时代走向 DT 时代。\n数据从产生到进入数据平台中被消费和使用，包含四大主要过程：数据产生、数据采集和传输、数据存储和处理以及数据应用。\n"),v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.jpg",alt:""}})]),a._v(" "),v("p",[a._v("数据采集传输主要技术：")]),a._v(" "),v("ul",[v("li",[a._v("Sqoop：主要用于 Hadoop\\Hive 与传统数据库间数据传递的离线数据传输工具")]),a._v(" "),v("li",[a._v("Flume：是 Cloudera 提供的一个高可用、高可靠、分布式的海量日志采集、聚合和传输的实时系统")]),a._v(" "),v("li",[a._v("Scribe：Facebook 开源的日志收集系统，为日志的分布式收集、统一处理提供一个可扩展的、高容错的简单实时方案")]),a._v(" "),v("li",[a._v("Kafka：由 LinkedIn 开发的一个分布式消息系统")])]),a._v(" "),v("p",[a._v("数据处理主要技术：")]),a._v(" "),v("ul",[v("li",[a._v("MapReduce：是 Google 公司的运行于大规模集群上的复杂并行计算模型")]),a._v(" "),v("li",[a._v("Hive：一个建立在 Hadoop 体系结构上的一层 SQL 抽象，提供了一些对 Hadoop 文件中的数据集进行数据处理、查询和分析的工具")]),a._v(" "),v("li",[a._v("Spark：具有可伸缩、基于内存计算等特点，且可以直接读写 Hadoop 上任何格式的数据，较好地满足了数据即时查询和迭代分析的需求")]),a._v(" "),v("li",[a._v("Storm：拥有低延迟、分布式、可扩展、高容错等特性，可以保证消息不丢失，目前 Storm、类 Storm 或者基于 Storm 抽象的框架技术是实时处理、流处理领域主要采用的技术")]),a._v(" "),v("li",[a._v("Flink：一个同时面向分布式实时流处理和批量数据处理的开源计算平台，同时支持流处理和批处理")]),a._v(" "),v("li",[a._v("Beam：在 Flink 基础上更进一步，重点在于数据处理的编程范式和接口定义")])]),a._v(" "),v("p",[a._v("数据存储主要技术")]),a._v(" "),v("ul",[v("li",[a._v("HDFS：提供了一个高容错性和高吞吐量的海量数据存储解决方案")]),a._v(" "),v("li",[a._v("HBase：一种构建在 HDFS 之上的分布式、面向列族的存储系统")])]),a._v(" "),v("p",[a._v("数据平台的搭建包含物理和逻辑：")]),a._v(" "),v("ul",[v("li",[a._v("物理数据平台的搭建包括硬件、大数据工具和技术的选型、购买、搭建等")]),a._v(" "),v("li",[a._v("逻辑数据平台的搭建包含数据平台架构设计、数据规范制定、数据开发实施和维护等")])]),a._v(" "),v("h2",{attrs:{id:"离线数据平台的架构、技术和设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#离线数据平台的架构、技术和设计"}},[a._v("#")]),a._v(" 离线数据平台的架构、技术和设计")]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("h3",{attrs:{id:"数据仓库技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库技术"}},[a._v("#")]),a._v(" 数据仓库技术")]),a._v(" "),v("ul",[v("li",[a._v("OLTP：Online Transaction Processing，业务系统数据库，主要用来进行事务处理，OLT[P 数据库最核心的需求是单条记录的高效快速处理，索引技术、分库分表等最根本的诉求就是解决此问题")]),a._v(" "),v("li",[a._v("OLAP：分析型数据库，为了满足分析人员的统计分析需求而发展起来的，通过列存储、列压缩和位图索引等技术可以大大加快响应数据查询请求的速度")])]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/kr/bigdata/hadoop/OLTP-OLAP.jpg",alt:""}})]),a._v(" "),v("p",[a._v("分布式区别：\nOLTP 数据库的分布式主要是为了解决海量单条数据请求的压力，其主要目的是把所有用户请求均匀分布到每个节点上，通常采用行式存储；\nOLAP 数据库的分布式是将用户单次对大数据集的请求任务分配到各个节点上独立计算然后再进行汇总返回给用户，一般采用列式存储")]),a._v(" "),v("blockquote",[v("p",[a._v("对于数据库表来说，列的类型是固定的，所以列存储可以很容易采用高压缩比的算法进行压缩和解压缩，磁盘的I/O会大大减少。列存储非常适合大数据量统计查询的应用场景，因为分析统计常常是针对某列或某些列的，列存储的数据库产品只需读出对应列并处理即可，而不是读出整个表的所有行进行处理")])]),a._v(" "),v("h3",{attrs:{id:"数据仓库建模技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库建模技术"}},[a._v("#")]),a._v(" 数据仓库建模技术")]),a._v(" "),v("h4",{attrs:{id:"ralph-kimball-建模方法论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#ralph-kimball-建模方法论"}},[a._v("#")]),a._v(" Ralph Kimball 建模方法论")]),a._v(" "),v("p",[a._v("利用维度建模理论建模的 Kimball 数据仓库常以星形架构来呈现：\n"),v("img",{attrs:{src:"/images/kr/bigdata/hadoop/Kimball%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%98%9F%E5%BD%A2%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("p",[a._v("采用 Kimball 建模理论的数据仓库体系架构：\n"),v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E9%87%87%E7%94%A8Kimball%E5%BB%BA%E6%A8%A1%E7%90%86%E8%AE%BA%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("p",[a._v("Kimball 维度建模的主题以星形架构为主，主题和主题之间则用一致性维度和企业总线体系架构来保证数据仓库的集成和一致性")]),a._v(" "),v("h4",{attrs:{id:"bill-inmon-建模方法论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#bill-inmon-建模方法论"}},[a._v("#")]),a._v(" Bill Inmon 建模方法论")]),a._v(" "),v("p",[a._v("数据仓库是“在企业管理和决策中面向主题的、集成的、与时间相关的、不可修改的数据集合”，与其他数据库应用不同的是，数据仓库更像一种过程，对分布在企业内部各处的业务数据的整合、加工和分析的过程\n"),v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E9%87%87%E7%94%A8Bill-Inmon%E5%BB%BA%E6%A8%A1%E7%90%86%E8%AE%BA%E7%9A%84%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("h4",{attrs:{id:"区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#区别"}},[a._v("#")]),a._v(" 区别")]),a._v(" "),v("p",[a._v("Inmon的方法是一种由上而下（top-down）的数据仓库构建方法，其主张首先要对企业数据仓库进行总体规划，并将不同的OLTP数据集中到面向主题、集成的、不易失的和时间变化的企业数据仓库中。数据集市应该是数据仓库的子集，每个数据集市都是为独立部门专门设计的\nKimball方法则相反，其是自下向上的（down-top）。Kimball认为数据仓库是一系列数据集市的集合，企业可以通过一致性的维度表和“企业总线架构”来递增式集成各个数据集市，从而构建整个企业的数据仓库\nInmon的方法部署和开发周期较长，但是容易维护而且高度集成；而Kimball的方法可以迅速响应业务需求，快速构建一个数据仓库，但是后期集成和维护较为麻烦")]),a._v(" "),v("h3",{attrs:{id:"数据仓库逻辑分层架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库逻辑分层架构"}},[a._v("#")]),a._v(" 数据仓库逻辑分层架构")]),a._v(" "),v("p",[a._v("离线数据仓库通常基于 Kimball 维度建模理论进行构建，通常从以下三点进行逻辑分层：")]),a._v(" "),v("ul",[v("li",[a._v("隔离性：用户使用的应该是数据平台精心加工后的数据，而不是来自于业务系统的原始数据")]),a._v(" "),v("li",[a._v("性能和可维护性：数据的分层也使得数据仓库的维护变得清晰和便捷")]),a._v(" "),v("li",[a._v("规范性：数据基于一个明确的、公认的口径")])]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E9%80%BB%E8%BE%91%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("ul",[v("li",[a._v("ODS：来自源头的数据表通常会原封不动地存储一份，也称准备区（staging area），ODS 也存储着历史的增量或全量数据")]),a._v(" "),v("li",[a._v("DW：数据仓库明细层（Data Warehouse Detail, DWD）和数据仓库汇总层（Data Warehouse Summary, DWS）的数据是 ODS 层数据经过 ETL 清洗、转换、加载生成的，通常基于 Kimball 维度建模理论进行构建，并通过一致性维度和数据总线来保证各个子主题的维度一致性")]),a._v(" "),v("li",[a._v("DM：基于 DW 建立的各个业务方各自所属的数据集市（Data Mart，DM），即应用层")])]),a._v(" "),v("p",[a._v("项目实际中，采用上述分层架构有以下好处：")]),a._v(" "),v("ul",[v("li",[a._v("屏蔽源头系统业务变更、系统变更对于下游用户的影响：相关变更由 DW 处理，对下游透明")]),a._v(" "),v("li",[a._v("屏蔽源头业务系统的复杂性：通过 DW 规范和屏蔽复杂性，保证下游数据使用数据的便捷和规范")]),a._v(" "),v("li",[a._v("避免重复计算和存储：通过汇总层，避免逻辑重复计算，节省计算和存储")]),a._v(" "),v("li",[a._v("数据仓库的可维护性：分层设计使得某一层的问题只在该层得到解决，无须更改下一层代码逻辑")])]),a._v(" "),v("h2",{attrs:{id:"实时数据平台的架构、技术和设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#实时数据平台的架构、技术和设计"}},[a._v("#")]),a._v(" 实时数据平台的架构、技术和设计")]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/kr/bigdata/hadoop/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.jpg",alt:""}})]),a._v(" "),v("h3",{attrs:{id:"流计算技术"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#流计算技术"}},[a._v("#")]),a._v(" 流计算技术")]),a._v(" "),v("p",[a._v("流计算特征：")]),a._v(" "),v("ul",[v("li",[a._v("无边界：流计算的数据源头是源源不断的，流计算任务也需要始终运行")]),a._v(" "),v("li",[a._v("触发：流计算任务的每次计算是由源头数据触发的")]),a._v(" "),v("li",[a._v("延迟：流计算必须能够高效地、迅速地处理数据")]),a._v(" "),v("li",[a._v("历史数据：实时流计算一般只能从问题发现的时刻修复数据，历史数据是无法通过流式方式来补的")])]),a._v(" "),v("p",[a._v("流计算的实现机制目前有两种处理方式：")]),a._v(" "),v("ul",[v("li",[a._v("模仿离线的批处理方式，即微批处理（Mini Batch），微批处理提升了吞吐量，但相应也增大了数据延迟，基本在秒级和分钟级，典型的技术是 Spark Streaming")]),a._v(" "),v("li",[a._v("原生消息数据方式，即处理单位是单条数据，早期原生流计算技术延迟低，但是数据吞吐量有限，典型的是原生的 Storm")])]),a._v(" "),v("h3",{attrs:{id:"主流流计算开源框架"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主流流计算开源框架"}},[a._v("#")]),a._v(" 主流流计算开源框架")]),a._v(" "),v("p",[a._v("流计算的另一个趋势是开发语言不停向声明式语言尤其是流计算 SQL 的发展")]),a._v(" "),v("ul",[v("li",[a._v("Storm：大批量流式数据处理的先锋，处理延迟非常低，数据吞吐量一般，不提供高级 API，不支持状态管理，不支持 exactly once 处理，只支持实时消息 atleast once 处理")]),a._v(" "),v("li",[a._v("Storm Trident：Trident 是对原生 Storm 的一个更高层次抽象，其最大特点是以 Mini Batch 形式进行流处理")]),a._v(" "),v("li",[a._v("Spark Streaming：基于微批处理的流计算框架，即它将源头数据分成很小的批并以类似于离线 Batch 方式来处理这小部分数据，底层依赖于 Spark Core 的 RDD 实现")]),a._v(" "),v("li",[a._v("Flink：一个同时面向流处理和批处理的开源计算平台，基于同一个 Flink 引擎，提供流处理和批处理两种类型应用的功能")])]),a._v(" "),v("h2",{attrs:{id:"数据湖-数据平台新架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据湖-数据平台新架构"}},[a._v("#")]),a._v(" 数据湖：数据平台新架构")])])}),[],!1,null,null,null);t.default=i.exports}}]);