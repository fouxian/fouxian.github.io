(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{489:function(a,s,t){"use strict";t.r(s);var r=t(34),e=Object(r.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"spark-概述与集群部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-概述与集群部署模式"}},[a._v("#")]),a._v(" Spark 概述与集群部署模式")]),a._v(" "),t("blockquote",[t("p",[a._v("Spark 是一种由 Scala 开发的基于内存的快速、通用、可扩展的大数据分析计算引擎，Spark 的计算模式也是 MapReduce。")])]),a._v(" "),t("blockquote",[t("p",[a._v("Apache Spark - A unified analytics engine for large-scale data processing.")]),a._v(" "),t("p",[a._v("Spark 是一种由 Scala 开发的基于内存的快速、通用、可扩展的大数据分析计算引擎。")]),a._v(" "),t("p",[a._v("Hadoop 是由 Java 编写的，在分布式服务器集群上存储并计算海量数据的分布式计算引擎。")]),a._v(" "),t("p",[a._v("Spark 和 Hadoop 的根本差异是多个作业间的数据通信问题：Spark 数据通信是基于内存，而 Hadoop 是基于磁盘。")]),a._v(" "),t("p",[a._v("Spark 的计算模式也是 MapReduce，Spark 是对 MR 的优化。")]),a._v(" "),t("p",[a._v("MR 中的 Map/Reduce Task 是 JVM 进程级别，每次启动都需要重新申请资源，而 Spark Task 是基于线程模型，复用线程池中的线程。")])]),a._v(" "),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark.png",alt:""}})]),a._v(" "),t("p",[a._v("Apache Spark 具有以下特点：")]),a._v(" "),t("ul",[t("li",[a._v("使用先进的 DAG 调度程序，查询优化器和物理执行引擎，以实现性能上的保证")]),a._v(" "),t("li",[a._v("多语言支持，目前支持的有 Java，Scala，Python 和 R")]),a._v(" "),t("li",[a._v("提供了 80 多个高级 API，可以轻松地构建应用程序")]),a._v(" "),t("li",[a._v("支持批处理、交互式查询、实时流处理、机器学习、图计算和复杂的业务分析")]),a._v(" "),t("li",[a._v("丰富的类库支持：包括 SQL，MLlib，GraphX 和 Spark Streaming 等库，并且可以无缝组合")]),a._v(" "),t("li",[a._v("丰富的部署模式：支持本地模式和自带集群模式，支持在 Hadoop，Mesos，Kubernetes 上运行")]),a._v(" "),t("li",[a._v("多数据源支持：支持访问 HDFS，Alluxio，Cassandra，HBase，Hive 等")])]),a._v(" "),t("h2",{attrs:{id:"spark-核心组件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-核心组件"}},[a._v("#")]),a._v(" Spark 核心组件")]),a._v(" "),t("ul",[t("li",[a._v("Spark Core：Spark 最基础最核心的功能")]),a._v(" "),t("li",[a._v("Spark SQL：用来操作结构化数据的组件")]),a._v(" "),t("li",[a._v("Spark Streaming：针对实时数据进行流式计算的组件")]),a._v(" "),t("li",[a._v("Spark MLlib：机器学习算法库")]),a._v(" "),t("li",[a._v("Spark GraphX：面向图计算提供的框架与算法库")])]),a._v(" "),t("h3",{attrs:{id:"spark-sql"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-sql"}},[a._v("#")]),a._v(" Spark SQL")]),a._v(" "),t("p",[a._v("Spark SQL 主要用于结构化数据的处理，其具有以下特点：")]),a._v(" "),t("ul",[t("li",[a._v("能够将 SQL 与 Spark 程序无缝混合，允许使用 SQL 或 DataFrame API 对结构化数据进行查询")]),a._v(" "),t("li",[a._v("支持多种数据源，包括 Hive，Avro，Parquet，ORC，JSON 和 JDBC")]),a._v(" "),t("li",[a._v("支持 HiveQL 语法以及用户自定义函数 (UDF)，允许访问现有的 Hive 仓库")]),a._v(" "),t("li",[a._v("支持标准的 JDBC 和 ODBC 连接")]),a._v(" "),t("li",[a._v("支持优化器，列式存储和代码生成等特性，以提高查询效率")])]),a._v(" "),t("h3",{attrs:{id:"spark-streaming"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-streaming"}},[a._v("#")]),a._v(" Spark Streaming")]),a._v(" "),t("p",[a._v("Spark Streaming 主要用于快速构建可扩展、高吞吐量、高容错的流处理程序，支持从 HDFS，Flume，Kafka，Twitter 和 ZeroMQ 读取数据，并进行处理\n"),t("img",{attrs:{src:"/images/kr/bigdata/spark/spark-streaming-arch.png",alt:""}})]),a._v(" "),t("p",[a._v("Spark Streaming 的本质是微批处理，它将数据流进行极小粒度的拆分，拆分为多个批处理，从而达到接近于流处理的效果\n"),t("img",{attrs:{src:"/images/kr/bigdata/spark/spark-streaming-flow.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"spark-mllib"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-mllib"}},[a._v("#")]),a._v(" Spark MLlib")]),a._v(" "),t("p",[a._v("MLlib 是 Spark 的机器学习赛算法库，其设计目标是使得机器学习变得简单且可扩展，它提供了以下工具：")]),a._v(" "),t("ul",[t("li",[a._v("常见的机器学习算法：如分类，回归，聚类和协同过滤")]),a._v(" "),t("li",[a._v("特征化：特征提取，转换，降维和选择")]),a._v(" "),t("li",[a._v("管道：用于构建，评估和调整 ML 管道的工具")]),a._v(" "),t("li",[a._v("持久性：保存和加载算法，模型，管道数据")]),a._v(" "),t("li",[a._v("实用工具：线性代数，统计，数据处理等")])]),a._v(" "),t("h3",{attrs:{id:"spark-graphx"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-graphx"}},[a._v("#")]),a._v(" Spark GraphX")]),a._v(" "),t("p",[a._v("GraphX 是 Spark 中用于图形计算和图形并行计算的新组件。在高层次上，GraphX 通过引入一个新的图形抽象来扩展 RDD(一种具有附加到每个顶点和边缘的属性的定向多重图形)。为了支持图计算，GraphX 提供了一组基本运算符（如： subgraph，joinVertices 和 aggregateMessages）以及优化后的 Pregel API。此外，GraphX 还包括越来越多的图形算法和构建器，以简化图形分析任务。")]),a._v(" "),t("h2",{attrs:{id:"作业提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#作业提交"}},[a._v("#")]),a._v(" 作业提交")]),a._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# Spark 所有模式均使用 spark-submit 命令提交作业")]),a._v("\nbin/spark-submit \n    --class "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("main-class"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("            "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 应用程序主入口类")]),a._v("\n    --master "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("master-url"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("           "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 集群的 Master Url：local[*]、spark://host:port、Yarn")]),a._v("\n    --deploy-mode "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("deploy-mode"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("     "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 部署模式")]),a._v("\n    --executor-memory               "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 指定每个 executor 可用内存")]),a._v("\n    --total-executor-cores          "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 指定所有 executor 使用的 CPU 核数量")]),a._v("\n    --executor-cores                "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 指定每个 executor 使用的 CPU 核数量")]),a._v("\n    --conf "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("key"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">=")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("            "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 可选配置  ")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("application-jar"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("               "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# Jar 包路径，集群环境下，必须都能被集群中所有节点访问")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("application-arguments"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("         "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 传递给主入口类的参数  ")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br")])]),t("p",[a._v("deploy-mode 部署模式有两个可选参数：cluster、client（默认），在 Spark On Yarn 模式下：")]),a._v(" "),t("ul",[t("li",[a._v("cluster：Spark Drvier 在应用程序的 Master 进程内运行，该进程由集群上的 YARN 管理，提交作业的客户端可以在启动应用程序后关闭，适用于生产环境")]),a._v(" "),t("li",[a._v("client：Spark Drvier 在提交作业的客户端进程中运行，Master 进程仅用于从 YARN 请求资源，适用于交互、调试，希望立即看到 app 输出")])]),a._v(" "),t("p",[a._v("master-url 的可选参数：")]),a._v(" "),t("ul",[t("li",[a._v("local：使用一个线程本地运行 Spark")]),a._v(" "),t("li",[a._v("local[K]：使用 K 个 worker 线程本地运行 Spark")]),a._v(" "),t("li",[a._v("local[K,F]：使用 K 个 worker 线程本地运行 Spark, 第二个参数为 Task 的失败重试次数")]),a._v(" "),t("li",[a._v("local[*]：使用与 CPU 核心数一样的线程数本地运行 Spark")]),a._v(" "),t("li",[a._v("local[*,F]：使用与 CPU 核心数一样的线程数本地运行 Spark，第二个参数为 Task 的失败重试次数")]),a._v(" "),t("li",[a._v("spark://HOST:PORT：连接至指定的 standalone 集群的 master 节点，端口号默认是 7077")]),a._v(" "),t("li",[a._v("spark://HOST1:PORT1,HOST2:PORT2：如果 standalone 集群采用 Zookeeper 实现高可用，则必须包含由 zookeeper 设置的所有 master 主机地址")]),a._v(" "),t("li",[a._v("mesos://HOST:PORT：连接至给定的 Mesos 集群，端口默认是 5050。对于使用了 ZooKeeper 的 Mesos cluster 来说，使用 mesos://zk://... 来指定地址，使用 --deploy-mode cluster 模式来提交")]),a._v(" "),t("li",[a._v("yarn：连接至一个 YARN 集群，集群由配置的 HADOOP_CONF_DIR 或者 YARN_CONF_DIR 来决定。使用 --deploy-mode 参数来配置 client 或 cluster 模式")])]),a._v(" "),t("h2",{attrs:{id:"spark-运行环境"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-运行环境"}},[a._v("#")]),a._v(" Spark 运行环境")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://gitee.com/fouxian/spark-docker",target:"_blank",rel:"noopener noreferrer"}},[a._v("代码仓库"),t("OutboundLink")],1)]),a._v(" "),t("h3",{attrs:{id:"local"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#local"}},[a._v("#")]),a._v(" Local")]),a._v(" "),t("p",[a._v("Local 模式：不需要其它任何节点资源即可在本地执行 Spark 代码的环境，采用单节点多线程方式运行，不用部署，开箱即用，适合日常测试开发\n"),t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-Shell.png",alt:""}})]),a._v(" "),t("div",{staticClass:"language-txt wordCount.txt line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-txt"}},[t("code",[a._v("Hello World\nHello Hadoop\nHello Hive\nHello Spark\nHello HBase\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br")])]),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("scala"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" sc.textFile"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/usr/local/data/test/wordCount.txt"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(".flatMap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_.split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('" "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("))")]),a._v(".map"),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("((")]),a._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("))")])]),a._v(".reduceByKey"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_+_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(".collect\nres0: Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("String, Int"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" Array"),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("((")]),a._v("Hello"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("World"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Hive"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("HBase"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("))")])]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-Shell-UI.png",alt:""}})]),a._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("bin/spark-submit --class org.apache.spark.examples.SparkPi --master local"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 本地模式提交作业")]),a._v("\n    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1000")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-Pi-UI.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"standalone"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone"}},[a._v("#")]),a._v(" Standalone")]),a._v(" "),t("p",[a._v("Standalone（独立部署）模式：Spark 提供的一种内置的基于 Master-Slave 的集群模式，采用内置的资源管理器进行管理。")]),a._v(" "),t("ul",[t("li",[a._v("Master(Cluster Manager)：主要负责资源的调度和分配，并进行集群的监控等职责，类似于 Yarn 的 RM")]),a._v(" "),t("li",[a._v("Worker：由 Master 分配资源对数据进行并行的处理和计算，类似于 Yarn 的 NM")])]),a._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 以 client 模式提交到 standalone 集群 ")]),a._v("\nspark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --master spark://spark-alone-master:7077 "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --executor-memory 2G --total-executor-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 以 cluster 模式提交到 standalone 集群 ")]),a._v("\nspark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --master spark://spark-alone-master:7077 "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --deploy-mode cluster "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --supervise     "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 配置此参数代表开启监督，如果主应用程序异常退出，则自动重启 Driver")]),a._v("\n    --executor-memory 2G --total-executor-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" \n    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br")])]),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-Master.png",alt:""}})]),a._v(" "),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-History.png",alt:""}}),a._v(" "),t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-History-Log.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"spark-on-yarn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-on-yarn"}},[a._v("#")]),a._v(" Spark On Yarn")]),a._v(" "),t("p",[a._v("基于 Yarn 资源管理与调度的 Spark 运行环境")]),a._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 以 client 模式提交到 Yarn 集群，适用于交互、调试，希望立即看到 app 输出 ")]),a._v("\nspark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --master "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v(" --deploy-mode client "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --executor-memory 2G --num-executors "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 以 cluster 模式提交到 Yarn 集群，适用于生产环境")]),a._v("\nspark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --master "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v(" --deploy-mode cluster "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    --executor-memory 2G --num-executors "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    /usr/local/spark-3.1.2/examples/jars/spark-examples_2.12-3.1.2.jar "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br")])]),t("p",[t("img",{attrs:{src:"/images/kr/bigdata/spark/Yarn-UI.png",alt:""}}),a._v(" "),t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-History-Yarn.png",alt:""}}),a._v(" "),t("img",{attrs:{src:"/images/kr/bigdata/spark/Spark-History-Yarn-Log.png",alt:""}})])])}),[],!1,null,null,null);s.default=e.exports}}]);