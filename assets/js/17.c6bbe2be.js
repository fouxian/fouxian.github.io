(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{471:function(s,a,e){"use strict";e.r(a);var t=e(34),n=Object(t.a)({},(function(){var s=this,a=s.$createElement,e=s._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h1",{attrs:{id:"sqoop-数据迁移工具"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-数据迁移工具"}},[s._v("#")]),s._v(" Sqoop 数据迁移工具")]),s._v(" "),e("p",[s._v("Sqoop 是一个常用的数据迁移工具，主要用于在不同存储系统之间实现数据的导入与导出，\n其原理是将执行命令转化成 MapReduce 作业来实现数据的迁移，在 MapReduce 中主要是对 inputformat/outputformat 进行定制")]),s._v(" "),e("ul",[e("li",[s._v("导入数据：从 MySQL，Oracle 等关系型数据库中导入数据到 HDFS、Hive、HBase 等分布式文件存储系统中")]),s._v(" "),e("li",[s._v("导出数据：从分布式文件系统中导出数据到关系数据库中")])]),s._v(" "),e("p",[s._v("其原理是将执行命令转化成 MapReduce 作业来实现数据的迁移，在 MapReduce 中主要是对 inputformat/outputformat 进行定制：\n"),e("img",{attrs:{src:"/images/kr/bigdata/sqoop/sqoop-tool.png",alt:""}})]),s._v(" "),e("h2",{attrs:{id:"sqoop-导入过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-导入过程"}},[s._v("#")]),s._v(" Sqoop 导入过程")]),s._v(" "),e("p",[e("img",{attrs:{src:"/images/kr/bigdata/sqoop/Sqoop-%E5%AF%BC%E5%85%A5%E8%BF%87%E7%A8%8B.png",alt:""}})]),s._v(" "),e("h2",{attrs:{id:"sqoop-导出过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-导出过程"}},[s._v("#")]),s._v(" Sqoop 导出过程")]),s._v(" "),e("p",[e("img",{attrs:{src:"/images/kr/bigdata/sqoop/Sqoop-%E5%AF%BC%E5%87%BA%E8%BF%87%E7%A8%8B.png",alt:""}})]),s._v(" "),e("h2",{attrs:{id:"sqoop-镜像"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-镜像"}},[s._v("#")]),s._v(" Sqoop 镜像")]),s._v(" "),e("div",{staticClass:"language-bash Dockerfile line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[s._v("FROM xzx/hadoop-3.2.2\nRUN yum -y "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v("\nRUN "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" -nv http://archive.apache.org/dist/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n        "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -C /usr/local "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" /dev/null "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n        "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("rm")]),s._v(" sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n        "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("mv")]),s._v(" /usr/local/sqoop-1.4.7.bin__hadoop-2.6.0/ /usr/local/sqoop-1.4.7\nENV SQOOP_HOME /usr/local/sqoop-1.4.7\nENV "),e("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/bin:"),e("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),s._v("\nCOPY mysql-connector-java-8.0.21.jar "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/lib\nCOPY commons-lang-2.6.jar "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/lib\nRUN "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("cp")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/conf/sqoop-env-template.sh "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/conf/sqoop-env.sh\nRUN "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'export HADOOP_COMMON_HOME=/usr/local/hadoop-3.2.2'")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/conf/sqoop-env.sh\nRUN "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'export HADOOP_MAPRED_HOME=/usr/local/hadoop-3.2.2'")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SQOOP_HOME")]),s._v("/conf/sqoop-env.sh\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br")])]),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查询所有数据库")]),s._v("\nsqoop list-databases --connect jdbc:mysql://192.168.72.1:3306?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC --username hue --password hue\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查询指定数据库的数据表")]),s._v("\nsqoop list-tables --connect jdbc:mysql://192.168.72.1:3306?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC --username hue --password hue\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br")])]),e("h2",{attrs:{id:"mysql-与-hdfs、hive、hbase-导入导出"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mysql-与-hdfs、hive、hbase-导入导出"}},[s._v("#")]),s._v(" MySQL 与 HDFS、Hive、HBase 导入导出")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# MySQL 数据导入 HDFS，导入命令")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC --username root --password root \n    --table help_keyword            "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 待导入的表")]),s._v("\n    --delete-target-dir             "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 目标目录存在则先删除")]),s._v("\n    --target-dir /sqoop             "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导入的目标目录")]),s._v("\n    --fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\t'")]),s._v("     "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定导出数据的分隔符")]),s._v("\n    -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("                            "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定并行执行的 map tasks 数量")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br")])]),e("p",[s._v("输入数据被平均 split 为三份，分别由三个 map task 进行处理。数据默认以表的主键列作为拆分依据，如果表没有主键，有以下两种方案：")]),s._v(" "),e("ul",[e("li",[s._v("添加 --autoreset-to-one-mapper 参数，代表只启动一个 map task，即不并行执行")]),s._v(" "),e("li",[s._v("若仍希望并行执行，则可以使用 "),e("code",[s._v("--split-by <column-name>")]),s._v(" 指明拆分数据的参考列")])]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# HDFS 数据导出到 MySQL，导出命令")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC \n    --username root --password root\n    --table help_keyword_from_hdfs         "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导出数据存储在 MySQL 的 help_keyword_from_hdf 的表中")]),s._v("\n    --export-dir /sqoop  \n    --input-fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\t'")]),s._v("\n    --m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" \n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br")])]),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# MySQL 数据导入到 Hive，Sqoop 导入数据到 Hive 是通过先将数据导入到 HDFS 上的临时目录，")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 然后再将数据从 HDFS 上 Load 到 Hive 中，最后将临时目录删除")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC\n  --username root --password root\n  --table help_keyword         "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 待导入的表     ")]),s._v("\n  --delete-target-dir          "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 如果临时目录存在删除")]),s._v("\n  --target-dir /sqoop_hive     "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 临时目录位置")]),s._v("\n  --hive-database sqoop_test   "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导入到 Hive 的 sqoop_test 数据库，数据库需要预先创建。不指定则默认为 default 库")]),s._v("\n  --hive-import                "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导入到 Hive")]),s._v("\n  --hive-overwrite             "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 如果 Hive 表中有数据则覆盖，这会清除表中原有的数据，然后再写入")]),s._v("\n  -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("                         "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 并行度")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br")])]),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Hive 导出数据到 MySQL，实际上就是 HDFS 导出数据到 MySQL")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC\n    --username root --password root\n    --table help_keyword_from_hive \n    --export-dir /user/hive/warehouse/sqoop_test.db/help_keyword \n    --input-fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\001'")]),s._v("              "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 需要注意的是 hive 中默认的分隔符为 \\001")]),s._v("\n    --m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" \n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br")])]),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# MySQL 导入数据到 HBase")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将 help_keyword 表中数据导入到 HBase 上的 help_keyword_hbase 表中，")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用原表的主键 help_keyword_id 作为 RowKey，原表的所有列都会在 keywordInfo 列族下，")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 目前只支持全部导入到一个列族下，不支持分别指定列族")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC\n    --username root --password root \n    --table help_keyword                "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 待导入的表")]),s._v("\n    --hbase-table help_keyword_hbase    "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hbase 表名称，表需要预先创建")]),s._v("\n    --column-family keywordInfo         "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 所有列导入到 keywordInfo 列族下 ")]),s._v("\n    --hbase-row-key help_keyword_id     "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用原表的 help_keyword_id 作为 RowKey")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br")])]),e("h2",{attrs:{id:"全量导入"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#全量导入"}},[s._v("#")]),s._v(" 全量导入")]),s._v(" "),e("p",[s._v("Sqoop 支持通过 import-all-tables 命令进行全量导入到 HDFS/Hive，但需要注意有以下两个限制：")]),s._v(" "),e("ul",[e("li",[s._v("所有表必须有主键；或者使用 --autoreset-to-one-mapper，代表只启动一个 map task")]),s._v(" "),e("li",[s._v("不能使用非默认的分割列，也不能通过 WHERE 子句添加任何限制")])]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全量导入到 HDFS")]),s._v("\nsqoop import-all-tables --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC \n    --username root --password root \n    --warehouse-dir  /sqoop_all       "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 每个表会单独导出到一个目录，需要用此参数指明所有目录的父目录")]),s._v("\n    --fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\t'")]),s._v("\n    -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全量导入到 Hive")]),s._v("\nsqoop import-all-tables -Dorg.apache.sqoop.splitter.allow_text_splitter"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true \n  --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC \n  --username root --password root \n  --hive-database sqoop_test          "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导出到 Hive 对应的库   ")]),s._v("\n  --hive-import \n  --hive-overwrite \n  -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br")])]),e("h2",{attrs:{id:"增量导入"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#增量导入"}},[s._v("#")]),s._v(" 增量导入")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Sqoop 支持使用 query 参数定义查询 SQL，从而进行手动的增量导入")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC\n  --username root --password root \n  --query "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'select * from help_keyword where $CONDITIONS and help_keyword_id < 50'")]),s._v(" \n  --delete-target-dir            \n  --target-dir /sqoop_hive   \n  --hive-database sqoop_test            "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定导入目标数据库 不指定则默认使用 Hive 中的 default 库")]),s._v("\n  --hive-table filter_help_keyword      "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定导入目标表")]),s._v("\n  --split-by help_keyword_id            "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定用于 split 的列      ")]),s._v("\n  --hive-import                         "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导入到 Hive")]),s._v("\n  --hive-overwrite\n  -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br")])]),e("p",[s._v("在使用 query 进行数据过滤时，需要注意以下三点：")]),s._v(" "),e("ul",[e("li",[s._v("必须用 --hive-table 指明目标表")]),s._v(" "),e("li",[s._v("如果并行度 -m 不为 1 或者没有指定 --autoreset-to-one-mapper，则需要用 --split-by 指明参考列")]),s._v(" "),e("li",[s._v("SQL 的 where 字句必须包含 $CONDITIONS，这是固定写法，作用是动态替换")])]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 增量导入：依靠维护的参考列来判断哪些是增量数据")]),s._v("\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.72.1:3306/mysql?serverTimezone"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("UTC\n    --username root --password root \n    --table help_keyword \n    --target-dir /sqoop_hive  \n    --hive-database sqoop_test          \n    --incremental  append               "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指明模式")]),s._v("\n    --check-column  help_keyword_id     "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指明用于增量导入的参考列")]),s._v("\n    --last-value "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("300")]),s._v("                    "),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定参考列上次导入的最大值")]),s._v("\n    --hive-import "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("   \n    -m "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("  \n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br")])]),e("p",[s._v("incremental 参数有以下两个可选的选项：")]),s._v(" "),e("ul",[e("li",[s._v("append：要求参考列的值必须是递增的，所有大于 last-value 的值都会被导入")]),s._v(" "),e("li",[s._v("lastmodified：要求参考列的值必须是 timestamp 类型，且插入数据时要在参考列插入当前时间戳，更新数据时也要更新参考列的时间戳，所有时间晚于 last-value 的数据都会被导入")])]),s._v(" "),e("h2",{attrs:{id:"导入导出脚本"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#导入导出脚本"}},[s._v("#")]),s._v(" 导入导出脚本")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 导入导出脚本以 .opt 为后缀")]),s._v("\nsqoop --options-file 导入导出脚本.opt\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br")])])])}),[],!1,null,null,null);a.default=n.exports}}]);